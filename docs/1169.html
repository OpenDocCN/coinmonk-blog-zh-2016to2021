<html>
<head>
<title>Training Neural Networks upto 10x Faster</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">训练神经网络的速度提高了10倍</h1>
<blockquote>原文：<a href="https://medium.com/coinmonks/training-neural-networks-upto-10x-faster-3246d84caacd?source=collection_archive---------4-----------------------#2018-07-30">https://medium.com/coinmonks/training-neural-networks-upto-10x-faster-3246d84caacd?source=collection_archive---------4-----------------------#2018-07-30</a></blockquote><div><div class="ef hh hi hj hk hl"/><div class="hm hn ho hp hq"><div class=""/><p id="659d" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">这是物体探测软件<a class="ae jo" href="https://github.com/karanchahal/object-detection/wiki" rel="noopener ugc nofollow" target="_blank"> wiki </a>的摘录。我目前正在实现一些最<strong class="is hu">前沿</strong>的物体检测算法<a class="ae jo" href="http://github.com/karanchahal/object-detection" rel="noopener ugc nofollow" target="_blank">这里</a>，我将把我实现它们的经历写在博客上。</p><p id="79aa" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">今天我们讨论如何通过使用两种技术来训练神经网络，使其比正常情况快得多。<strong class="is hu">循环学习率</strong>和<strong class="is hu">超收敛</strong>。</p><p id="bcab" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">该项目的培训方法旨在使培训简单快捷。最近，像超收敛和循环学习率这样的技术已经极大地改善了模型收敛的时间。</p><p id="ce4d" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">目标检测软件试图使用最先进的训练技术。在寻找最佳方法的过程中，我偶然发现了fastai图书馆使用的这项技术。</p><h1 id="8dfc" class="jp jq ht bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km dt translated">学习率探测器</h1><p id="5e12" class="pw-post-body-paragraph iq ir ht is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hm dt translated">学习率查找器首先由CLR (link) fame的Leslie N Smith(link)介绍，它寻求找到最佳学习率来开始任何数据集/架构的训练。</p><p id="492d" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">这个技术很简单。有一个时期，</p><ol class=""><li id="3647" class="ks kt ht is b it iu ix iy jb ku jf kv jj kw jn kx ky kz la dt translated">以非常小的学习速率(大约1e-8)开始，然后<em class="lb">线性增加学习速率</em>。</li><li id="aeee" class="ks kt ht is b it lc ix ld jb le jf lf jj lg jn kx ky kz la dt translated">绘制LR每一步的损失。</li><li id="1fa4" class="ks kt ht is b it lc ix ld jb le jf lf jj lg jn kx ky kz la dt translated">当亏损停止下降并开始增加时，停止学习率查找器。</li></ol><p id="e656" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">我想到了一些问题:</p><ol class=""><li id="cd7a" class="ks kt ht is b it iu ix iy jb ku jf kv jj kw jn kx ky kz la dt translated">你如何线性增加LR？</li><li id="5ed2" class="ks kt ht is b it lc ix ld jb le jf lf jj lg jn kx ky kz la dt translated">如果损失没有停止减少，你什么时候停止这个过程<strong class="is hu">？</strong></li></ol><p id="1833" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu">Ans 1</strong>:LR的线性变化策略如下。我们有一个初始学习率(~1e-8)和一个最终学习率(8)(很大)。下面给出了一些示例代码:</p><pre class="lh li lj lk fq ll lm ln lo aw lp dt"><span id="e4bf" class="lq jq ht lm b fv lr ls l lt lu">num = 100 # the number of mini batches in an epoch<br/>mult = (final_value / init_value) ** (1/num) # the lr multiplier<br/>new_lr = old_lr*mult</span></pre><p id="3b21" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu"> Ans 2 </strong>:这是一种非常罕见的情况，如果确实发生了，那么再次运行LR查找器，使<strong class="is hu">最终值</strong>增大一个因子。一般来说，一个好的最终学习率应该在8%左右。</p><p id="6a0b" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">学习率查找器非常适合查找最佳学习率，并且还能提供关于模型如何与数据集收敛的更多信息。</p><p id="9523" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">我们使用学习率查找器中的信息来实施我们的1周期策略，该策略将在下一节课中介绍。</p><p id="5cd7" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">学习率查找器的代码如下所示:</p><figure class="lh li lj lk fq lv"><div class="bz el l di"><div class="lw lx l"/></div></figure><p id="02b8" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">该功能的执行图表如下所示。</p><figure class="lh li lj lk fq lv fe ff paragraph-image"><div class="fe ff ly"><img src="../Images/0f65fbf249cec22e61cd1b9ef747776f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/0*Ie74kBmNYhl7M1a6.png"/></div></figure><p id="626d" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt">.</p><p id="acd4" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">从这个图看，0.01的学习率似乎是训练网络的一个好值。我们可以选择的最大学习率大约是0.1。</p><h1 id="74a9" class="jp jq ht bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km dt translated">1周期政策</h1><p id="5dbf" class="pw-post-body-paragraph iq ir ht is b it kn iv iw ix ko iz ja jb kp jd je jf kq jh ji jj kr jl jm jn hm dt translated"><em class="lb"> 1周期策略</em>规定，使用周期学习率可以在比标准时间短得多的时间内收敛模型。使用这种方法，我们旨在实现所谓的超收敛。</p><p id="8fa6" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">超收敛是在相同硬件条件下，模型在比范数更短的时间内进行训练。</p><p id="9f10" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">在训练cifar10数据集时，可以找到超收敛的一个例子。</p><p id="5bc6" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">使用<em class="lb"> 1周期策略</em>，网络在20个时间段内收敛到93%的准确率，批量为150个。</p><p id="257f" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">这比使用手动学习率步骤的500个纪元要好得多，手动学习率步骤为1-150个纪元0.1，0.01-150-300个纪元0.001-300-500个纪元，批量为150。</p><p id="8e38" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">所有结果都已在配备约11 GB单GPU (Nvidia Tesla K80)的<strong class="is hu"> Colab </strong>笔记本上测试过。</p><p id="eee1" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">一个周期的保单如下:</p><p id="ad8d" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">注:我们称LR查找器找到的学习率为<strong class="is hu"> L </strong>。</p><ol class=""><li id="3ae0" class="ks kt ht is b it iu ix iy jb ku jf kv jj kw jn kx ky kz la dt translated"><strong class="is hu">从比学习率查找器找到的学习率低1/10的学习率开始</strong>。</li><li id="0ac5" class="ks kt ht is b it lc ix ld jb le jf lf jj lg jn kx ky kz la dt translated">训练模型，每个纪元后<strong class="is hu">将LR线性增加至L </strong>。</li><li id="4220" class="ks kt ht is b it lc ix ld jb le jf lf jj lg jn kx ky kz la dt translated">达到L后，开始<strong class="is hu">降低左后</strong>直到L/10。</li></ol><p id="28b2" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">学习率变化的图表如下所示:</p><figure class="lh li lj lk fq lv fe ff paragraph-image"><div class="fe ff mb"><img src="../Images/1059aada48aaea618abf329acb7b4aad.png" data-original-src="https://miro.medium.com/v2/resize:fit:974/format:webp/0*YUey2ceEul2bK9dR.png"/></div></figure><p id="5dfc" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">将该学习率序列划分为~ 20 ~ 30个时期，并检查<em class="lb">验证准确性</em>。如果模型达不到要求的精度，增加纪元数。</p><p id="6e8d" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">在使用这种方法进行实验时，在Cifar10数据集上获得的一些结果在此处<a class="ae jo" href="https://github.com/karanchahal/papers/blob/master/super_convergence_notes.md" rel="noopener ugc nofollow" target="_blank"/>给出</p><p id="2fd9" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">然而，这种方法存在许多问题。具体如下:</p><ol class=""><li id="9bd5" class="ks kt ht is b it iu ix iy jb ku jf kv jj kw jn kx ky kz la dt translated">一个人应该使用什么样的<strong class="is hu">乐观者</strong>？</li><li id="b1f3" class="ks kt ht is b it lc ix ld jb le jf lf jj lg jn kx ky kz la dt translated">应该选择什么<strong class="is hu">批量</strong>？</li><li id="54f8" class="ks kt ht is b it lc ix ld jb le jf lf jj lg jn kx ky kz la dt translated">这适用于<strong class="is hu">大数据集和小数据集</strong>吗？</li><li id="73d5" class="ks kt ht is b it lc ix ld jb le jf lf jj lg jn kx ky kz la dt translated">什么<strong class="is hu">模型架构</strong>不支持1周期策略？</li><li id="670c" class="ks kt ht is b it lc ix ld jb le jf lf jj lg jn kx ky kz la dt translated">你应该测试<strong class="is hu">循环动量</strong>吗？</li></ol><p id="8845" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">这些问题需要一个可靠的答案，我们将适当地研究这些问题，并在训练网络时达成一套可靠的规则。</p><blockquote class="mc"><p id="f4e3" class="md me ht bd mf mg mh mi mj mk ml jn ek translated"><a class="ae jo" href="https://coincodecap.com/?utm_source=coinmonks" rel="noopener ugc nofollow" target="_blank">直接在您的收件箱中获取最佳软件交易</a></p></blockquote><figure class="mn mo mp mq mr lv fe ff paragraph-image"><a href="https://coincodecap.com/?utm_source=coinmonks"><div class="fe ff mm"><img src="../Images/7c0b3dfdcbfea594cc0ae7d4f9bf6fcb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1168/format:webp/0*OJ-qb5G6i863msBB.png"/></div></a></figure></div></div>    
</body>
</html>