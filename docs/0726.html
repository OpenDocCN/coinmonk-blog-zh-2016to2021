<html>
<head>
<title>Learn How to Train U-Net On Your Dataset</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">了解如何在数据集上训练U-Net</h1>
<blockquote>原文：<a href="https://medium.com/coinmonks/learn-how-to-train-u-net-on-your-dataset-8e3f89fbd623?source=collection_archive---------0-----------------------#2018-06-08">https://medium.com/coinmonks/learn-how-to-train-u-net-on-your-dataset-8e3f89fbd623?source=collection_archive---------0-----------------------#2018-06-08</a></blockquote><div><div class="ef hh hi hj hk hl"/><div class="hm hn ho hp hq"><div class=""/><figure class="fi fk ir is it iu fe ff paragraph-image"><div role="button" tabindex="0" class="iv iw di ix bf iy"><div class="fe ff iq"><img src="../Images/ded916d49f344b256a992e6a57466451.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sj5U51StQ16r_x38t7yHuA.png"/></div></div><figcaption class="jb jc fg fe ff jd je bd b be z ek">Fig.1 : A test image along with its label (semantically segmented output)</figcaption></figure><p id="5182" class="pw-post-body-paragraph jf jg ht jh b ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc hm dt translated">为了在一个小的生物医学数据集上执行语义分割，我使用Keras坚定地尝试去揭开U-Net工作的神秘面纱。由于我还没有看到任何系统解释训练步骤的文章，所以我想到了为其他深度学习爱好者记录这些内容。你们中的一些人一定在想，我是否已经涵盖了这个框架的理论方面。虽然我的主要重点是阐述实现，但我也试图包括与其理解相关的细节。我的大部分参考资料包括<strong class="jh hu"> </strong> <a class="ae kd" href="https://github.com/zhixuhao" rel="noopener ugc nofollow" target="_blank"> <strong class="jh hu">智旭豪</strong> </a> <strong class="jh hu">在Github上的unet知识库</strong>和论文，<strong class="jh hu"> U-Net:卷积网络用于生物医学图像分割</strong>由<strong class="jh hu"/><a class="ae kd" href="https://arxiv.org/search?searchtype=author&amp;query=Ronneberger%2C+O" rel="noopener ugc nofollow" target="_blank">Olaf Ronneberger</a>等人</p><h1 id="c1fb" class="ke kf ht bd kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb dt translated">关于优信网</h1><p id="f654" class="pw-post-body-paragraph jf jg ht jh b ji lc jk jl jm ld jo jp jq le js jt ju lf jw jx jy lg ka kb kc hm dt translated">U-net架构与编码器-解码器架构同义。本质上是基于<a class="ae kd" href="https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf" rel="noopener ugc nofollow" target="_blank"> FCNs </a>的深度学习框架；它由两部分组成:</p><ol class=""><li id="35ba" class="lh li ht jh b ji jj jm jn jq lj ju lk jy ll kc lm ln lo lp dt translated">类似于编码器的收缩路径，通过紧凑的特征图<strong class="jh hu">捕获上下文。</strong></li><li id="d113" class="lh li ht jh b ji lq jm lr jq ls ju lt jy lu kc lm ln lo lp dt translated">类似于解码器的对称扩展路径，允许<strong class="jh hu">精确定位</strong>。尽管在编码器阶段执行了下采样和最大汇集，但完成该步骤是为了保留边界信息(空间信息)。</li></ol><figure class="lw lx ly lz fq iu fe ff paragraph-image"><div class="fe ff lv"><img src="../Images/91415dbceaa2caf20327b8e93e2c9af5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/format:webp/1*TXfEPqTbFBPCbXYh2bstlA.png"/></div><figcaption class="jb jc fg fe ff jd je bd b be z ek">Fig.2: Architecture of U-Net based on the paper by <a class="ae kd" href="https://arxiv.org/search?searchtype=author&amp;query=Ronneberger%2C+O" rel="noopener ugc nofollow" target="_blank">Olaf Ronneberger</a> et.al</figcaption></figure><h2 id="4b1b" class="ma kf ht bd kg mb mc md kk me mf mg ko jq mh mi ks ju mj mk kw jy ml mm la mn dt translated">使用U-Net的优势</h2><ol class=""><li id="99cf" class="lh li ht jh b ji lc jm ld jq mo ju mp jy mq kc lm ln lo lp dt translated">计算效率高</li><li id="2295" class="lh li ht jh b ji lq jm lr jq ls ju lt jy lu kc lm ln lo lp dt translated">可用小数据集训练</li><li id="fc3e" class="lh li ht jh b ji lq jm lr jq ls ju lt jy lu kc lm ln lo lp dt translated">端到端培训</li><li id="a6a4" class="lh li ht jh b ji lq jm lr jq ls ju lt jy lu kc lm ln lo lp dt translated">更适合生物医学应用</li></ol><p id="e15b" class="pw-post-body-paragraph jf jg ht jh b ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc hm dt translated">等等，到底什么是语义切分和本地化？简单来说，他们指的是<strong class="jh hu">像素级标签</strong>，即图像中的每个像素都有一个类别标签。你会得到分割图，如图1所示。在此之前，生物医学研究人员遵循两种方法:</p><ol class=""><li id="88e7" class="lh li ht jh b ji jj jm jn jq lj ju lk jy ll kc lm ln lo lp dt translated">将图像作为一个整体进行分类(恶性或良性)。</li><li id="0a90" class="lh li ht jh b ji lq jm lr jq ls ju lt jy lu kc lm ln lo lp dt translated">将图像分成<strong class="jh hu">块</strong>并分类。</li></ol><p id="ce39" class="pw-post-body-paragraph jf jg ht jh b ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc hm dt translated">由于数据集大小增加，修补当然比整个图像分类更好，但是，这也有一些缺点。较小的步距或大量重叠的修补都是计算密集型的，并导致冗余(重复)信息。其次，<strong class="jh hu"> <em class="mr">上下文信息和本地化之间的良好权衡至关重要</em> </strong>。<strong class="jh hu">小补丁导致上下文信息丢失，而大补丁篡改定位结果。</strong>最后，非重叠补丁会导致上下文信息的丢失。基于先前的观察，编码器-解码器架构产生比将每个像素馈送到CNN进行分类高得多的交集(IoU) 值。</p><h1 id="ed88" class="ke kf ht bd kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb dt translated">准备数据集</h1><p id="9649" class="pw-post-body-paragraph jf jg ht jh b ji lc jk jl jm ld jo jp jq le js jt ju lf jw jx jy lg ka kb kc hm dt translated">让我们开始准备您的数据集吧！我将写一篇单独的文章，涵盖U-Net的本质，所以不要绞尽脑汁，陷入它的架构。</p><ol class=""><li id="d849" class="lh li ht jh b ji jj jm jn jq lj ju lk jy ll kc lm ln lo lp dt translated">将您的原始数据集和相应的注释分成两组，即<em class="mr">训练集和测试集</em>(验证，更精确地说)集。<strong class="jh hu">原始图像为RGB </strong>格式，而其<strong class="jh hu">蒙版为二进制</strong>(黑白)。</li><li id="a8d2" class="lh li ht jh b ji lq jm lr jq ls ju lt jy lu kc lm ln lo lp dt translated">将所有图像数据转换为<strong class="jh hu"> .tif. </strong></li><li id="0b57" class="lh li ht jh b ji lq jm lr jq ls ju lt jy lu kc lm ln lo lp dt translated">您将不需要测试集的图像类标签或注释(这不是一个分类问题)。</li></ol><p id="ac4d" class="pw-post-body-paragraph jf jg ht jh b ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc hm dt translated"><strong class="jh hu">注意:</strong>选择图像尺寸，使得连续的convs和max-pooling在每个阶段 产生x和y  (即特征图的宽度和高度)<strong class="jh hu"> <em class="mr">的偶数值<strong class="jh hu"> <em class="mr">。虽然我的图片是360X360像素，但我把它们的尺寸调整为256X256。裁剪出边界以获得合适的图像尺寸。为此，我已经包含了代码。</em></strong></em></strong></p><figure class="lw lx ly lz fq iu"><div class="bz el l di"><div class="ms mt l"/></div><figcaption class="jb jc fg fe ff jd je bd b be z ek">Cropping and conversion to .tif</figcaption></figure><p id="869a" class="pw-post-body-paragraph jf jg ht jh b ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc hm dt translated">你一定在想给这些文件夹取什么名字，等等等等..再等几分钟，你就知道该把它们放在哪里了！</p><h1 id="f85d" class="ke kf ht bd kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb dt translated">先决条件</h1><ul class=""><li id="99ae" class="lh li ht jh b ji lc jm ld jq mo ju mp jy mq kc mu ln lo lp dt translated">张量流</li><li id="f25a" class="lh li ht jh b ji lq jm lr jq ls ju lt jy lu kc mu ln lo lp dt translated">Keras &gt;= 1.0</li><li id="a7a8" class="lh li ht jh b ji lq jm lr jq ls ju lt jy lu kc mu ln lo lp dt translated">libtiff(可选)</li><li id="66e8" class="lh li ht jh b ji lq jm lr jq ls ju lt jy lu kc mu ln lo lp dt translated">OpenCV 3(如果你是MAC用户，按照<a class="ae kd" href="https://www.codingforentrepreneurs.com/blog/install-opencv-3-for-python-on-mac/" rel="noopener ugc nofollow" target="_blank">这个</a>进行安装)</li></ul><p id="1287" class="pw-post-body-paragraph jf jg ht jh b ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc hm dt translated">此外，这段代码应该与Python版本2.7–3.5兼容。</p><h1 id="0921" class="ke kf ht bd kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb dt translated">培训和数据扩充</h1><p id="818a" class="pw-post-body-paragraph jf jg ht jh b ji lc jk jl jm ld jo jp jq le js jt ju lf jw jx jy lg ka kb kc hm dt translated">如果需要，你可以旋转、反射和扭曲图像。<a class="ae kd" href="https://github.com/zhixuhao" rel="noopener ugc nofollow" target="_blank">智旭豪</a>使用了一种可用的变形方法<a class="ae kd" href="https://github.com/cxcxcxcx/imgwarp-opencv" rel="noopener ugc nofollow" target="_blank">这里</a>。仔细遵循下面的几个步骤；少走一步会让你发疯几个小时！为简单起见，我将培训阶段分为两部分——A部分和B部分。</p><h2 id="1797" class="ma kf ht bd kg mb mc md kk me mf mg ko jq mh mi ks ju mj mk kw jy ml mm la mn dt translated">A部分-修改数据. py</h2><p id="47ee" class="pw-post-body-paragraph jf jg ht jh b ji lc jk jl jm ld jo jp jq le js jt ju lf jw jx jy lg ka kb kc hm dt translated">1.克隆<a class="ae kd" href="https://github.com/zhixuhao" rel="noopener ugc nofollow" target="_blank">智旭豪</a>的仓库。</p><pre class="lw lx ly lz fq mv mw mx my aw mz dt"><span id="38e2" class="ma kf ht mw b fv na nb l nc nd">$ git clone <a class="ae kd" href="https://github.com/zhixuhao/unet" rel="noopener ugc nofollow" target="_blank">https://github.com/zhixuhao/unet</a></span></pre><p id="724e" class="pw-post-body-paragraph jf jg ht jh b ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc hm dt translated">2.进入<strong class="jh hu"> <em class="mr">图像</em> </strong>文件夹，该文件夹位于列车文件夹(<em class="mr">内../unet/data/train/image </em>。</p><p id="3da4" class="pw-post-body-paragraph jf jg ht jh b ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc hm dt translated">3.将训练图像包含在图像文件夹中。<strong class="jh hu">每个图像都应该在。tif格式，连续命名，<em class="mr">从0.tif开始，1 . TIF…以此类推。</em>T15】</strong></p><p id="9fd7" class="pw-post-body-paragraph jf jg ht jh b ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc hm dt translated">4.进入火车文件夹(<em class="mr">内的<strong class="jh hu"> <em class="mr">标签</em> </strong>文件夹../unet/data/train/label </em>。包括相应的训练图像注释。<strong class="jh hu">每个图像都应该在。tif格式，连续命名，<em class="mr">从0.tif开始，1 . TIF…以此类推。标签必须对应于训练图像集</em> </strong>。</p><p id="9381" class="pw-post-body-paragraph jf jg ht jh b ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc hm dt translated">5.进入数据文件夹内的测试文件夹(<em class="mr">../unet/data/test </em>。</p><p id="6284" class="pw-post-body-paragraph jf jg ht jh b ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc hm dt translated">6.在数据文件夹(<em class="mr">内创建一个名为<strong class="jh hu"> <em class="mr"> npydata </em> </strong>的文件夹../unet/data/npydata </em>)。让它保持空白；处理后的数据集将作为3保存在此。npy文件。</p><p id="aeb2" class="pw-post-body-paragraph jf jg ht jh b ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc hm dt translated">7.打开unet文件夹(<em class="mr">中的<strong class="jh hu"> <em class="mr"> data.py </em> </strong>文件../unet/data.py </em>)。步骤8、9、10和11是指您必须在该文件中对RGB图像进行的更改。粗体区域对应于我所做的更改。</p><p id="df4d" class="pw-post-body-paragraph jf jg ht jh b ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc hm dt translated">8.修改<em class="mr">def create _ train _ data(self)</em>如下图所示。</p><pre class="lw lx ly lz fq mv mw mx my aw mz dt"><span id="15bd" class="ma kf ht mw b fv na nb l nc nd">def create_train_data(self):<br/>...<br/>  imgdatas = np.ndarray((len(imgs),self.out_rows,self.out_cols,<strong class="mw hu">3</strong>),     dtype=np.uint8)<br/>  imglabels =  np.ndarray((len(imgs),self.out_rows,self.out_cols,1),   dtype=np.uint8)<br/>...<br/>  img = load_img(self.data_path + "/" + midname) <strong class="mw hu">#Removed grayscale</strong><br/>  label = load_img(self.label_path + "/" + midname,grayscale = True)<br/>#Correspond to lines 159-164</span></pre><p id="8da9" class="pw-post-body-paragraph jf jg ht jh b ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc hm dt translated">9.修改def<em class="mr">create _ test _ data(self)</em>如下所示。</p><pre class="lw lx ly lz fq mv mw mx my aw mz dt"><span id="354c" class="ma kf ht mw b fv na nb l nc nd">def create_test_data(self):<br/>…<br/> imgdatas = np.ndarray((len(imgs),self.out_rows,self.out_cols,<strong class="mw hu">3</strong>), dtype=np.uint8)<br/> …<br/> img = load_img(self.test_path + "/" + midname) <strong class="mw hu">#Removed grayscale<br/></strong>#Correspond to lines 188 and 191</span></pre><p id="1671" class="pw-post-body-paragraph jf jg ht jh b ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc hm dt translated">10.将<strong class="jh hu"> <em class="mr"> imgnum </em> </strong>更改为您的车组尺寸。</p><pre class="lw lx ly lz fq mv mw mx my aw mz dt"><span id="0a89" class="ma kf ht mw b fv na nb l nc nd">def doAugmentate(self, img, save_to_dir, save_prefix, batch_size=1, save_format='tif', <strong class="mw hu">imgnum=26</strong>): #I've considered 26 training images</span></pre><p id="9e47" class="pw-post-body-paragraph jf jg ht jh b ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc hm dt translated">11.通过提供正确的路径详细信息，修改类dataProcess(object)中的以下内容。我把<strong class="jh hu"> <em class="mr"> data_path、label_path、test_path和npy_path </em> </strong>改成了正确的路径(对应我系统中的目录)。你可以试着在data.py的第138行编辑这些。如果出现一些错误，请浏览我在Github上对<a class="ae kd" href="https://github.com/zhixuhao/unet/issues/40" rel="noopener ugc nofollow" target="_blank">问题#40 </a>的回答。请确保npydata文件夹的路径没有错误(这是一个常见的错误)。</p><pre class="lw lx ly lz fq mv mw mx my aw mz dt"><span id="0f3e" class="ma kf ht mw b fv na nb l nc nd">def __init__(self, out_rows, out_cols, <strong class="mw hu">data_path</strong> = "/Users/sukritipaul/Dev/newcvtestpy2/unet2/data/train/image", <strong class="mw hu">label_path</strong> = "/Users/sukritipaul/Dev/newcvtestpy2/unet2/data/train/label", <strong class="mw hu">test_path</strong> = "/Users/sukritipaul/Dev/newcvtestpy2/unet2/data/test", <strong class="mw hu">npy_path</strong> = "/Users/sukritipaul/Dev/newcvtestpy2/unet2/data/npydata", img_type = "tif"):<br/>#Corresponds to line 138</span></pre><p id="a0ba" class="pw-post-body-paragraph jf jg ht jh b ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc hm dt translated">12.运行data.py</p><pre class="lw lx ly lz fq mv mw mx my aw mz dt"><span id="bf48" class="ma kf ht mw b fv na nb l nc nd">$python data.py</span></pre><h2 id="2e89" class="ma kf ht bd kg mb mc md kk me mf mg ko jq mh mi ks ju mj mk kw jy ml mm la mn dt translated">A部分-验证</h2><figure class="lw lx ly lz fq iu fe ff paragraph-image"><div class="fe ff ne"><img src="../Images/f7f5f172a8dac31bf32a3c008e0bc57d.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*wV9UpIBrGq2cXjGaMdhbGw.png"/></div><figcaption class="jb jc fg fe ff jd je bd b be z ek">Fig 3: Output obtained on running data.py</figcaption></figure><p id="913a" class="pw-post-body-paragraph jf jg ht jh b ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc hm dt translated">您的输出应该与图3中的输出相匹配。我已经打印了训练图像、训练注释和测试图像的大小。如果您的终端显示了正确数量的训练和测试图像(在本例中是8和4)，那么您就可以开始了！如果它显示0，则您的文件尚未包括在中。npy文件。检查<em class="mr"> /unet/data/npydata </em>中是否有以下文件:</p><ol class=""><li id="4d62" class="lh li ht jh b ji jj jm jn jq lj ju lk jy ll kc lm ln lo lp dt translated">imgs_mask_train.npy</li><li id="979f" class="lh li ht jh b ji lq jm lr jq ls ju lt jy lu kc lm ln lo lp dt translated">imgs_test.npy</li><li id="c5a3" class="lh li ht jh b ji lq jm lr jq ls ju lt jy lu kc lm ln lo lp dt translated">imgs_train.npy</li></ol><p id="51a6" class="pw-post-body-paragraph jf jg ht jh b ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc hm dt translated">喔喔喔！您已经完成了数据准备部分:)</p><figure class="lw lx ly lz fq iu fe ff paragraph-image"><div class="fe ff nf"><img src="../Images/7a81cdd262ca38b8d5d58aa922d56790.png" data-original-src="https://miro.medium.com/v2/resize:fit:692/format:webp/1*xWYQ_4yvBkVDm0na5ykKlg.png"/></div><figcaption class="jb jc fg fe ff jd je bd b be z ek">Fig4: Result on the ISBI cell tracking challenge- input and cyan mask</figcaption></figure><h1 id="d3b6" class="ke kf ht bd kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb dt translated">B部分-修改unet.py</h1><ol class=""><li id="3fef" class="lh li ht jh b ji lc jm ld jq mo ju mp jy mq kc lm ln lo lp dt translated">在unet文件夹中创建一个<strong class="jh hu"> <em class="mr">结果</em> </strong>文件夹(../unet/results)。如果你在想为什么你创造了这个-你马上就会知道为什么！</li></ol><p id="3f79" class="pw-post-body-paragraph jf jg ht jh b ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc hm dt translated">2.打开<strong class="jh hu"> <em class="mr"> unet.py </em> </strong>(。<em class="mr">。/unet/unet.py </em></p><p id="065d" class="pw-post-body-paragraph jf jg ht jh b ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc hm dt translated">3.编辑下一行的行数和列数。我的图片尺寸为256X256。</p><pre class="lw lx ly lz fq mv mw mx my aw mz dt"><span id="cfd9" class="ma kf ht mw b fv na nb l nc nd">def __init__(self, img_rows = 256, img_cols = 256):<br/> #Corresponds to line 13</span></pre><p id="45d2" class="pw-post-body-paragraph jf jg ht jh b ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc hm dt translated">4.在<em class="mr"> get_unet(self) </em>中，为3通道输入修改以下内容，如下所示。</p><pre class="lw lx ly lz fq mv mw mx my aw mz dt"><span id="d59d" class="ma kf ht mw b fv na nb l nc nd">def get_unet(self):<br/> inputs = Input((self.img_rows, self.img_cols,3))<br/> #Corresponds to line 27</span></pre><p id="e487" class="pw-post-body-paragraph jf jg ht jh b ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc hm dt translated">5.修改<em class="mr">列车(自)中的以下线路。</em></p><pre class="lw lx ly lz fq mv mw mx my aw mz dt"><span id="7583" class="ma kf ht mw b fv na nb l nc nd">def train(self):<br/>...<br/> np.save('<strong class="mw hu">/Users/sukritipaul/Dev/newcvtestpy2/unet2/results/imgs_mask_test.npy</strong>', imgs_mask_test)<br/>...<br/>#Note that the address to the <strong class="mw hu">results </strong>directory must be provided<br/>##Corresponds to line 164</span></pre><p id="116b" class="pw-post-body-paragraph jf jg ht jh b ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc hm dt translated">6.修改<em class="mr"> def save_img(self)，</em>记住结果目录的<strong class="jh hu"> <em class="mr">地址，如步骤4所述。</em> </strong></p><pre class="lw lx ly lz fq mv mw mx my aw mz dt"><span id="af93" class="ma kf ht mw b fv na nb l nc nd">def save_img(self):<br/> imgs = np.load('/Users/sukritipaul/Dev/newcvtestpy2/unet2/results/imgs_mask_test.npy') <strong class="mw hu"># Use the same address as above</strong><br/> img.save("/Users/sukritipaul/Dev/newcvtestpy2/unet2/results/%d.jpg"%(i)) #Saves the resulting segmented maps in /results<br/>##Corresponds to lines 169 and 173 </span></pre><p id="4902" class="pw-post-body-paragraph jf jg ht jh b ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc hm dt translated">7.运行<strong class="jh hu"> <em class="mr"> unet.py </em> </strong>并等待几分钟(根据数据集大小和系统硬件，您的训练时间可能需要几个小时)。</p><pre class="lw lx ly lz fq mv mw mx my aw mz dt"><span id="a352" class="ma kf ht mw b fv na nb l nc nd">$python unet.py</span></pre><h2 id="89d7" class="ma kf ht bd kg mb mc md kk me mf mg ko jq mh mi ks ju mj mk kw jy ml mm la mn dt translated">B部分-验证</h2><p id="2909" class="pw-post-body-paragraph jf jg ht jh b ji lc jk jl jm ld jo jp jq le js jt ju lf jw jx jy lg ka kb kc hm dt translated">访问<em class="mr"> /unet/results </em>和viola！可以找到生成的图像蒙版或灰度分割特征图:)</p><p id="2441" class="pw-post-body-paragraph jf jg ht jh b ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc hm dt translated">总之，我在65幅训练图像和10幅大小为256X256的验证图像上获得了90.71%的总体准确率。他们使用二元交叉熵作为损失函数。我花了大约3个小时在一台8 GB的MacBook Air上进行训练，它配备了1.8 GHz的英特尔酷睿i5处理器(CPU)。</p><p id="941a" class="pw-post-body-paragraph jf jg ht jh b ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc hm dt translated">请随意将您的疑问添加到评论中！:)</p><blockquote class="ng"><p id="92f5" class="nh ni ht bd nj nk nl nm nn no np kc ek translated">加入Coinmonks <a class="ae kd" href="https://t.me/coincodecap" rel="noopener ugc nofollow" target="_blank">电报频道</a>和<a class="ae kd" href="https://www.youtube.com/c/coinmonks/videos" rel="noopener ugc nofollow" target="_blank"> Youtube频道</a>获取每日<a class="ae kd" href="http://coincodecap.com/" rel="noopener ugc nofollow" target="_blank">加密新闻</a></p></blockquote><h2 id="15d6" class="ma kf ht bd kg mb nq md kk me nr mg ko jq ns mi ks ju nt mk kw jy nu mm la mn dt translated">另外，阅读</h2><ul class=""><li id="20fb" class="lh li ht jh b ji lc jm ld jq mo ju mp jy mq kc mu ln lo lp dt translated"><a class="ae kd" href="http://Top 4 Telegram Channels for Crypto Traders" rel="noopener ugc nofollow" target="_blank">密码电报信号</a> | <a class="ae kd" rel="noopener" href="/coinmonks/crypto-trading-bot-c2ffce8acb2a">密码交易机器人</a></li><li id="14e6" class="lh li ht jh b ji lq jm lr jq ls ju lt jy lu kc mu ln lo lp dt translated"><a class="ae kd" rel="noopener" href="/coinmonks/top-10-crypto-copy-trading-platforms-for-beginners-d0c37c7d698c">复制交易</a> | <a class="ae kd" rel="noopener" href="/coinmonks/crypto-tax-software-ed4b4810e338">加密税务软件</a></li><li id="723e" class="lh li ht jh b ji lq jm lr jq ls ju lt jy lu kc mu ln lo lp dt translated"><a class="ae kd" href="https://coincodecap.com/grid-trading" rel="noopener ugc nofollow" target="_blank">电网交易</a> | <a class="ae kd" rel="noopener" href="/coinmonks/the-best-cryptocurrency-hardware-wallets-of-2020-e28b1c124069">加密硬件钱包</a></li><li id="f33b" class="lh li ht jh b ji lq jm lr jq ls ju lt jy lu kc mu ln lo lp dt translated"><a class="ae kd" rel="noopener" href="/coinmonks/crypto-exchange-dd2f9d6f3769">加密交易所</a> | <a class="ae kd" rel="noopener" href="/coinmonks/buy-bitcoin-in-india-feb50ddfef94">印度的加密应用</a></li></ul></div></div>    
</body>
</html>