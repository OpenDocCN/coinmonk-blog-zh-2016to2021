# 虫洞:脸书的一个发布订阅系统

> 原文：<https://medium.com/coinmonks/wormhole-a-pub-sub-system-at-facebook-6274ea5fd11b?source=collection_archive---------2----------------------->

![](img/8485974626691ba72ec1109858fbf994.png)

A wormhole shortcut in space-time. Credit: [Shutterstock](http://www.shutterstock.com/)

## 介绍

发布-订阅系统有效地解决了交流系统变化的问题。每当某个数据发生更改时，发布服务器都会通知订阅服务器这一更改。在使用数据库存储状态的传统应用程序中，数据的生产者可以向数据库写入数据。为了收集这些更新，订阅者会面临这样的困境:要么以在一段时间内操作陈旧数据为代价不频繁地进行轮询，要么以数据库本身的性能开销为代价经常进行轮询。发布-订阅系统通常通过引入中间代理来解决这个问题。发布者向代理发布变更，并向代理订阅注册以获取变更通知。

在脸书，许多应用程序依赖于这样的更改通知。新闻订阅源可能想要接收最新的更新，朋友可能想要访问通知内容。此外，即使是内部系统，如索引修改或缓存失效，也可以通过了解底层数据的变化或使不再有效的数据失效而受益。这显然会在内部产生大量数据。这些数据被内部分割，并使用 RocksDB、HDFS、MySQL 等系统存储在许多集群中。对于脸书来说，使用这样一个基于代理的系统意味着代理需要支持脸书的内部系统，并扩展到非常高的容量，还需要大规模的复制。为了解决这些限制，脸书提出了一个叫做[虫洞](https://www.usenix.org/system/files/conference/nsdi15/nsdi15-paper-sharma.pdf)的新系统。

在虫洞中，用户直接向数据系统注册。所有数据系统都维护事务日志。Wormhole 使用这些日志来识别更新，然后将这些更新传播给订阅者。这是非常独特的，完全消除了对中间代理的需要，但这意味着发布者可能需要针对不同的数据系统进行专门化。在这篇文章中，我们将介绍虫洞的高级架构。

## 脸书对发布订阅系统的挑战

你可以想象，脸书产生了大量的数据。为了保证可靠性，这些数据被分片并跨数据中心进行地理复制。此外，facebook 还有许多数据系统，如 [Tao](/coinmonks/tao-facebooks-distributed-database-for-social-graph-c2b45f5346ea) 用于优化读取繁重的图形数据，以及 [memcache](https://www.usenix.org/system/files/conference/nsdi13/nsdi13-final170_update.pdf) 用于处理读取繁重的工作负载。这种系统使用主动缓存来卸载数据库访问。在写入时，需要使这些缓存副本失效，或者如果数据库上有索引，则需要重建索引。此外，发布-订阅系统可能需要支持以下内容:

1.  为了从同一个碎片交付更新
2.  至少交付一次—更新不会丢失，但可能会交付一些副本
3.  不同的消费者可能有不同的存储和消费速度的需求。
4.  像任何大型分布式系统一样，它需要容错，软件和硬件异常是常态。

## 体系结构

![](img/4fc88d4a80ca8f0a2b6a9d62911f86da.png)

Wormhole architecture with many-to-many mapping between publishers and subscriber shards.

Wormhole 由一个数据存储库组成，它可以满足 facebook 的需求。每一个这样的数据库，MySQL 或者 TAO 都运行一个发布者。这是虫洞出版商。这个发布者知道如何使用数据生产者写入事务日志的内容。然后，Publisher 将这种本机数据存储格式转换为标准化的键值格式，然后将其传递给订阅者。发布者通过读取 zookeeper(类似于 [chubby](/coinmonks/chubby-a-centralized-lock-service-for-distributed-applications-390571273052) 的分布式协调服务)的配置文件来找到订阅者。一个用户或应用程序得到一个客户端虫洞库，并向 zookeeper 注册。订阅者的一个有趣的方面是，对于一个给定的应用程序，存在多个订阅者，它们被发布者分配来处理整体数据的一些碎片。发布者将特定碎片的所有权分配给特定订阅者，然后将碎片的更新发送给相应的订阅者。对于给定的碎片，只要订阅服务器可用，所有的更新总是落在同一个订阅服务器上。发布者确保来自给定碎片的所有更新都按顺序交付给订阅者。

在这一点上介绍一些术语是有好处的，这些术语将在随后的章节中有用。

*数据存储*为数据集存储了一组*碎片*。

*流:*发布者发送给订阅者的每个分片的更新流。它包含每次更新中的碎片号。

*Datamarker* :表示用户最后成功确认的流。这是指向给定数据存储的事务日志的指针。发布者存储数据标记，以确保至少向订阅者传递一次数据。

*阅读器*:将事务日志中的内容传递给发布者的组件。下一节将详细解释。

*大篷车和领导者*:读者和关联流被称为大篷车。由于多个读取器可以同时读取事务日志，因此读取最远的读取器称为 lead caravan。

## 向订阅者传送更新

发布者读取 zookeeper 文件以发现哪些应用程序对更新感兴趣。对于每个碎片和应用对，它创建一个更新流，即 flow。一旦进入稳定状态，阅读器就从最新的位置开始阅读并发送更新。读取器有助于以有效的方式管理事务日志访问。进行恢复时，可能需要从多个数据标记(即日志中的位置)中读取数据。为了避免磁盘颠簸，阅读器可以更有效地管理数据访问。希望这解释了大篷车和领头大篷车的概念。

此外，发布者尽量不让订阅者不知所措。因此，发布者可以使用加权随机选择将给定的流发布给负载较轻的订阅者。此外，订阅者可以更新 zookeeper 文件，将负载转移给其他订阅者。一旦发布者在 caravan 和订阅者之间建立了流，所有的更新都通过 TCP 发送，以实现可靠的有序交付。虫洞还在同一连接上多路传输许多更新，以减少连接开销。

## 多个大篷车和慢速消费者

一般来说，领头大篷车满足大多数更新和最新的阅读。但是，无论是在恢复期间还是在有慢速消费者时，都需要多个车队来发送旧的更新。商队到流的分配取决于 I/O 负载与延迟要求。如果有很多大篷车，那么它们可以非常随意地访问磁盘，并导致严重的 I/O 负载。但是它们可以更快地解除阻止同一流程中的后续更新。另一方面，如果车队的数量较少，那么可以通过批处理磁盘访问来更好地优化 I/O 负载。但这可能会由于更长的队列而导致延迟增加，特别是对于较晚或最近的更新。虫洞允许商队根据这两个参数分裂和合并。通常情况下，非铅商队被要求以更快的速度阅读，以便赶上铅商队。还有一些配置限制，通过限制读取速度、车队数量等来避免过度使用磁盘。

## 过滤

一个很好的特性是让应用程序/订阅者指定它希望发布者过滤的内容。这可以通过使用简单和/或基于过滤规则的配置来完成。Publisher 不会将这些更新发送给订阅者应用程序。常见的滤镜类型有:*是特定范围内的键？key 有特定的值吗？这种成员查询的否定。*

## 单一发布者的可靠交付

可靠的传送对虫洞很重要，因为索引生成等关键过程依赖于它。缺少对索引的更新，显然会导致索引状态不一致。因此，虫洞发布者在向订阅者发送更新时使用数据标记。当客户端确认标记时，发布者将数据标记(事务日志中的偏移量)写入永久日志。如果发布者进程终止并重新启动，它可以从最后确认的数据标记开始读取，并从那里发送更新。这显然会导致重复，但是订户有责任处理重复。如果订阅者失败，那么发布者可以使用相同的机制从最后确认的标记发送更新。TCP 的使用确保了有序交付。

## 发布者故障转移的可靠交付

facebook 中的大部分数据都是地理复制的，以确保可靠性。订阅者可以注册数据集的多个副本。当 publisher 面临机器无法启动等硬故障时，另一个 publisher 需要帮助恢复。在这种模式下，wormhole 保证来自某个数据集的所有更新至少被传送一次。这带来了几个挑战。

当发布者遇到永久性故障时，通常存储在同一台机器上的所有数据标记也会变得不可用。此外，为了避免开销，发行商之间不进行通信。为了克服这些限制，wormhole 使用 zookeeper 来存储数据标记。

考虑以下地理复制数据库的图表。有两家出版商 P1 和 P2。P1 最初拥有 A1 的流量。随着 P1 更新 A1 用户，它正在 zookeeper 中存储数据标记。此外，每个发布者获得一个相应的临时节点，由其他发布者监视。分布式协作中的临时节点是指一旦节点的所有者离开，它就会消失。在这种情况下，一旦 P1 死亡，P1 短暂节点可能会消失，P2 将通过 Zookeepr API 得到通知。现在，P2 可以接管流的所有权，并开始通过存储的数据标记发布到 A1。这里的另一个实现细节是，数据标记是指向事务日志的指针，不能被 P2 直接使用。因此虫洞增加了逻辑偏移来帮助解决这个问题。

![](img/576f1c696e95c1c6f4f96207ec1f4577.png)

Publisher failover monitored by backup publishers that are watching ephemeral zookeeper nodes

一些操作上的改进包括使用分布式部署模型，在与发布者相同的机器上使用监视器，而不是集中式部署模型。此外，所有配置都是动态的，因此新配置生效并不总是需要重启过程。

## 可比的发布-订阅系统

大多数类似 Kafka、RabbitMQ 的发布-订阅系统都使用中间代理。这些代理可以根据消费者的速度存储和转发消息。脸书不需要这样做，因为他们的数据存储库已经保存了可靠的日志。此外，数据规模使得中间代理的开发同样具有挑战性，并可能增加额外的延迟。

Google 的 Thialfi 只处理版本号，用于数据失效。而虫洞可以用于数据填充，因为它发送数据更新。如果 broker 失败并且运行速度比 wormhole 慢一个数量级，Kafka 可能会丢失数据。Apache Hedwig 没有太多的发布者和订阅者。由于地理复制的限制，各种消息队列实现并不适合 facebook，或者它们不够通用。

## 结论

虽然更复杂，但 Wormhole 提供了一种非常独特和有效的机制，在数据密集和高吞吐量的环境中使用事务日志来实现发布-订阅系统，我发现这与传统的发布-订阅系统的实现方式非常不同。

> [在您的收件箱中直接获得最佳软件交易](https://coincodecap.com/?utm_source=coinmonks)

[![](img/7c0b3dfdcbfea594cc0ae7d4f9bf6fcb.png)](https://coincodecap.com/?utm_source=coinmonks)