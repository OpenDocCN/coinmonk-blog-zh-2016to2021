<html>
<head>
<title>Review: GoogLeNet (Inception v1)— Winner of ILSVRC 2014 (Image Classification)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">评论:Google net(Inception v1)——2014年ILSVRC(图像分类)获奖者</h1>
<blockquote>原文：<a href="https://medium.com/coinmonks/paper-review-of-googlenet-inception-v1-winner-of-ilsvlc-2014-image-classification-c2b3565a64e7?source=collection_archive---------0-----------------------#2018-08-24">https://medium.com/coinmonks/paper-review-of-googlenet-inception-v1-winner-of-ilsvlc-2014-image-classification-c2b3565a64e7?source=collection_archive---------0-----------------------#2018-08-24</a></blockquote><div><div class="ef hh hi hj hk hl"/><div class="hm hn ho hp hq"><div class=""/><p id="9603" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">在这个故事中，<strong class="is hu"> GoogLeNet [1] </strong>被回顾，它是图像分类竞赛<strong class="is hu"> ILSVRC ( </strong> <a class="ae jo" href="http://www.image-net.org/challenges/LSVRC/" rel="noopener ugc nofollow" target="_blank"> <strong class="is hu"> ImageNet大规模视觉识别竞赛</strong> </a> <strong class="is hu"> ) 2014 </strong>的冠军，比ZF net(2013年的冠军)【2】和AlexNet(2012年的冠军)【3】都有显著的提升，并且相对于VGGNet(2014年的亚军)【4】</p><p id="878a" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">从“<strong class="is hu"> GoogLe </strong> Net”这个名字，我们已经知道它来自GoogLe。而“Goog <strong class="is hu"> LeNet </strong>”也包含了“LeNet”一词，以此向颜乐存教授的LeNet [5]致敬。这是一篇<strong class="is hu"> 2015年CVPR </strong>的论文，有<strong class="is hu">大约9000次引用</strong>当我在写这个故事的时候。(<a class="jp jq gr" href="https://medium.com/u/aff72a0c1243?source=post_page-----c2b3565a64e7--------------------------------" rel="noopener" target="_blank"> Sik-Ho Tsang </a> @中)</p><p id="43e3" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">它也被称为<strong class="is hu"> Inception v1 </strong>，因为后来还有v2、v3和v4。</p><figure class="js jt ju jv fq jw fe ff paragraph-image"><div role="button" tabindex="0" class="jx jy di jz bf ka"><div class="fe ff jr"><img src="../Images/912693c956e1ebbff7e9019f0ff23d7a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_X6NzAnveK3QBT029X8D7Q.png"/></div></div><figcaption class="kd ke fg fe ff kf kg bd b be z ek"><strong class="bd kh">ILSVRC 2014 Error Rate (%)</strong></figcaption></figure><p id="c160" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">本文中的网络架构与VGGNet、ZFNet和AlexNet有很大不同。在网络中间包含<strong class="is hu"> 1×1卷积</strong>。并且<strong class="is hu">全局平均池</strong>在网络末端使用，而不是使用全连接层。这两种技术来自另一篇论文《网络中的网络》(NIN) [6]。另一种被称为<strong class="is hu">初始模块</strong>的技术是对相同的输入使用不同大小/类型的卷积，并堆叠所有的输出。</p><p id="210b" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">作者还提到“<strong class="is hu">盗梦空间</strong>”这个名字的想法来自NIN和下面一个著名的互联网模因:<strong class="is hu">我们需要更深入</strong>。</p><figure class="js jt ju jv fq jw fe ff paragraph-image"><div class="fe ff ki"><img src="../Images/a038c1e63e1b324afbeaf7d13dbf39bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/0*9oltTOaaHAbeLzeh.jpg"/></div><figcaption class="kd ke fg fe ff kf kg bd b be z ek"><strong class="bd kh">WE NEED TO GO DEEPER</strong></figcaption></figure><p id="c2d6" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">ImageNet是一个数据集，包含超过1500万张带有标签的高分辨率图像，大约有22，000个类别。ILSVRC在1000个类别中的每个类别中使用大约1000个图像的ImageNet子集。总的来说，大约有120万幅训练图像、50，000幅验证图像和100，000幅测试图像。</p></div><div class="ab cl kj kk hb kl" role="separator"><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko"/></div><div class="hm hn ho hp hq"><h1 id="91b0" class="kq kr ht bd ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln dt translated">我们将涵盖的内容:</h1><ol class=""><li id="43b1" class="lo lp ht is b it lq ix lr jb ls jf lt jj lu jn lv lw lx ly dt translated"><strong class="is hu">1×1卷积</strong></li><li id="c544" class="lo lp ht is b it lz ix ma jb mb jf mc jj md jn lv lw lx ly dt translated"><strong class="is hu">初始模块</strong></li><li id="5ca5" class="lo lp ht is b it lz ix ma jb mb jf mc jj md jn lv lw lx ly dt translated"><strong class="is hu">全球平均池</strong></li><li id="311e" class="lo lp ht is b it lz ix ma jb mb jf mc jj md jn lv lw lx ly dt translated"><strong class="is hu">整体架构</strong></li><li id="5e8e" class="lo lp ht is b it lz ix ma jb mb jf mc jj md jn lv lw lx ly dt translated"><strong class="is hu">用于训练的辅助分类器</strong></li><li id="96b7" class="lo lp ht is b it lz ix ma jb mb jf mc jj md jn lv lw lx ly dt translated"><strong class="is hu">测试细节</strong></li></ol></div><div class="ab cl kj kk hb kl" role="separator"><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko"/></div><div class="hm hn ho hp hq"><h1 id="6ae2" class="kq kr ht bd ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln dt translated"><strong class="ak"> 1。1×1卷积</strong></h1><p id="6358" class="pw-post-body-paragraph iq ir ht is b it lq iv iw ix lr iz ja jb me jd je jf mf jh ji jj mg jl jm jn hm dt translated">1×1卷积是由NIN [6]引入的。ReLU使用1×1卷积。因此，最初，NIN使用它来引入更多的非线性以增加网络的表示能力，因为NIN的作者认为数据是非线性形式的。<strong class="is hu">在GoogLeNet中，使用1×1卷积作为降维模块来减少计算量。通过减少计算瓶颈，可以增加深度和宽度。</strong></p><p id="d4a7" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">我举一个简单的例子来说明这一点。假设我们需要执行5×5卷积<strong class="is hu">而不使用1×1卷积</strong>，如下所示:</p><figure class="js jt ju jv fq jw fe ff paragraph-image"><div class="fe ff mh"><img src="../Images/b54e35a5946820c977046de9f185eb86.png" data-original-src="https://miro.medium.com/v2/resize:fit:844/format:webp/1*s6_8m_0EpwrzZPunRGgFCQ.png"/></div><figcaption class="kd ke fg fe ff kf kg bd b be z ek"><strong class="bd kh">Without the Use of 1×1 Convolution</strong></figcaption></figure><p id="fb59" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu">运算次数=(14×14×48)×(5×5×480)= 112.9米</strong></p><p id="90f6" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu">使用1×1卷积:</strong></p><figure class="js jt ju jv fq jw fe ff paragraph-image"><div class="fe ff mi"><img src="../Images/7e5398658f6b59f373b48ada57f99f19.png" data-original-src="https://miro.medium.com/v2/resize:fit:1366/format:webp/1*SJDJyBGM__wRX9wJYIKv8w.png"/></div><figcaption class="kd ke fg fe ff kf kg bd b be z ek"><strong class="bd kh">With the Use of 1×1 Convolution</strong></figcaption></figure><p id="6463" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu">1×1的运算次数=(14×14×16)×(1×1×480)= 1.5M<br/>5×5的运算次数=(14×14×48)×(5×5×16)= 3.8M</strong><br/><strong class="is hu">总运算次数= 1.5M + 3.8M = 5.3M <br/>远小于112.9M！！！！！！！！！！！！！！！</strong></p><p id="99f5" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">实际上，上面的例子是在初始阶段(4a)对<strong class="is hu"> 5×5 conv的计算。</strong></p><p id="d3fa" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">(我们可能认为，当维度降低时，实际上我们正在以非线性的方式进行从高维到低维的映射。相比之下，对于PCA，它执行线性降维。)</p><p id="2611" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">因此，<strong class="is hu">与没有1×1卷积的情况相比，在不增加运算次数的情况下</strong> <strong class="is hu">就可以建立起初始模块！</strong></p><blockquote class="mj"><p id="067c" class="mk ml ht bd mm mn mo mp mq mr ms jn ek translated"><strong class="ak"> 1×1卷积可以帮助减少模型大小，这也可以在某种程度上帮助减少过拟合问题！！</strong></p></blockquote></div><div class="ab cl kj kk hb kl" role="separator"><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko"/></div><div class="hm hn ho hp hq"><h1 id="fc20" class="kq kr ht bd ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln dt translated"><strong class="ak"> 2。初始模块</strong></h1><p id="1174" class="pw-post-body-paragraph iq ir ht is b it lq iv iw ix lr iz ja jb me jd je jf mf jh ji jj mg jl jm jn hm dt translated">初始模块(原始版本，无1×1卷积)如下所示:</p><figure class="js jt ju jv fq jw fe ff paragraph-image"><div class="fe ff mt"><img src="../Images/095a2f9a4b5ff7d865e38ce2ac723229.png" data-original-src="https://miro.medium.com/v2/resize:fit:1098/format:webp/1*m1wn5P5BFZydFgVd3RiZNw.png"/></div><figcaption class="kd ke fg fe ff kf kg bd b be z ek"><strong class="bd kh">Inception Module (Without 1×1 Convolution)</strong></figcaption></figure><p id="71b6" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">以前，如AlexNet和VGGNet，每层的conv大小是固定的。</p><p id="c516" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">现在，<strong class="is hu"> 1×1 conv </strong>、<strong class="is hu"> 3×3 conv </strong>、<strong class="is hu"> 5×5 conv </strong>、<strong class="is hu"> 3×3最大合并</strong>对之前的输入一起完成，在输出时再次叠加在一起。<strong class="is hu">当图像进入时，尝试不同大小的卷积以及最大池。然后提取不同种类的特征。</strong></p><p id="d6d5" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">之后，不同路径的所有特征图被连接在一起作为下一个模块的输入。</p><p id="97d6" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">但是，如果没有上面的1×1卷积，我们可以想象运算的次数有多大！</p><figure class="js jt ju jv fq jw fe ff paragraph-image"><div class="fe ff mu"><img src="../Images/9e732dc30f8f5b9404b80f7ee4303477.png" data-original-src="https://miro.medium.com/v2/resize:fit:1108/format:webp/1*sezFsYW1MyM9YOMa1q909A.png"/></div><figcaption class="kd ke fg fe ff kf kg bd b be z ek"><strong class="bd kh">Inception Module (With 1×1 Convolution)</strong></figcaption></figure><p id="8fb2" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">因此，1×1卷积被插入到初始模块中用于降维！</p></div><div class="ab cl kj kk hb kl" role="separator"><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko"/></div><div class="hm hn ho hp hq"><h1 id="81a6" class="kq kr ht bd ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln dt translated"><strong class="ak"> 3。全球平均池</strong></h1><figure class="js jt ju jv fq jw fe ff paragraph-image"><div role="button" tabindex="0" class="jx jy di jz bf ka"><div class="fe ff mv"><img src="../Images/9a6e59341748f276fde67239f716f403.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0-wMHcASLDFzx9YBRCZXHg.png"/></div></div><figcaption class="kd ke fg fe ff kf kg bd b be z ek"><strong class="bd kh">Fully Connected Layer VS Global Average Pooling</strong></figcaption></figure><p id="d42a" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">以前，<strong class="is hu">全连接(FC)层</strong>用于网络末端，比如在AlexNet中。所有输入都连接到每个输出。</p><p id="bf6a" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu">以上重量(连接)数= 7×7×1024×1024 = 51.3米</strong></p><p id="a43e" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu">在GoogLeNet中，全球平均池(global average pooling)几乎在网络</strong> <strong class="is hu">的末端使用，通过平均每个特征图从7×7到1×1，如上图所示。</strong></p><p id="2a8c" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu">重量数= 0 </strong></p><p id="4a4a" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">作者发现，从FC层转移到<strong class="is hu">平均池提高了前1名的准确度约0.6%。</strong></p><p id="493f" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">这是NIN [6]的想法，它不容易过度拟合。</p></div><div class="ab cl kj kk hb kl" role="separator"><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko"/></div><div class="hm hn ho hp hq"><h1 id="2b92" class="kq kr ht bd ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln dt translated"><strong class="ak"> 4。整体架构</strong></h1><p id="8d84" class="pw-post-body-paragraph iq ir ht is b it lq iv iw ix lr iz ja jb me jd je jf mf jh ji jj mg jl jm jn hm dt translated">了解了如上所述的基本单元后，我们就可以讨论整体网络架构了。</p><figure class="js jt ju jv fq jw fe ff paragraph-image"><div role="button" tabindex="0" class="jx jy di jz bf ka"><div class="fe ff mw"><img src="../Images/ff8ffec2f2627005907d76c35e358c68.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZFPOSAted10TPd3hBQU8iQ.png"/></div></div><figcaption class="kd ke fg fe ff kf kg bd b be z ek"><strong class="bd kh">GoogLeNet Network (From Left to Right)</strong></figcaption></figure><p id="ce04" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu">一共22层！</strong></p><p id="8e69" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">和之前的AlexNet，ZFNet，VGGNet相比已经是很深度的机型了。(但和后来发明的ResNet比起来没那么深。)并且我们可以看到<strong class="is hu">有许多连接在一起的初始模块可以更深入。</strong>(中间有一些中间的softmax分支，我们将在下一节描述它们。)</p><p id="bb36" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">下面是每一层的参数细节。我们实际上可以扩展1×1卷积的例子来自己计算运算次数。:)</p><figure class="js jt ju jv fq jw fe ff paragraph-image"><div role="button" tabindex="0" class="jx jy di jz bf ka"><div class="fe ff mx"><img src="../Images/e13b748395c0db4fcde56a96b938e00e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lRN3h9a_qJdT6NIy0VOu3Q.png"/></div></div><figcaption class="kd ke fg fe ff kf kg bd b be z ek"><strong class="bd kh">Details about Parameters of Each Layer in GoogLeNet Network (From Top to Bottom)</strong></figcaption></figure></div><div class="ab cl kj kk hb kl" role="separator"><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko"/></div><div class="hm hn ho hp hq"><h1 id="78f7" class="kq kr ht bd ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln dt translated"><strong class="ak"> 5。用于训练的辅助分类器</strong></h1><p id="4d3b" class="pw-post-body-paragraph iq ir ht is b it lq iv iw ix lr iz ja jb me jd je jf mf jh ji jj mg jl jm jn hm dt translated">如我们所见，在中间有一些中间softmax分支<strong class="is hu">,它们仅用于训练。这些分支是辅助分类器，包括:</strong></p><p id="8e0a" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">5×5平均池(步幅3) <br/> 1×1 Conv (128个过滤器)<br/>1024 FC<br/>1000 FC<br/>soft max</p><p id="1340" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">损失被添加到总损失中，权重为0.3。</p><p id="50d0" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">作者声称它可以用于解决梯度消失问题，还提供正则化。</p><p id="99d8" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">并且它不用于测试或推理时间。</p></div><div class="ab cl kj kk hb kl" role="separator"><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko"/></div><div class="hm hn ho hp hq"><h1 id="77ac" class="kq kr ht bd ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln dt translated">6。测试细节</h1><p id="cc65" class="pw-post-body-paragraph iq ir ht is b it lq iv iw ix lr iz ja jb me jd je jf mf jh ji jj mg jl jm jn hm dt translated">7个谷歌网用于集合预报。这已经是LeNet，AlexNet，ZFNet，VGGNet的一种助推方式了。</p><p id="3d15" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu">多尺度</strong> <strong class="is hu">测试</strong>使用方法与VGGNet一样，尺寸更短，为256、288、320、352。(4个刻度)</p><p id="48d0" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu">使用多作物测试</strong>，相同的想法，但与AlexNet稍有不同，且比Alex net更复杂。</p><p id="0138" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">首先，对于每个刻度，它需要左、中、右或上、中、下的正方形(3个正方形)。然后，对于每个正方形，裁剪4个角和中心以及调整大小的正方形(6次裁剪),并生成相应的翻转(2个版本)。</p><p id="cf66" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">总数为<strong class="is hu"> 4个比例×3个正方形×6个裁剪×2个版本=144个裁剪/图像</strong></p><p id="b7c8" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">Softmax概率是所有作物的平均值。</p><figure class="js jt ju jv fq jw fe ff paragraph-image"><div class="fe ff my"><img src="../Images/73511679a2534ff857777545b6ab7e6e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1212/format:webp/1*797bP-wph8ZswjKBspKsYg.png"/></div><figcaption class="kd ke fg fe ff kf kg bd b be z ek"><strong class="bd kh">Ablation Study</strong></figcaption></figure><p id="f80d" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu">用7个模型+ 144种作物，前5位误差为6.67%。</strong></p><p id="c443" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">与1个模型+ 1个作物相比，从10.07%下降了很多。</p><p id="4120" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">由此我们可以看出，<strong class="is hu">除了网络设计</strong>，其他东西如<strong class="is hu">集合方法、多尺度和多作物方法也是降低错误率的关键！！！</strong></p><p id="9bf5" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">实际上，这些技术在本文中并不是全新的！</p><figure class="js jt ju jv fq jw fe ff paragraph-image"><div class="fe ff mz"><img src="../Images/eaf0e56a597b5ac19e126c4fae6d71ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1266/format:webp/1*4L02Gx6OJirydhtygS-geg.png"/></div><figcaption class="kd ke fg fe ff kf kg bd b be z ek"><strong class="bd kh">Comparison with State-of-the-art Approaches</strong></figcaption></figure><p id="e6ea" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu">最后，GoogLeNet胜过之前的其他深度学习网络</strong>，在ILSVRC 2014中胜出。</p></div><div class="ab cl kj kk hb kl" role="separator"><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko"/></div><div class="hm hn ho hp hq"><p id="ebad" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">稍后，我将回顾其他深度学习网络以及inception版本。如果感兴趣，也请访问LeNet [7]、AlexNet [8]、ZFNet [9]和VGGNet [10]的评论。</p><h1 id="b64a" class="kq kr ht bd ks kt na kv kw kx nb kz la lb nc ld le lf nd lh li lj ne ll lm ln dt translated">参考</h1><ol class=""><li id="4359" class="lo lp ht is b it lq ix lr jb ls jf lt jj lu jn lv lw lx ly dt translated">【2015】【CVPR】【谷歌网】<br/> <a class="ae jo" href="https://www.cs.unc.edu/~wliu/papers/GoogLeNet.pdf" rel="noopener ugc nofollow" target="_blank">用回旋更深入</a></li><li id="d91a" class="lo lp ht is b it lz ix ma jb mb jf mc jj md jn lv lw lx ly dt translated">【2014 ECCV】【ZFNet】<br/><a class="ae jo" href="https://cs.nyu.edu/~fergus/papers/zeilerECCV2014.pdf" rel="noopener ugc nofollow" target="_blank">可视化和理解卷积网络</a></li><li id="36c4" class="lo lp ht is b it lz ix ma jb mb jf mc jj md jn lv lw lx ly dt translated">【2012 NIPS】【Alex net】<br/><a class="ae jo" href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf" rel="noopener ugc nofollow" target="_blank">使用深度卷积神经网络的ImageNet分类</a></li><li id="9148" class="lo lp ht is b it lz ix ma jb mb jf mc jj md jn lv lw lx ly dt translated">【2015 ICLR】【VGGNet】<br/><a class="ae jo" href="https://arxiv.org/pdf/1409.1556" rel="noopener ugc nofollow" target="_blank">用于大规模图像识别的极深度卷积网络</a></li><li id="6c56" class="lo lp ht is b it lz ix ma jb mb jf mc jj md jn lv lw lx ly dt translated">[1998年Proc。IEEE] [LeNet-1，LeNet-4，LeNet-5，Boosted LeNet-4] <br/> <a class="ae jo" href="http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf" rel="noopener ugc nofollow" target="_blank">基于梯度的学习应用于文档识别</a></li><li id="cc19" class="lo lp ht is b it lz ix ma jb mb jf mc jj md jn lv lw lx ly dt translated">【2014 ICLR】【宁】<br/> <a class="ae jo" href="https://arxiv.org/pdf/1312.4400.pdf" rel="noopener ugc nofollow" target="_blank">中网</a></li><li id="9aca" class="lo lp ht is b it lz ix ma jb mb jf mc jj md jn lv lw lx ly dt translated"><a class="ae jo" rel="noopener" href="/@sh.tsang/paper-brief-review-of-lenet-1-lenet-4-lenet-5-boosted-lenet-4-image-classification-1f5f809dbf17">审查LeNet-1、LeNet-4、LeNet-5、Boosted LeNet-4(图像分类)</a></li><li id="0a5a" class="lo lp ht is b it lz ix ma jb mb jf mc jj md jn lv lw lx ly dt translated"><a class="ae jo" rel="noopener" href="/coinmonks/paper-review-of-alexnet-caffenet-winner-in-ilsvrc-2012-image-classification-b93598314160">2012年ILSVRC(图像分类)获奖者AlexNet、CaffeNet点评</a></li><li id="97f2" class="lo lp ht is b it lz ix ma jb mb jf mc jj md jn lv lw lx ly dt translated"><a class="ae jo" rel="noopener" href="/coinmonks/paper-review-of-zfnet-the-winner-of-ilsvlc-2013-image-classification-d1a5a0c45103">2013年ILSVRC(图像分类)获奖者ZFNet点评</a></li><li id="7758" class="lo lp ht is b it lz ix ma jb mb jf mc jj md jn lv lw lx ly dt translated"><a class="ae jo" rel="noopener" href="/coinmonks/paper-review-of-vggnet-1st-runner-up-of-ilsvlc-2014-image-classification-d02355543a11">VG gnet回顾——ils VLC 2014(影像分类)亚军</a></li></ol><blockquote class="mj"><p id="061a" class="mk ml ht bd mm mn nf ng nh ni nj jn ek translated">加入Coinmonks <a class="ae jo" href="https://t.me/coincodecap" rel="noopener ugc nofollow" target="_blank">电报频道</a>和<a class="ae jo" href="https://www.youtube.com/c/coinmonks/videos" rel="noopener ugc nofollow" target="_blank"> Youtube频道</a>获取每日<a class="ae jo" href="http://coincodecap.com/" rel="noopener ugc nofollow" target="_blank">加密新闻</a></p></blockquote><h2 id="15d6" class="nk kr ht bd ks nl nm nn kw no np nq la jb nr ns le jf nt nu li jj nv nw lm nx dt translated">另外，阅读</h2><ul class=""><li id="20fb" class="lo lp ht is b it lq ix lr jb ls jf lt jj lu jn ny lw lx ly dt translated"><a class="ae jo" href="http://Top 4 Telegram Channels for Crypto Traders" rel="noopener ugc nofollow" target="_blank">密码电报信号</a> | <a class="ae jo" rel="noopener" href="/coinmonks/crypto-trading-bot-c2ffce8acb2a">密码交易机器人</a></li><li id="14e6" class="lo lp ht is b it lz ix ma jb mb jf mc jj md jn ny lw lx ly dt translated"><a class="ae jo" rel="noopener" href="/coinmonks/top-10-crypto-copy-trading-platforms-for-beginners-d0c37c7d698c">复制交易</a> | <a class="ae jo" rel="noopener" href="/coinmonks/crypto-tax-software-ed4b4810e338">加密税务软件</a></li><li id="723e" class="lo lp ht is b it lz ix ma jb mb jf mc jj md jn ny lw lx ly dt translated"><a class="ae jo" href="https://coincodecap.com/grid-trading" rel="noopener ugc nofollow" target="_blank">网格交易</a> | <a class="ae jo" rel="noopener" href="/coinmonks/the-best-cryptocurrency-hardware-wallets-of-2020-e28b1c124069">加密硬件钱包</a></li><li id="f33b" class="lo lp ht is b it lz ix ma jb mb jf mc jj md jn ny lw lx ly dt translated"><a class="ae jo" rel="noopener" href="/coinmonks/crypto-exchange-dd2f9d6f3769">印度的加密交易所</a> | <a class="ae jo" rel="noopener" href="/coinmonks/buy-bitcoin-in-india-feb50ddfef94">印度的加密应用</a></li><li id="47a8" class="lo lp ht is b it lz ix ma jb mb jf mc jj md jn ny lw lx ly dt translated">开发人员的最佳加密API</li><li id="ce0a" class="lo lp ht is b it lz ix ma jb mb jf mc jj md jn ny lw lx ly dt translated">最佳<a class="ae jo" rel="noopener" href="/coinmonks/top-5-crypto-lending-platforms-in-2020-that-you-need-to-know-a1b675cec3fa">加密贷款平台</a></li></ul></div></div>    
</body>
</html>