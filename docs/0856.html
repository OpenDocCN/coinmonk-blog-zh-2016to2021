<html>
<head>
<title>Automated Animal Identification Using Deep Learning Techniques</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用深度学习技术的自动动物识别</h1>
<blockquote>原文：<a href="https://medium.com/coinmonks/automated-animal-identification-using-deep-learning-techniques-41039f2a994d?source=collection_archive---------2-----------------------#2018-06-26">https://medium.com/coinmonks/automated-animal-identification-using-deep-learning-techniques-41039f2a994d?source=collection_archive---------2-----------------------#2018-06-26</a></blockquote><div><div class="ef hh hi hj hk hl"/><div class="hm hn ho hp hq"><div class=""/><figure class="fi fk ir is it iu fe ff paragraph-image"><div role="button" tabindex="0" class="iv iw di ix bf iy"><div class="fe ff iq"><img src="../Images/939b45f7dd25b25e8520bd6516ad479b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HQjbv10ZKSyrpuSrBG93lA.png"/></div></div></figure><p id="b831" class="pw-post-body-paragraph jb jc ht jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">拥有足够大的数据量为将深度学习方法应用于几乎任何任务提供了机会。近年来，我们已经看到了深度学习方法和技术的成功，尤其是在计算机视觉领域。如今，获取大量的图像数据并不是一个大问题，因为我们的相机以及系统的传输和存储能力都有了很大的提高。同时，标记如此大量的获得的数据需要巨大的人力努力，并且在某种程度上，它代表了解决某些特定问题的整个过程中的瓶颈。</p><p id="44cd" class="pw-post-body-paragraph jb jc ht jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">为了更好地了解野生动物生态系统，有必要对动物在自然生态系统中的位置和行为有详细、全面的了解。关于生态系统中动物状态的准确和最新信息对于研究和保护野生动物生态系统至关重要。在过去的几十年里，生态学家、生物学家和野生动物专家已经付出了巨大的努力来拯救野生动物，他们试图提高人们对野生动物和荒野重要性的认识。</p><p id="3c7b" class="pw-post-body-paragraph jb jc ht jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">生态学家和生物学家获取野生动物信息的一种常用方法是照相机捕捉项目。在野外的特定位置放置大量的摄像机使他们能够研究动物的数量和分布。然而，由于分析来自相机陷阱项目的图像需要人力，专家只能从他们拥有的大量数据中提取很少有价值的信息。</p><figure class="jz ka kb kc fq iu fe ff paragraph-image"><div class="ab fr cl kd"><img src="../Images/746294e2488ca8803bf6b831477f6444.png" data-original-src="https://miro.medium.com/v2/format:webp/1*YIKUqDqB0mIIm9x3Zjk_2Q.png"/></div><figcaption class="ke kf fg fe ff kg kh bd b be z ek">The cover page of PNAS Journal for June 2018 presenting this work.</figcaption></figure><p id="05db" class="pw-post-body-paragraph jb jc ht jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">怀俄明大学研究人员的共同努力；奥本大学、哈佛大学、牛津大学、明尼苏达大学、优步人工智能实验室已经产生了一种从相机捕捉的图像中自动识别动物的<a class="ae ki" href="http://www.pnas.org/content/pnas/115/25/E5716.full.pdf" rel="noopener ugc nofollow" target="_blank"><strong class="jd hu"/></a><strong class="jd hu">的精确方法。</strong>研究人员使用深度学习技术和大型标记数据集来解决在野外自动识别动物的问题。</p><p id="0b40" class="pw-post-body-paragraph jb jc ht jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">这个项目的目标是应用深度学习，能够识别、计数和描述动物物种的行为。根据这个定义，这个问题可以被框架为使用来自相机陷阱项目的图像的多任务学习问题。研究人员认为上面提到的任务是相关的，并且所有任务都有共同的特征，他们通过一起学习来解决这个问题。他们还认为，通过这样做，可以更快、更有效地解决任务，并且可以更容易地存储和传输模型。</p><h1 id="aa3c" class="kj kk ht bd kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg dt translated">资料组</h1><p id="5bfe" class="pw-post-body-paragraph jb jc ht jd b je lh jg jh ji li jk jl jm lj jo jp jq lk js jt ju ll jw jx jy hm dt translated">研究人员使用了来自世界上最大的相机陷阱项目 的<a class="ae ki" href="https://www.nature.com/articles/sdata201526" rel="noopener ugc nofollow" target="_blank"> <strong class="jd hu">快照塞伦盖蒂项目的大规模标记数据集。这个项目在坦桑尼亚的<em class="lm">塞伦盖蒂国家公园</em>有225个连续运行的摄像陷阱。<br/>本项目中使用的公共Serengeti数据集包含320万幅图像，对应于120万个捕捉事件(<strong class="jd hu">注</strong> : <em class="lm">一个捕捉事件代表相机识别运动和拍摄几张照片的时刻</em>)。在这个项目中，研究人员专注于捕捉只包含一个物种的事件，他们从数据集中删除了包含多个物种的事件。</strong></a></p><p id="ffa4" class="pw-post-body-paragraph jb jc ht jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">因为大多数时候，捕捉事件被触发，并且没有动物出现，所以大多数图像不包含任何动物。从人类的标签来看，75%的数据集是空的(不包括动物)。值得一提的是，该数据集是由志愿者标记的，他们实际上标记了整个捕捉事件(不仅仅是单个图像！).在这种方法中，作者专注于对单个图像进行标记和分类。为此，他们获取每个捕获事件的标签，并将其分配给所有单独的图像。</p><p id="f710" class="pw-post-body-paragraph jb jc ht jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">然而，采用这种方法可能对学习过程有潜在的危害，因为从事件转移到单个图像的标签可能经常不对应。在论文中，他们认为添加这种“<em class="lm">噪声</em>”可以被神经网络克服。</p><h2 id="307a" class="ln kk ht bd kl lo lp lq kp lr ls lt kt jm lu lv kx jq lw lx lb ju ly lz lf ma dt translated">测试装置</h2><p id="1a19" class="pw-post-body-paragraph jb jc ht jd b je lh jg jh ji li jk jl jm lj jo jp jq lk js jt ju ll jw jx jy hm dt translated">为了评估模型，作者创建了两个测试集:包含3800个捕获事件的专家标记的测试集和包含17400个捕获事件的志愿者标记的测试集。</p><h1 id="c929" class="kj kk ht bd kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg dt translated">方法</h1><p id="6de1" class="pw-post-body-paragraph jb jc ht jd b je lh jg jh ji li jk jl jm lj jo jp jq lk js jt ju ll jw jx jy hm dt translated">研究人员在利用两阶段管道以两阶段方式解决问题时考虑到了这一点:</p><ul class=""><li id="020b" class="mb mc ht jd b je jf ji jj jm md jq me ju mf jy mg mh mi mj dt translated"><strong class="jd hu">检测动物的存在</strong>(解决空对动物任务)</li><li id="1ce1" class="mb mc ht jd b je mk ji ml jm mm jq mn ju mo jy mg mh mi mj dt translated">(II) <strong class="jd hu">识别存在哪个物种</strong>，</li><li id="2639" class="mb mc ht jd b je mk ji ml jm mm jq mn ju mo jy mg mh mi mj dt translated">(III) <strong class="jd hu">计算动物数量</strong>，以及</li><li id="4be6" class="mb mc ht jd b je mk ji ml jm mm jq mn ju mo jy mg mh mi mj dt translated">(IV) <strong class="jd hu">描述附加的动物属性</strong>(它们的行为和幼仔是否存在)。</li></ul><p id="b317" class="pw-post-body-paragraph jb jc ht jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">为了执行这两个主要任务以及信息提取任务中定义的子任务，研究人员训练了一个模型。事实上，在整个项目中，他们研究了不同的深度神经网络架构，以找到最适合在自动动物识别背景下进行多任务学习的架构。</p><figure class="jz ka kb kc fq iu fe ff paragraph-image"><div class="ab fr cl kd"><img src="../Images/377595fc03c5e20334ca27660560875d.png" data-original-src="https://miro.medium.com/v2/format:webp/1*XqReKd6ejOlXDHy35b3k6w.png"/></div><figcaption class="ke kf fg fe ff kg kh bd b be z ek">Gradually converting raw data into more abstract concepts.</figcaption></figure><figure class="jz ka kb kc fq iu fe ff paragraph-image"><div class="ab fr cl kd"><img src="../Images/c70b9b6f4b3c38294a7276270e6fe376.png" data-original-src="https://miro.medium.com/v2/format:webp/1*xh7ougLy1h9FwhMtkxddcA.png"/></div><figcaption class="ke kf fg fe ff kg kh bd b be z ek">Description of some of the most popular Deep Neural Network architectures, also used in this project.</figcaption></figure><h2 id="ee47" class="ln kk ht bd kl lo lp lq kp lr ls lt kt jm lu lv kx jq lw lx lb ju ly lz lf ma dt translated">任务一:检测包含动物的图像</h2><p id="0568" class="pw-post-body-paragraph jb jc ht jd b je lh jg jh ji li jk jl jm lj jo jp jq lk js jt ju ll jw jx jy hm dt translated">第一项任务是最容易的。这是一种二元分类，在这种情况下出现的唯一问题是明显的阶级不平衡。为了解决这个问题，他们采用了<em class="lm"> 25% </em>的非空图像，并且他们从剩余的<em class="lm"> 75% </em>的空图像中随机选择了相同数量的数据。这样，他们最终得到了150万张图片，其中140万张用于训练，10万张用于测试。正如他们报告的那样，所有分类器在这项任务上都达到了超过<em class="lm"> 95.8% </em>的准确率，其中VGG是最好的模型，达到了<strong class="jd hu"> 96.8%。</strong></p><figure class="jz ka kb kc fq iu fe ff paragraph-image"><div class="ab fr cl kd"><img src="../Images/5b9aaf428a5cd996ae44e544c0878cce.png" data-original-src="https://miro.medium.com/v2/format:webp/1*kpouS6X_8F4pgEdR7ZPDfg.png"/></div><figcaption class="ke kf fg fe ff kg kh bd b be z ek">Evaluation of different models and the ensemble of all of them.</figcaption></figure><h2 id="44c1" class="ln kk ht bd kl lo lp lq kp lr ls lt kt jm lu lv kx jq lw lx lb ju ly lz lf ma dt translated">任务二:识别物种</h2><p id="4abf" class="pw-post-body-paragraph jb jc ht jd b je lh jg jh ji li jk jl jm lj jo jp jq lk js jt ju ll jw jx jy hm dt translated">对于这项任务，作者报告了多标签分类的前1名和前5名准确性，其中48个类别对应于训练数据集中存在的48个物种。最终模型达到前5名准确率的<em class="lm"> 99.1% </em>。事实上，他们用于识别物种这一特定任务的方法是集成学习——通过对多个模型的所有预测进行平均来获得预测。在专家标记的测试集上评估，该方法具有<em class="lm"> 94.9% </em> top-1和<strong class="jd hu"> <em class="lm"> 99.1% </em> </strong> top-5的准确率(其中最好的单个模型是ResNet-152，获得了<em class="lm"> 93.8% </em> top-1和<em class="lm"> 98.8% </em> top-5的准确率。</p><figure class="jz ka kb kc fq iu fe ff paragraph-image"><div class="ab fr cl kd"><img src="../Images/b58b2e228d2a6bf5297e429806bcf50d.png" data-original-src="https://miro.medium.com/v2/format:webp/1*g_X3xKGGth5n1Z60YPykIQ.png"/></div><figcaption class="ke kf fg fe ff kg kh bd b be z ek">Top-1 and top-5 accuracy of different models on the task of identifying the species of animal present in the image.</figcaption></figure><h2 id="6c60" class="ln kk ht bd kl lo lp lq kp lr ls lt kt jm lu lv kx jq lw lx lb ju ly lz lf ma dt translated">任务三:数动物</h2><p id="3c56" class="pw-post-body-paragraph jb jc ht jd b je lh jg jh ji li jk jl jm lj jo jp jq lk js jt ju ll jw jx jy hm dt translated">为了解决这个问题，研究人员将可能的答案空间分成12个箱，分别对应于1、2、3、4、5、6、7、8、9、10、11–50或+51个人。对于这项任务，通过专家标记的测试集上的模型集成，他们获得了63.1%的顶级准确性和84.7%的预测在+/- 1箱内。</p><h2 id="0b86" class="ln kk ht bd kl lo lp lq kp lr ls lt kt jm lu lv kx jq lw lx lb ju ly lz lf ma dt translated">任务四:动物行为和附加属性</h2><p id="b838" class="pw-post-body-paragraph jb jc ht jd b je lh jg jh ji li jk jl jm lj jo jp jq lk js jt ju ll jw jx jy hm dt translated">塞伦盖蒂数据集包含6个不相互排斥的标签，定义了图像中动物的行为:站立、休息、移动、进食、互动以及幼仔是否存在。</p><p id="4526" class="pw-post-body-paragraph jb jc ht jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">二元分类解决了由于每个标签的分类问题的非排他性而具有多个标签的可能性(预测该行为是否存在于图像中)。综合所有属性，模型的集合产生了76.2%的准确度、86.1%的精确度和81.1%的召回率。</p><figure class="jz ka kb kc fq iu fe ff paragraph-image"><div role="button" tabindex="0" class="iv iw di ix bf iy"><div class="fe ff mp"><img src="../Images/cc7b85232c14aac1da6f8a42173ecd8c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NUv7ptXvZRuVWh_UJxnBKQ.png"/></div></div></figure><figure class="jz ka kb kc fq iu fe ff paragraph-image"><div role="button" tabindex="0" class="iv iw di ix bf iy"><div class="fe ff mq"><img src="../Images/b1195aaf5bf088f47a6be42d43aa9005.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*d0IxHChqkamv1yav88PK9Q.png"/></div></div></figure><h1 id="6805" class="kj kk ht bd kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg dt translated">结论</h1><p id="f538" class="pw-post-body-paragraph jb jc ht jd b je lh jg jh ji li jk jl jm lj jo jp jq lk js jt ju ll jw jx jy hm dt translated">这项工作表明，深度学习技术可以用于许多领域的问题，它们可以帮助从大量数据中提取大量信息。这是深度学习非常有用的一个用例，可以帮助生物学家和生态学家等专家研究和保护野生动物。</p><p id="6a1a" class="pw-post-body-paragraph jb jc ht jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated"><a class="ae ki" rel="noopener" href="/@mitrevdane">T21【戴恩】米特列夫T23】</a></p><blockquote class="mr"><p id="b5ba" class="ms mt ht bd mu mv mw mx my mz na jy ek translated">加入Coinmonks <a class="ae ki" href="https://t.me/coincodecap" rel="noopener ugc nofollow" target="_blank">电报频道</a>和<a class="ae ki" href="https://www.youtube.com/c/coinmonks/videos" rel="noopener ugc nofollow" target="_blank"> Youtube频道</a>获取每日<a class="ae ki" href="http://coincodecap.com/" rel="noopener ugc nofollow" target="_blank">加密新闻</a></p></blockquote><h2 id="15d6" class="ln kk ht bd kl lo nb lq kp lr nc lt kt jm nd lv kx jq ne lx lb ju nf lz lf ma dt translated">另外，阅读</h2><ul class=""><li id="20fb" class="mb mc ht jd b je lh ji li jm ng jq nh ju ni jy mg mh mi mj dt translated"><a class="ae ki" rel="noopener" href="/coinmonks/top-10-crypto-copy-trading-platforms-for-beginners-d0c37c7d698c">复制交易</a> | <a class="ae ki" rel="noopener" href="/coinmonks/crypto-tax-software-ed4b4810e338">加密税务软件</a></li><li id="723e" class="mb mc ht jd b je mk ji ml jm mm jq mn ju mo jy mg mh mi mj dt translated"><a class="ae ki" href="https://coincodecap.com/grid-trading" rel="noopener ugc nofollow" target="_blank">网格交易</a> | <a class="ae ki" rel="noopener" href="/coinmonks/the-best-cryptocurrency-hardware-wallets-of-2020-e28b1c124069">加密硬件钱包</a></li><li id="874f" class="mb mc ht jd b je mk ji ml jm mm jq mn ju mo jy mg mh mi mj dt translated"><a class="ae ki" href="http://Top 4 Telegram Channels for Crypto Traders" rel="noopener ugc nofollow" target="_blank">密码电报信号</a> | <a class="ae ki" rel="noopener" href="/coinmonks/crypto-trading-bot-c2ffce8acb2a">密码交易机器人</a></li><li id="50d2" class="mb mc ht jd b je mk ji ml jm mm jq mn ju mo jy mg mh mi mj dt translated"><a class="ae ki" rel="noopener" href="/coinmonks/binance-trading-bots-d0d57bb62c4c">币安交易机器人</a> | <a class="ae ki" rel="noopener" href="/coinmonks/okex-review-6b369304110f"> OKEx评论</a> | <a class="ae ki" href="https://coincodecap.com/atani-review" rel="noopener ugc nofollow" target="_blank">阿塔尼评论</a></li><li id="3b1f" class="mb mc ht jd b je mk ji ml jm mm jq mn ju mo jy mg mh mi mj dt translated"><a class="ae ki" rel="noopener" href="/coinmonks/best-crypto-signals-telegram-5785cdbc4b2b">最佳加密交易信号电报</a> | <a class="ae ki" rel="noopener" href="/coinmonks/moonxbt-review-6e4ab26d037"> MoonXBT评论</a></li><li id="c44c" class="mb mc ht jd b je mk ji ml jm mm jq mn ju mo jy mg mh mi mj dt translated">如何在Bitbns上购买柴犬(SHIB)币？ | <a class="ae ki" href="https://coincodecap.com/buy-floki-inu-token" rel="noopener ugc nofollow" target="_blank">买弗洛基</a></li><li id="af80" class="mb mc ht jd b je mk ji ml jm mm jq mn ju mo jy mg mh mi mj dt translated"><a class="ae ki" href="https://coincodecap.com/coinflex-review" rel="noopener ugc nofollow" target="_blank"> CoinFLEX评论</a> | <a class="ae ki" href="https://coincodecap.com/aex-exchange-review" rel="noopener ugc nofollow" target="_blank"> AEX交易所评论</a> | <a class="ae ki" href="https://coincodecap.com/upbit-review" rel="noopener ugc nofollow" target="_blank"> UPbit评论</a></li><li id="29b5" class="mb mc ht jd b je mk ji ml jm mm jq mn ju mo jy mg mh mi mj dt translated"><a class="ae ki" href="https://coincodecap.com/best-cryptocurrency-blogs" rel="noopener ugc nofollow" target="_blank">十大最佳加密货币博客</a> | <a class="ae ki" href="https://coincodecap.com/youhodler-review" rel="noopener ugc nofollow" target="_blank"> YouHodler评论</a></li><li id="f33b" class="mb mc ht jd b je mk ji ml jm mm jq mn ju mo jy mg mh mi mj dt translated"><a class="ae ki" rel="noopener" href="/coinmonks/crypto-exchange-dd2f9d6f3769">最佳加密交易所</a> | <a class="ae ki" rel="noopener" href="/coinmonks/bitcoin-exchange-in-india-7f1fe79715c9">最佳加密交易所</a></li><li id="47a8" class="mb mc ht jd b je mk ji ml jm mm jq mn ju mo jy mg mh mi mj dt translated">面向开发者的最佳加密API</li><li id="b359" class="mb mc ht jd b je mk ji ml jm mm jq mn ju mo jy mg mh mi mj dt translated">最佳<a class="ae ki" rel="noopener" href="/coinmonks/top-5-crypto-lending-platforms-in-2020-that-you-need-to-know-a1b675cec3fa">密码借贷平台</a></li><li id="3c98" class="mb mc ht jd b je mk ji ml jm mm jq mn ju mo jy mg mh mi mj dt translated"><a class="ae ki" rel="noopener" href="/coinmonks/free-crypto-signals-48b25e61a8da">免费加密信号</a> | <a class="ae ki" rel="noopener" href="/coinmonks/crypto-trading-bot-c2ffce8acb2a">加密交易机器人</a></li><li id="9487" class="mb mc ht jd b je mk ji ml jm mm jq mn ju mo jy mg mh mi mj dt translated"><a class="ae ki" rel="noopener" href="/coinmonks/leveraged-token-3f5257808b22">杠杆代币</a>终极指南</li></ul></div></div>    
</body>
</html>