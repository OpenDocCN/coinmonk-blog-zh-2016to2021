<html>
<head>
<title>Tensorflow: A Conceptual Introduction</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">张量流:概念介绍</h1>
<blockquote>原文：<a href="https://medium.com/coinmonks/tensorflow-a-conceptual-introduction-bc35a6267e41?source=collection_archive---------8-----------------------#2018-08-13">https://medium.com/coinmonks/tensorflow-a-conceptual-introduction-bc35a6267e41?source=collection_archive---------8-----------------------#2018-08-13</a></blockquote><div><div class="ef hh hi hj hk hl"/><div class="hm hn ho hp hq"><div class=""/><div class=""><h2 id="3a12" class="pw-subtitle-paragraph iq hs ht bd b ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ek translated">张量流背后核心概念的说明性介绍。</h2></div><h1 id="fdd2" class="ji jj ht bd jk jl jm jn jo jp jq jr js iz jt ja ju jc jv jd jw jf jx jg jy jz dt translated">什么是张量流</h1><p id="5772" class="pw-post-body-paragraph ka kb ht kc b kd ke iu kf kg kh ix ki kj kk kl km kn ko kp kq kr ks kt ku kv hm dt translated">TensorFlow (TF)是一个开源的数值计算框架，提供了常用的机器学习(ML)和深度学习(DL)工具的抽象，以及构建新模型、优化器、损失函数等的能力。与无数的其他ML/DL库不同，TensorFlow在研究所需的灵活性和在生产中部署应用程序所需的可伸缩性和效率之间提供了关键的平衡。</p><p id="d001" class="pw-post-body-paragraph ka kb ht kc b kd kw iu kf kg kx ix ki kj ky kl km kn kz kp kq kr la kt ku kv hm dt translated">TF框架使用两个基本概念:</p><ol class=""><li id="e26a" class="lb lc ht kc b kd kw kg kx kj ld kn le kr lf kv lg lh li lj dt translated">数据流编程范例</li><li id="0cc2" class="lb lc ht kc b kd lk kg ll kj lm kn ln kr lo kv lg lh li lj dt translated">将数据封装为张量</li></ol><h1 id="6d63" class="ji jj ht bd jk jl jm jn jo jp jq jr js iz jt ja ju jc jv jd jw jf jx jg jy jz dt translated">数据流编程范例</h1><p id="7275" class="pw-post-body-paragraph ka kb ht kc b kd ke iu kf kg kh ix ki kj kk kl km kn ko kp kq kr ks kt ku kv hm dt translated">大多数程序员接触到的编程范例是<a class="ae lp" href="https://en.wikipedia.org/wiki/Imperative_programming" rel="noopener ugc nofollow" target="_blank">命令式编程</a>。这里的代码是一个命令序列，其中控制以有序的方式流过代码，以生成所需的输出。命令式程序的主要焦点是关于接下来需要执行什么语句，而不是所述执行需要什么数据。更简洁地说，<em class="lq">命令式编程是控制流而不是数据流。</em></p><p id="9aa5" class="pw-post-body-paragraph ka kb ht kc b kd kw iu kf kg kx ix ki kj ky kl km kn kz kp kq kr la kt ku kv hm dt translated">在<a class="ae lp" href="https://en.wikipedia.org/wiki/Dataflow_programming" rel="noopener ugc nofollow" target="_blank">数据流编程</a>中，代码是需要执行的操作定义的集合。一个<em class="lq">操作</em>可以是简单的两个数相加，来执行一个复杂的优化程序。操作可以依赖于一些输入数据，或者依赖于其他操作的输出(独立的情况是没有意思的)。评估一个操作的主要要求是其所有输入的可用性，使其对数据做出反应，因此得名:<em class="lq">数据流</em>。</p><h1 id="fc54" class="ji jj ht bd jk jl jm jn jo jp jq jr js iz jt ja ju jc jv jd jw jf jx jg jy jz dt translated">数据流和张量流</h1><p id="b845" class="pw-post-body-paragraph ka kb ht kc b kd ke iu kf kg kh ix ki kj kk kl km kn ko kp kq kr ks kt ku kv hm dt translated">数据流程序的代码通常被视为有向图，其节点是操作，传入的边表示在操作之间流动的数据。因此，任何TF应用程序的第一步都是建立数据流图。例如，要在TF中添加两个数字，我们通过将操作定义为图节点，将对其他操作的依赖定义为边来构建图。下图中的三行TF代码正是这样做的。第<code class="eh lr ls lt lu b">1</code>行和第<code class="eh lr ls lt lu b">2</code>行定义了保存数据的操作，从而创建了蓝色和绿色节点。行<code class="eh lr ls lt lu b">3</code>定义了<code class="eh lr ls lt lu b">add</code>操作，因为它使用<code class="eh lr ls lt lu b">ip1_op</code>和<code class="eh lr ls lt lu b">ip2_op</code>作为op的参数，所以创建了红色节点和两条红色边。需要注意的重要一点是，此时对<code class="eh lr ls lt lu b">3+5</code>的实际评估还没有发生，只是构建了图形。</p><figure class="lw lx ly lz fq ma fe ff paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="fe ff lv"><img src="../Images/49c90c439397dda94354e8416ee17965.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*BxdE-bhu9gNy-cjL.png"/></div></div></figure><p id="6b28" class="pw-post-body-paragraph ka kb ht kc b kd kw iu kf kg kx ix ki kj ky kl km kn kz kp kq kr la kt ku kv hm dt translated">在数据流编程范例中，<em class="lq">执行</em>的概念被视为当数据流经一个有向图时对它的评估。在TF中，我们评估节点，而不是直接执行图形。由于节点有依赖关系，我们最终只评估由这些依赖关系引起的子图。如下图所示，<code class="eh lr ls lt lu b">add</code>节点的评估将导致保存在<code class="eh lr ls lt lu b">input1</code>和<code class="eh lr ls lt lu b">input2</code>节点(此处为<code class="eh lr ls lt lu b">3</code>和<code class="eh lr ls lt lu b">5</code>)中的数据流向<code class="eh lr ls lt lu b">add</code>节点。因为现在满足了<code class="eh lr ls lt lu b">add</code>节点的所有依赖关系，所以它继续进行自我评估，即计算<code class="eh lr ls lt lu b">3+5=8</code>。因此，在TF的说法中，我们说节点<code class="eh lr ls lt lu b">add</code>评估为<code class="eh lr ls lt lu b">8</code>。同样，当我们评估<code class="eh lr ls lt lu b">pow</code>节点时，首先评估依赖节点<code class="eh lr ls lt lu b">add</code>和<code class="eh lr ls lt lu b">sqrt</code>，然后<code class="eh lr ls lt lu b">pow</code>节点拥有评估自身所需的数据。</p><figure class="lw lx ly lz fq ma fe ff paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="fe ff mh"><img src="../Images/4ab7afde874ce193abe36b7bd0caa5ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*_FTuDChLhkaYUrq5.png"/></div></div></figure><h1 id="d3b5" class="ji jj ht bd jk jl jm jn jo jp jq jr js iz jt ja ju jc jv jd jw jf jx jg jy jz dt translated">图形评估</h1><p id="e7af" class="pw-post-body-paragraph ka kb ht kc b kd ke iu kf kg kh ix ki kj kk kl km kn ko kp kq kr ks kt ku kv hm dt translated">为了评估节点，我们使用了一个<code class="eh lr ls lt lu b">tf.Session</code>对象。一个会话对象充当一个容器，将一个图的执行环境上下文化。人们可以将会话视为数据流图的执行引擎——待评估的节点被发送到会话，它评估归纳的子图，并输出一个输出。代码执行的实际物理位置，即CPU、GPU、<a class="ae lp" href="https://en.wikipedia.org/wiki/Tensor_processing_unit" rel="noopener ugc nofollow" target="_blank"> TPUs </a>、分布式云等。由会话对象管理。也就是说，我们可以灵活地指定在哪里执行某些操作。我们将在以后的文章中介绍更高级的图形执行方法。</p><figure class="lw lx ly lz fq ma fe ff paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="fe ff mh"><img src="../Images/80a8e02806509ba0cae8fd99513046ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*judKT5O9WGrnKSVP.png"/></div></div></figure><h1 id="bbd8" class="ji jj ht bd jk jl jm jn jo jp jq jr js iz jt ja ju jc jv jd jw jf jx jg jy jz dt translated">为什么使用数据流范式？</h1><p id="f91b" class="pw-post-body-paragraph ka kb ht kc b kd ke iu kf kg kh ix ki kj kk kl km kn ko kp kq kr ks kt ku kv hm dt translated">许多ML/DL模型(神经网络、图形模型等。)被表示为图形，用于可视化它们的理论定义。使用图作为这种模型的计算模型是一种自然的扩展。此外，使用图来建模ML/DL问题也有许多计算优势。例如，操作(节点)的计算只需要执行连接到该操作的子图，从而节省了计算时间。这也允许将计算分成更小的片段，便于分布式计算(将计算分散到不同的CPU、GPU、TPU等。).</p><p id="b84c" class="pw-post-body-paragraph ka kb ht kc b kd kw iu kf kg kx ix ki kj ky kl km kn kz kp kq kr la kt ku kv hm dt translated">大多数ML/DL应用程序都有一个优化器组件，它经常使用基于梯度的方法来最小化损失函数。传统上，损失函数的梯度是手动计算的，并提供给优化器——这是一项繁琐的工作，有时本身就是一个难题。通过将模型表示为图形，我们可以方便地使用<a class="ae lp" href="https://en.wikipedia.org/wiki/Automatic_differentiation" rel="noopener ugc nofollow" target="_blank">自动微分</a>来消除推导和实现梯度函数的手动步骤。</p><h1 id="0f43" class="ji jj ht bd jk jl jm jn jo jp jq jr js iz jt ja ju jc jv jd jw jf jx jg jy jz dt translated">将数据封装为张量</h1><p id="dfc8" class="pw-post-body-paragraph ka kb ht kc b kd ke iu kf kg kh ix ki kj kk kl km kn ko kp kq kr ks kt ku kv hm dt translated">张量是一个数学对象，表示为一个多维数组。根据上下文，它可能意味着许多事情。例如，张量可以是向量、标量甚至其他张量之间的<a class="ae lp" href="https://en.wikipedia.org/wiki/Linear_map" rel="noopener ugc nofollow" target="_blank">线性变换</a>。更多关于张量的数学方面，这里<a class="ae lp" href="https://www.ese.wustl.edu/~nehorai/Porat_A_Gentle_Introduction_to_Tensors_2014.pdf" rel="noopener ugc nofollow" target="_blank">这里</a>和<a class="ae lp" href="https://web2.ph.utexas.edu/~jcfeng/notes/Tensors_Poor_Man.pdf" rel="noopener ugc nofollow" target="_blank">这里</a>。</p><p id="6590" class="pw-post-body-paragraph ka kb ht kc b kd kw iu kf kg kx ix ki kj ky kl km kn kz kp kq kr la kt ku kv hm dt translated">出于张量流的目的，可以把张量想象成能够以结构化的方式存储对象的存储单元。下图说明了张量在维度增长时的结构和索引。</p><figure class="lw lx ly lz fq ma fe ff paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="fe ff mh"><img src="../Images/02e05e0b174269600a2e48051ead9911.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*d5ukGtln7dGn23rk.jpg"/></div></div></figure><p id="fd40" class="pw-post-body-paragraph ka kb ht kc b kd kw iu kf kg kx ix ki kj ky kl km kn kz kp kq kr la kt ku kv hm dt translated">在上图中，用用于访问存储值的索引方案来表示单元格。当维度增长时，更高维度的索引被钉在左侧。例如，二维张量(矩阵)中的元素被索引为<code class="eh lr ls lt lu b">(row, column)</code>，而在三维张量中，它被索引为<code class="eh lr ls lt lu b">(depth, row, column)</code>。</p><p id="2761" class="pw-post-body-paragraph ka kb ht kc b kd kw iu kf kg kx ix ki kj ky kl km kn kz kp kq kr la kt ku kv hm dt translated">很难想象大于三维的张量的结构。一个技巧是将高维度想象成一个容器，以结构化(索引)的方式存储一组低维张量。例如，四维张量是三维张量的数组。</p><figure class="lw lx ly lz fq ma fe ff paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="fe ff mi"><img src="../Images/c6e0bbdd1b3c12c582d410d07b6d5f7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*8xLNN_3q5qhKgP8w.jpg"/></div></div></figure><p id="aaad" class="pw-post-body-paragraph ka kb ht kc b kd kw iu kf kg kx ix ki kj ky kl km kn kz kp kq kr la kt ku kv hm dt translated">类似地，5维张量是4维张量的数组。</p><figure class="lw lx ly lz fq ma fe ff paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="fe ff mj"><img src="../Images/ce861b95745cffea4726e50aab1a38f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*GNVnzS2c8LMnS9y5.jpg"/></div></div></figure><p id="d3b0" class="pw-post-body-paragraph ka kb ht kc b kd kw iu kf kg kx ix ki kj ky kl km kn kz kp kq kr la kt ku kv hm dt translated">现在，试着想象一个6-D张量。</p><h1 id="19cf" class="ji jj ht bd jk jl jm jn jo jp jq jr js iz jt ja ju jc jv jd jw jf jx jg jy jz dt translated">一个简单的张量流程序</h1><figure class="lw lx ly lz fq ma"><div class="bz el l di"><div class="mk ml l"/></div></figure><pre class="lw lx ly lz fq mm lu mn mo aw mp dt"><span id="e7fc" class="mq jj ht lu b fv mr ms l mt mu"><strong class="lu hu">[Out]</strong><br/>[8.0, 2.236068, 104.56122]</span></pre><p id="30f8" class="pw-post-body-paragraph ka kb ht kc b kd kw iu kf kg kx ix ki kj ky kl km kn kz kp kq kr la kt ku kv hm dt translated">Tensorboard 是随TensorFlow框架一起提供的一个图形可视化(等等)工具。TF提供的<code class="eh lr ls lt lu b">FileWriter</code> API将数据流图写成文件，以便Tensorboard生成可视化效果。</p><figure class="lw lx ly lz fq ma fe ff paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="fe ff mv"><img src="../Images/6e471e56c274fe3f096207c75ec76c44.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*x2q0I0uo-6BjBJu4.png"/></div></div></figure><h1 id="20bb" class="ji jj ht bd jk jl jm jn jo jp jq jr js iz jt ja ju jc jv jd jw jf jx jg jy jz dt translated">结论</h1><p id="2287" class="pw-post-body-paragraph ka kb ht kc b kd ke iu kf kg kh ix ki kj kk kl km kn ko kp kq kr ks kt ku kv hm dt translated">TensorFlow是一个使用数据流范式构建的数值计算库，其中在操作之间流动的数据是张量。在TensorFlow中，学习算法表示为数据流图，输入数据表示为流经该图的张量。这就是这个框架被恰当地命名为<strong class="kc hu"> TensorFlow </strong>的原因。下图是描述输入张量通过数据流图的流动的动画。它还展示了并行性如何成为数据流范例的一个内置特性。</p><figure class="lw lx ly lz fq ma fe ff paragraph-image"><div class="fe ff mw"><img src="../Images/04bd39eb0349892ef65d03362e57bb32.png" data-original-src="https://miro.medium.com/v2/resize:fit:504/0*k-EUaQT2qyQibnD7.gif"/></div><figcaption class="mx my fg fe ff mz na bd b be z ek">Credit: Tensorflow Programmers Guide, <a class="ae lp" href="https://www.tensorflow.org/guide/graphs" rel="noopener ugc nofollow" target="_blank">Graphs and Sessions</a></figcaption></figure><p id="e6a9" class="pw-post-body-paragraph ka kb ht kc b kd kw iu kf kg kx ix ki kj ky kl km kn kz kp kq kr la kt ku kv hm dt translated">由于表示一个TF应用程序的图形本质，我们获得了以无数种方式组合操作的能力，给予研究人员实现新想法所需的灵活性。TF还利用数据流图提供的内置并行性来提供高效的计算能力。此外，定义和计算之间的明确分离使我们能够轻松地为TF应用程序启用分布式计算，从而使TensorFlow成为企业ML/DL应用程序的理想框架。</p></div><div class="ab cl nb nc hb nd" role="separator"><span class="ne bw bk nf ng nh"/><span class="ne bw bk nf ng nh"/><span class="ne bw bk nf ng"/></div><div class="hm hn ho hp hq"><p id="b6de" class="pw-post-body-paragraph ka kb ht kc b kd kw iu kf kg kx ix ki kj ky kl km kn kz kp kq kr la kt ku kv hm dt translated"><em class="lq">原发布于</em><a class="ae lp" href="https://www.surajx.in/2018/07/tensorflow-a-conceptual-introduction/" rel="noopener ugc nofollow" target="_blank"><em class="lq">https://www . surajx . in/2018/07/tensor flow-a-conceptual-introduction/</em></a><em class="lq">。</em></p></div></div>    
</body>
</html>