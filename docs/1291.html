<html>
<head>
<title>Target Customers, smartly!</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">目标客户，潇洒！</h1>
<blockquote>原文：<a href="https://medium.com/coinmonks/target-customers-smartly-5c3f49add85d?source=collection_archive---------3-----------------------#2018-08-11">https://medium.com/coinmonks/target-customers-smartly-5c3f49add85d?source=collection_archive---------3-----------------------#2018-08-11</a></blockquote><div><div class="ef hh hi hj hk hl"/><div class="hm hn ho hp hq"><div class=""/><div class=""><h2 id="5fdc" class="pw-subtitle-paragraph iq hs ht bd b ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ek translated">ε贪婪算法和Thompson采样简介</h2></div><p id="6660" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hm dt translated">在台湾数据专业人士7月的meet up中，美国证券交易所的陈美威对生存偏差和应对挑战的算法、<em class="ke">ε贪婪算法</em>和<em class="ke">汤普森抽样</em>做了精彩的介绍。在这篇文章中，我将从头开始解释它是如何工作的。一些代码是从Udemy.com的<a class="ae kf" href="https://www.udemy.com/bayesian-machine-learning-in-python-ab-testing/" rel="noopener ugc nofollow" target="_blank">贝叶斯机器学习</a>课上修改的。我强烈推荐这份详尽而简洁的材料。</p><p id="727c" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hm dt translated">好了，我们走吧！</p></div><div class="ab cl kg kh hb ki" role="separator"><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl"/></div><div class="hm hn ho hp hq"><h1 id="0537" class="kn ko ht bd kp kq kr ks kt ku kv kw kx iz ky ja kz jc la jd lb jf lc jg ld le dt translated">问题定义</h1><p id="fe20" class="pw-post-body-paragraph ji jj ht jk b jl lf iu jn jo lg ix jq jr lh jt ju jv li jx jy jz lj kb kc kd hm dt translated">想象一下，你的公司正在开展基于电子邮件的营销活动。自然，有些客户更有可能打开电子邮件，而有些则不会。但是在开展任何活动之前，你对你的顾客一无所知。了解客户打开电子邮件的可能性的唯一方法是通过向他们发送整批电子邮件来收集数据，并观察回复率。问题是，我们需要向所有客户发送多少封电子邮件才能确定统计意义？</p><p id="2e11" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hm dt translated">如果我们给每个客户发100封电子邮件，我们可能会知道谁是我们的最佳目标。但是效率很低！随着活动的进行，我们希望接触尽可能多的顾客。与此同时，我们也要瞄准那些回复率最高的客户，那些是我们给予最佳回报的最佳客户。这是一个<strong class="jk hu"> <em class="ke">探索-利用权衡</em> </strong> <em class="ke">。</em></p><p id="a92f" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hm dt translated">探索、开发和取舍是我们在选择时经常面临的两难境地。你应该选择你所知道的并得到你所期望的东西(“利用”)还是选择你不确定的东西并可能学到更多(“探索”)？</p><p id="d73e" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hm dt translated"><strong class="jk hu"> </strong>挑战可以存在于许多不同的环境中。例如营销活动、网站A/B测试或您的赌博策略。挑战的核心本质上是一样的。</p><h1 id="4187" class="kn ko ht bd kp kq lk ks kt ku ll kw kx iz lm ja kz jc ln jd lb jf lo jg ld le dt translated">ε贪婪</h1><p id="5392" class="pw-post-body-paragraph ji jj ht jk b jl lf iu jn jo lg ix jq jr lh jt ju jv li jx jy jz lj kb kc kd hm dt translated">为了解决剥削和探索问题，ε贪婪算法分配一个概率<strong class="jk hu"> ε </strong>，我们随机探索更多的客户。在剩下的时间里，我们根据目前已知的情况，利用概率最高的客户。伪代码可以写成如下形式:</p><pre class="lp lq lr ls fq lt lu lv lw aw lx dt"><span id="98da" class="ly ko ht lu b fv lz ma l mb mc"><em class="ke">while True:</em><br/><em class="ke">    r = random.random()</em><br/><em class="ke">    if r &lt; eps:</em><br/><em class="ke">        #explore</em><br/><em class="ke">        #show ads to random customer</em><br/><em class="ke">        #update </em><strong class="lu hu"><em class="ke">p</em></strong><br/><em class="ke">        pass</em><br/><em class="ke">    else:</em><br/><em class="ke">        #exploit</em><br/><em class="ke">        #show ads customer with highest </em><strong class="lu hu"><em class="ke">p</em></strong><br/><em class="ke">        break</em></span></pre><p id="8e80" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hm dt translated">为了建立实验，我编写了一个python类来恢复客户的内在概率和过去的反应记录。注意，固有概率被假设为高斯分布，其特征在于<strong class="jk hu"> p_mean </strong>和<strong class="jk hu"> p_sigma </strong>。因此，每次我们联系到客户时，打开链接的概率不是一个恒定的概率，而是从高斯分布中抽取的一个随机数。</p><pre class="lp lq lr ls fq lt lu lv lw aw lx dt"><span id="bdf0" class="ly ko ht lu b fv lz ma l mb mc">class Target(object):<br/>    def __init__(self,p_mean,p_sigma):<br/>        self.p_mean = p_mean<br/>        self.p_sigma = p_sigma<br/>        self.a = 1<br/>        self.b = 1<br/>        self.n = 0<br/>        <br/>    def trigger(self):<br/>        return np.random.random() &lt; np.random.normal(loc=self.p_mean, scale=self.p_sigma)<br/>    <br/>    def sample(self):<br/>        return np.random.beta(self.a, self.b)<br/>        <br/>    def prob(self):<br/>        return self.a/(self.a + self.b)<br/>    <br/>    def update(self, x):<br/>        self.a += x<br/>        self.b += 1 - x<br/>        self.n += 1</span></pre><p id="f04a" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hm dt translated">类构造器<strong class="jk hu"> <em class="ke"> __init__ </em> </strong>接受两个参数<strong class="jk hu"> p_mean </strong>和<strong class="jk hu"> p_sigma </strong>。我们也初始化<strong class="jk hu"> <em class="ke"> self.a = 1 </em> </strong>和<strong class="jk hu"> <em class="ke"> self.b = 1 </em> </strong>，分别表示总成功和总失败。<strong class="jk hu"> a </strong>和<strong class="jk hu"> b </strong>开始时设置为1，方便后面的实验。类方法<strong class="jk hu"><em class="ke">trigger()</em></strong><em class="ke"/>将通过比较均匀随机数和从高斯分布中抽取的样本来返回测试结果。<strong class="jk hu"> <em class="ke"> prob() </em> </strong>方法将返回基于先前测试的经验概率。最后，<strong class="jk hu"> <em class="ke"> update() </em> </strong>方法记录一个目标的测试历史。</p><pre class="lp lq lr ls fq lt lu lv lw aw lx dt"><span id="a385" class="ly ko ht lu b fv lz ma l mb mc">def experiment():<br/>    #Create target objects for epsilon greedy<br/>    Targets = [Target(p,s) for p,s in zip(p_means,p_sigmas)] <br/>    n_pulling = [0,0,0]<br/>    regret = 0<br/>    cumulative_regret = []<br/>    <br/>    for i in range(num_trials):<br/>        best_target = None<br/>        max_prob = -1</span><span id="1bce" class="ly ko ht lu b fv md ma l mb mc">        #with probability epsilon, we explore more data<br/>        r = np.random.random()        <br/>        if r &lt; epsilon: #<br/>            index = np.random.randint(0,len(Targets))<br/>            best_target = Targets[index]<br/>        else: <br/>            for n,target in enumerate(Targets):<br/>                prob = target.prob()<br/>                if prob &gt; max_prob:<br/>                    maxprob = prob<br/>                    best_target = target<br/>                    index = n<br/>                    <br/>        x = best_target.trigger()<br/>        best_target.update(x)<br/>        regret += optimal-x<br/>        cumulative_regret.append(regret)<br/>    plot(Targets, cumulative_regret, cumulative_reward, num_trials)</span><span id="e44e" class="ly ko ht lu b fv md ma l mb mc">num_trials = 1000<br/>p_means = [0.2, 0.5, 0.7]<br/>p_sigmas = [0.1, 0.1, 0.1]<br/>optimal = max(p_means)<br/>epsilon = 0.2<br/>experiment()</span></pre><p id="f4c5" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hm dt translated">这是一段python代码，实现了ε贪婪算法。为了方便起见，我们把实验简化为三个选项。我们还引入了一个新的变量<em class="ke">后悔</em>来评估性能。后悔被定义为与最佳选择相比的损失。换句话说，如果我们总是以最高的概率锁定客户，那么我们就不会后悔。因此，我们的目标是尽量减少累积的遗憾。</p><figure class="lp lq lr ls fq mf fe ff paragraph-image"><div class="fe ff me"><img src="../Images/5024507233c4666469be264ad5a5e896.png" data-original-src="https://miro.medium.com/v2/resize:fit:1210/format:webp/1*b4Jxf0mUW9JqsUMzDfNIdQ.png"/></div></figure><p id="af74" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hm dt translated">左手边是1000次试验后每个选项<strong class="jk hu"> </strong>的<strong class="jk hu"> p </strong>的概率分布。我们观察到的第一件事是绿线的分布比其他线窄得多，这意味着我们非常确定绿线是一个更好的目标，因此我们在1000次试验中有872次选择了绿色目标。</p><p id="8a66" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hm dt translated">同时，由于勘探的随机性，另外两个目标也得到较好的勘探。随机探索的结果是，累积的遗憾总是在增加！一个解决方案是<a class="ae kf" href="http://banditalgs.com/2016/09/18/the-upper-confidence-bound-algorithm/" rel="noopener ugc nofollow" target="_blank">上置信结合</a>。UBC算法将决定我们何时可以用收集到的数据自信地停止随机探索。或者，我们可以考虑一种更聪明的方法，在不增加遗憾的情况下无缝地探索客户。</p><h1 id="111e" class="kn ko ht bd kp kq lk ks kt ku ll kw kx iz lm ja kz jc ln jd lb jf lo jg ld le dt translated">汤普森取样</h1><figure class="lp lq lr ls fq mf fe ff paragraph-image"><div class="fe ff mi"><img src="../Images/6174c6531d4739d49912d9774945bbf8.png" data-original-src="https://miro.medium.com/v2/resize:fit:896/format:webp/1*r48G_XyTxw_kh7leWjfhOw.png"/></div><figcaption class="mj mk fg fe ff ml mm bd b be z ek">The Bayes’ Theorem</figcaption></figure><p id="be5e" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hm dt translated">汤普森抽样是贝叶斯定理的一个应用。贝叶斯定理为估计参数的概率分布提供了强有力的工具。等式的左侧是后验概率，通常解释为参数给定数据的概率分布。右手边是可能性倍数先验除以边际概率。</p><p id="28e7" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hm dt translated">在我们的例子中，似然函数是<a class="ae kf" href="https://en.wikipedia.org/wiki/Beta_distribution" rel="noopener ugc nofollow" target="_blank"> <strong class="jk hu">伯努利分布</strong> </a>。伯努利分布给出了两种可能的结果(0，1)，并由<strong class="jk hu"> p. </strong>参数化，也就是说，每次我们联系到客户时，他/她都有内在概率<strong class="jk hu"> p </strong>打开链接(输出= 1)和概率<strong class="jk hu"> 1-p </strong>忽略它(输出=0)。</p><figure class="lp lq lr ls fq mf fe ff paragraph-image"><div class="fe ff mn"><img src="../Images/7055f5ecf07856569dffd8dc26bab748.png" data-original-src="https://miro.medium.com/v2/resize:fit:840/format:webp/1*lP9yCXozjchFLoA2Jzy19Q.png"/></div></figure><p id="b09b" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hm dt translated">对于先验分布，我们用<a class="ae kf" href="https://en.wikipedia.org/wiki/Beta_distribution" rel="noopener ugc nofollow" target="_blank"> <strong class="jk hu">贝塔分布</strong> </a> <strong class="jk hu">。</strong>在贝叶斯统计中，我们经常为似然函数选择一个<a class="ae kf" href="https://en.wikipedia.org/wiki/Conjugate_prior" rel="noopener ugc nofollow" target="_blank">共轭先验</a>，以确保后验分布与先验分布相同。因此，我们可以减少计算量。</p><figure class="lp lq lr ls fq mf fe ff paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="fe ff mo"><img src="../Images/e847ee2cb2682cfc04684941704e6366.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WefSSHTH50R6kaNBG40ufA.png"/></div></div><figcaption class="mj mk fg fe ff ml mm bd b be z ek">Wikipedia : Conjugate Prior</figcaption></figure><p id="eeab" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hm dt translated">这听起来很复杂，但实际上很简单。β分布由两个参数表征，⍺和β。开始时，我们从Beta(⍺=1,β=1抽取样本并进行测试。如果结果是头(x=1)m，我们更新后验Beta(⍺'=⍺+1,β'=β).我们运行另一个测试，使用新Beta作为先验，更新超参数。一次又一次，最终，后验函数会给我们<strong class="jk hu"> p </strong>的真实分布。在伪代码中:</p><pre class="lp lq lr ls fq lt lu lv lw aw lx dt"><span id="2de7" class="ly ko ht lu b fv lz ma l mb mc">⍺1=β1=⍺2=β2...⍺k=βk=1<br/>while True:<br/><em class="ke">    # draw samples from Beta_i(</em>⍺i,βi) i=0-k<br/>    # <em class="ke">show ads to sample with largest number<br/>    # receive response x = 0 or 1    <br/>    # update posterior </em>⍺'= ⍺+x,β'= β+(1-x)</span></pre><p id="1073" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hm dt translated">要实现Thompson采样，我们只需在前面的实验()函数中添加几行代码:</p><pre class="lp lq lr ls fq lt lu lv lw aw lx dt"><span id="ac2b" class="ly ko ht lu b fv lz ma l mb mc">#Thompson Sampling<br/>        for n, target in enumerate(Targets):<br/>            sample = target.sample()<br/>            if sample &gt; max_prob:<br/>                max_pro = sample<br/>                best_target = target<br/>                index = n</span></pre><p id="c611" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hm dt translated">请注意，唯一的区别是我们比较的样本来自贝塔分布，而不是直接比较经验概率。</p><div class="lp lq lr ls fq ab cb"><figure class="mt mf mu mv mw mx my paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><img src="../Images/2aebf710f4aeb0b8d5fa2ad670a61cf5.png" data-original-src="https://miro.medium.com/v2/resize:fit:674/format:webp/1*UmLZoK-4DFoXseE0JCGe8w.png"/></div></figure><figure class="mt mf mz mv mw mx my paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><img src="../Images/cf252e04a8035bcbf62e755591b53787.png" data-original-src="https://miro.medium.com/v2/resize:fit:664/format:webp/1*-lyz19u_JbdsUhVi7geQWA.png"/></div></figure><figure class="mt mf mz mv mw mx my paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><img src="../Images/30abd32906cbecab67f35c578b400e6e.png" data-original-src="https://miro.medium.com/v2/resize:fit:664/format:webp/1*hRr5IVnM4ZVZ3JnlSyNJjA.png"/></div><figcaption class="mj mk fg fe ff ml mm bd b be z ek na di nb nc">The posterior distribution of <strong class="bd nd">p. </strong>The solid line EG stand for epsilon greedy algorithm. The dash line TS stand for Thompson sampling. From left to right is the posterior after [50, 200, 500] trials.</figcaption></figure></div><p id="0276" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hm dt translated">成绩有了明显的提高！通过Thompson采样，该算法很快就知道哪个是最佳目标，并坚持下去，而不会浪费时间随机探索更多数据。</p><figure class="lp lq lr ls fq mf fe ff paragraph-image"><div class="fe ff me"><img src="../Images/18231c3bfb0c47e6c6198ff583d0f8ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1210/format:webp/1*I04V_NtWmpbSLSvmCu8y3A.png"/></div></figure><p id="10d9" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hm dt translated">从累积遗憾图中，我们清楚地看到，累积遗憾在300次尝试后显著降低，并变为平坦，这意味着算法已经学会总是选择最优目标。</p><p id="042f" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hm dt translated">我们可以从Thompson抽样中受益，用更少的试验和最大的回报。</p></div><div class="ab cl kg kh hb ki" role="separator"><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl"/></div><div class="hm hn ho hp hq"><h1 id="a25b" class="kn ko ht bd kp kq kr ks kt ku kv kw kx iz ky ja kz jc la jd lb jf lc jg ld le dt translated">结论</h1><p id="92a3" class="pw-post-body-paragraph ji jj ht jk b jl lf iu jn jo lg ix jq jr lh jt ju jv li jx jy jz lj kb kc kd hm dt translated">在现实世界中，打开链接的可能性通常在3-5%左右，甚至更低。此外，客户群要大得多。下周，我将在更大的目标数量和更低的概率下对这两种算法的性能做更多的实验。我还将尝试其他想法来改进算法，例如设置不同的初始先验或不同的ε。</p><p id="fc45" class="pw-post-body-paragraph ji jj ht jk b jl jm iu jn jo jp ix jq jr js jt ju jv jw jx jy jz ka kb kc kd hm dt translated">完整的python代码可以在我的<a class="ae kf" href="https://github.com/easonla/ABTesting/blob/master/GreedyVSThompson.ipynb" rel="noopener ugc nofollow" target="_blank"> github </a>上找到。希望这篇文章可以帮助你更好地理解epsilon贪婪算法和Thompson采样。如果你有任何问题，给我留言。谢谢！</p></div></div>    
</body>
</html>