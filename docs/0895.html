<html>
<head>
<title>Support Vector Regression Or SVR</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">支持向量回归机</h1>
<blockquote>原文：<a href="https://medium.com/coinmonks/support-vector-regression-or-svr-8eb3acf6d0ff?source=collection_archive---------2-----------------------#2018-06-29">https://medium.com/coinmonks/support-vector-regression-or-svr-8eb3acf6d0ff?source=collection_archive---------2-----------------------#2018-06-29</a></blockquote><div><div class="ef hh hi hj hk hl"/><div class="hm hn ho hp hq"><div class=""/><p id="e0ef" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">这篇文章是关于支持向量回归的。那些从事机器学习或数据科学的人非常熟悉术语SVM或支持向量机。但是SVR和SVM有点不同。顾名思义，SVR是一种回归算法，因此我们可以使用SVR来处理连续值，而不是SVM分类。</p><p id="c637" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">在这篇文章中我们将会经常用到的术语</p><ol class=""><li id="7011" class="jo jp ht is b it iu ix iy jb jq jf jr jj js jn jt ju jv jw dt translated"><strong class="is hu">内核</strong>:用于将低维数据映射到高维数据的函数。</li><li id="9276" class="jo jp ht is b it jx ix jy jb jz jf ka jj kb jn jt ju jv jw dt translated"><strong class="is hu">超平面</strong>:在SVM，这基本上是数据类之间的分隔线。虽然在SVR中，我们将它定义为，将帮助我们预测连续值或目标值的线</li><li id="1d29" class="jo jp ht is b it jx ix jy jb jz jf ka jj kb jn jt ju jv jw dt translated"><strong class="is hu">边界线</strong>:在SVM，除了超平面之外，还有两条线形成了一个边界。支持向量可以在边界线上或边界线外。这条分界线把两个阶级分开了。在SVR中，概念是相同的。</li><li id="ad79" class="jo jp ht is b it jx ix jy jb jz jf ka jj kb jn jt ju jv jw dt translated"><strong class="is hu">支持向量</strong>:这是最接近边界的数据点。这些点的距离是最小的。</li></ol><blockquote class="kc kd ke"><p id="3253" class="iq ir kf is b it iu iv iw ix iy iz ja kg jc jd je kh jg jh ji ki jk jl jm jn hm dt translated"><strong class="is hu"> <em class="ht">为什么是SVR？SVR和简单回归模型的主要区别是什么？</em>T11】</strong></p><p id="9acf" class="iq ir kf is b it iu iv iw ix iy iz ja kg jc jd je kh jg jh ji ki jk jl jm jn hm dt translated">在简单回归中，我们试图将误差率降到最低。而在SVR中，我们试图将误差拟合在某个阈值内。这可能有点令人困惑，但让我解释一下。</p></blockquote><figure class="kk kl km kn fq ko fe ff paragraph-image"><div class="fe ff kj"><img src="../Images/f0da6a3b8a0fa985cbba562ffbb225e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1138/format:webp/1*o3Gmkg7BRAvzyIDwRGhxPg.png"/></div><figcaption class="kr ks fg fe ff kt ku bd b be z ek">fig 1 :Blue line: Hyper Plane; Red Line: Boundary Line</figcaption></figure><p id="5aa9" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu"> <em class="kf">蓝线:超平面；红线:边界线</em> </strong></p><figure class="kk kl km kn fq ko fe ff paragraph-image"><div class="fe ff kv"><img src="../Images/e871c9129c55c1ec92b4442f3d53c2e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*fVCEP_qxSWYwKcpkt2Xk2w.png"/></div><figcaption class="kr ks fg fe ff kt ku bd b be z ek">\fig 2:Now see the points</figcaption></figure><p id="3e1e" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">参见图2，了解所有点如何位于边界线(红线)内。当我们继续使用SVR时，我们的目标是基本上考虑边界线内的点。我们的最佳拟合线是具有最大点数的线超平面。</p><p id="d2fb" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu"> <em class="kf">那么我们开始:</em> </strong></p><p id="24d0" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">所以我们首先要了解的是<strong class="is hu"> <em class="kf">这条边界线是什么？(是的！那条红线)。</em> </strong>把它想象成距离为‘e’(虽然不是e，但基本上是ε)的线，但为了简单起见，让我们称它为<strong class="is hu">‘e’。</strong></p><blockquote class="kw"><p id="a9a5" class="kx ky ht bd kz la lb lc ld le lf jn ek translated">所以<strong class="ak"> </strong>我们画的线在距离超平面<strong class="ak"> '+e' </strong>和<strong class="ak"> '-e ' </strong>的位置。</p></blockquote><blockquote class="kc kd ke"><p id="e5ff" class="iq ir kf is b it lg iv iw ix lh iz ja kg li jd je kh lj jh ji ki lk jl jm jn hm dt translated">假设我们的超平面是穿过Y轴的直线</p><p id="2df1" class="iq ir kf is b it iu iv iw ix iy iz ja kg jc jd je kh jg jh ji ki jk jl jm jn hm dt translated">我们可以说超平面的方程是</p></blockquote><blockquote class="kw"><p id="e482" class="kx ky ht bd kz la ll lm ln lo lp jn ek translated"><strong class="ak"> wx+b=0 </strong></p></blockquote><blockquote class="kc kd ke"><p id="a919" class="iq ir kf is b it lg iv iw ix lh iz ja kg li jd je kh lj jh ji ki lk jl jm jn hm dt translated">所以我们可以说这两条边界线的方程是</p></blockquote><blockquote class="kw"><p id="62dc" class="kx ky ht bd kz la ll lm ln lo lp jn ek translated"><strong class="ak"> Wx+b=+e </strong></p><p id="3ad4" class="kx ky ht bd kz la lb lc ld le lf jn ek translated"><strong class="ak"> Wx+b=-e </strong></p></blockquote><p id="d880" class="pw-post-body-paragraph iq ir ht is b it lg iv iw ix lh iz ja jb li jd je jf lj jh ji jj lk jl jm jn hm dt translated">各自地</p><p id="e037" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">因此，根据以下事实，对于任何线性超平面，满足我们的SVR的方程是:</p><blockquote class="kw"><p id="eb4e" class="kx ky ht bd kz la lb lc ld le lf jn ek translated">e≤y-Wx-b≤+e</p></blockquote><blockquote class="kc kd ke"><p id="6013" class="iq ir kf is b it lg iv iw ix lh iz ja kg li jd je kh lj jh ji ki lk jl jm jn hm dt translated">陈述y=Wx+b的事实</p><p id="deb1" class="iq ir kf is b it iu iv iw ix iy iz ja kg jc jd je kh jg jh ji ki jk jl jm jn hm dt translated">y-Wx-b=0</p></blockquote><p id="b5b0" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu"> <em class="kf">这适用于所有其他类型的回归(非线性、多项式)</em> </strong></p><blockquote class="kw"><p id="bfae" class="kx ky ht bd kz la lb lc ld le lf jn ek translated">概述</p><p id="da43" class="kx ky ht bd kz la lb lc ld le lf jn ek translated">我们在这里尝试做的事情基本上是尝试在距离原始超平面“e”距离处决定决策边界，使得最接近超平面或支持向量的数据点在该边界线内</p></blockquote><figure class="lr ls lt lu lv ko fe ff paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="fe ff lq"><img src="../Images/f268abd50257f37ea6a496269fa8bfd7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rs0EfF8RPVpgA-EfgAq85g.jpeg"/></div></div><figcaption class="kr ks fg fe ff kt ku bd b be z ek">Fig 3: <a class="ae ma" href="https://www.researchgate.net/figure/Schematic-of-the-one-dimensional-support-vector-regression-SVR-model-Only-the-points_fig5_320916953" rel="noopener ugc nofollow" target="_blank">https://www.researchgate.net/figure/Schematic-of-the-one-dimensional-support-vector-regression-SVR-model-Only-the-points_fig5_320916953</a></figcaption></figure><p id="fc79" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">因此，决策边界是我们的容限，也就是说，我们将只选取那些在此边界内的点。</p><p id="18a8" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">或者简单地说，我们只取那些误差率最小的点。从而给我们一个更好的拟合模型。</p><p id="e02e" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">如果我的解释不够充分，你可以检查:</p><div class="mb mc fm fo md me"><a href="http://www.saedsayad.com/support_vector_machine_reg.htm" rel="noopener  ugc nofollow" target="_blank"><div class="mf ab ej"><div class="mg ab mh cl cj mi"><h2 class="bd hu fv z el mj eo ep mk er et hs dt translated">支持向量回归</h2><div class="ml l"><h3 class="bd b fv z el mj eo ep mk er et ek translated">编辑描述</h3></div><div class="mm l"><p class="bd b gc z el mj eo ep mk er et ek translated">www.saedsayad.com</p></div></div><div class="mn l"><div class="mo l mp mq mr mn ms kp me"/></div></div></a></div><p id="e258" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">好了，现在让我们做我们真正想做的事。当然是编码部分</p><p id="1447" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu">从这里下载代码和CSV:</strong></p><div class="mb mc fm fo md me"><a href="https://github.com/neelindresh/NeelBlog" rel="noopener  ugc nofollow" target="_blank"><div class="mf ab ej"><div class="mg ab mh cl cj mi"><h2 class="bd hu fv z el mj eo ep mk er et hs dt translated">neelindresh/NeelBlog</h2><div class="ml l"><h3 class="bd b fv z el mj eo ep mk er et ek translated">NeelBlog——包含我博客中的代码和csv</h3></div><div class="mm l"><p class="bd b gc z el mj eo ep mk er et ek translated">github.com</p></div></div><div class="mn l"><div class="mt l mp mq mr mn ms kp me"/></div></div></a></div><p id="c1fc" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu"> <em class="kf">数据集描述:</em> </strong></p><pre class="kk kl km kn fq mu mv mw mx aw my dt"><span id="9c48" class="mz na ht mv b fv nb nc l nd ne">Predicting the age of abalone from physical measurements. </span><span id="31e1" class="mz na ht mv b fv nf nc l nd ne"><br/>Name		Data Type	Meas.	Description<br/>	----		---------	-----	-----------<br/>	Sex		nominal			M, F, and I (infant)<br/>	Length		continuous	mm	Longest shell measurement<br/>	Diameter	continuous	mm	perpendicular to length<br/>	Height		continuous	mm	with meat in shell<br/>	Whole weight	continuous	grams	whole abalone<br/>	Shucked weight	continuous	grams	weight of meat<br/>	Viscera weight	continuous	grams	gut weight (after bleeding)<br/>	Shell weight	continuous	grams	after being dried<br/>	Rings		integer			+1.5 gives the age in years</span></pre><p id="34b5" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">链接:</p><p id="3f38" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><a class="ae ma" href="https://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.names" rel="noopener ugc nofollow" target="_blank">https://archive . ics . UCI . edu/ml/machine-learning-databases/鲍鱼/鲍鱼. names </a></p><p id="77c4" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">这次让我们全力以赴吧！从缩放到功能选择，说什么！</p><blockquote class="kc kd ke"><p id="6649" class="iq ir kf is b it iu iv iw ix iy iz ja kg jc jd je kh jg jh ji ki jk jl jm jn hm dt translated">#编码:utf-8</p><p id="99bd" class="iq ir kf is b it iu iv iw ix iy iz ja kg jc jd je kh jg jh ji ki jk jl jm jn hm dt translated">进口熊猫作为pd</p><p id="d166" class="iq ir kf is b it iu iv iw ix iy iz ja kg jc jd je kh jg jh ji ki jk jl jm jn hm dt translated">df=pd.read_csv('。/age _ mod . CSV’)</p><p id="d478" class="iq ir kf is b it iu iv iw ix iy iz ja kg jc jd je kh jg jh ji ki jk jl jm jn hm dt translated">df.head()</p><p id="9f60" class="iq ir kf is b it iu iv iw ix iy iz ja kg jc jd je kh jg jh ji ki jk jl jm jn hm dt translated">df=df.drop(['Sex']，axis=1)</p><p id="617e" class="iq ir kf is b it iu iv iw ix iy iz ja kg jc jd je kh jg jh ji ki jk jl jm jn hm dt translated">从sklearn.svm导入SVR</p><p id="114f" class="iq ir kf is b it iu iv iw ix iy iz ja kg jc jd je kh jg jh ji ki jk jl jm jn hm dt translated">回归变量=SVR(内核= '线性'，次数=1)</p><p id="280e" class="iq ir kf is b it iu iv iw ix iy iz ja kg jc jd je kh jg jh ji ki jk jl jm jn hm dt translated">将matplotlib.pyplot作为plt导入</p><p id="51b2" class="iq ir kf is b it iu iv iw ix iy iz ja kg jc jd je kh jg jh ji ki jk jl jm jn hm dt translated">plt.scatter(df['去皮重量']，df['年龄'])</p><p id="acd4" class="iq ir kf is b it iu iv iw ix iy iz ja kg jc jd je kh jg jh ji ki jk jl jm jn hm dt translated">从sklearn.model_selection导入训练_测试_拆分</p><p id="f25b" class="iq ir kf is b it iu iv iw ix iy iz ja kg jc jd je kh jg jh ji ki jk jl jm jn hm dt translated">xtrain，xtest，ytrain，ytest=train_test_split(x，y)</p><p id="4535" class="iq ir kf is b it iu iv iw ix iy iz ja kg jc jd je kh jg jh ji ki jk jl jm jn hm dt translated">regressor.fit(xtrain，ytrain)</p><p id="1178" class="iq ir kf is b it iu iv iw ix iy iz ja kg jc jd je kh jg jh ji ki jk jl jm jn hm dt translated">pred=regressor.predict(xtest)</p><p id="23d1" class="iq ir kf is b it iu iv iw ix iy iz ja kg jc jd je kh jg jh ji ki jk jl jm jn hm dt translated">print(regressor.score(xtest，ytest))</p><p id="577e" class="iq ir kf is b it iu iv iw ix iy iz ja kg jc jd je kh jg jh ji ki jk jl jm jn hm dt translated">从sklearn.metrics导入r2_score</p><p id="36fc" class="iq ir kf is b it iu iv iw ix iy iz ja kg jc jd je kh jg jh ji ki jk jl jm jn hm dt translated">print(r2_score(ytest，pred))</p><p id="ce8c" class="iq ir kf is b it iu iv iw ix iy iz ja kg jc jd je kh jg jh ji ki jk jl jm jn hm dt translated">regressor=SVR(kernel='rbf '，epsilon = 1.0)<br/>regressor . fit(xtrain，ytrain)<br/>pred = regressor . predict(xtest)<br/>print(regressor . score(xtest，ytest))<br/>print(R2 _ score(ytest，pred))</p></blockquote><p id="9dff" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu"> <em class="kf">读取CSV文件</em> </strong></p><blockquote class="kc kd ke"><p id="e2d9" class="iq ir kf is b it iu iv iw ix iy iz ja kg jc jd je kh jg jh ji ki jk jl jm jn hm dt translated">进口熊猫作为pd</p><p id="8c13" class="iq ir kf is b it iu iv iw ix iy iz ja kg jc jd je kh jg jh ji ki jk jl jm jn hm dt translated">df=pd.read_csv('。/age _ mod . CSV’)</p><p id="eeb1" class="iq ir kf is b it iu iv iw ix iy iz ja kg jc jd je kh jg jh ji ki jk jl jm jn hm dt translated">df.head()</p></blockquote><p id="0196" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu"> <em class="kf">我们不需要‘性别’一栏所以删除</em> </strong></p><blockquote class="kc kd ke"><p id="bdbb" class="iq ir kf is b it iu iv iw ix iy iz ja kg jc jd je kh jg jh ji ki jk jl jm jn hm dt translated">df=df.drop(['Sex']，axis=1)</p></blockquote><p id="e81e" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu"> <em class="kf">从sklearn.svm加载SVR模型</em> </strong></p><blockquote class="kc kd ke"><p id="50cd" class="iq ir kf is b it iu iv iw ix iy iz ja kg jc jd je kh jg jh ji ki jk jl jm jn hm dt translated">从sklearn.svm导入SVR</p><p id="c79e" class="iq ir kf is b it iu iv iw ix iy iz ja kg jc jd je kh jg jh ji ki jk jl jm jn hm dt translated">回归变量=支持向量回归机(内核= '线性')</p></blockquote><p id="ec35" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu">#注意:kernel='linear' →我们将内核设置为线性内核</strong></p><p id="e4b0" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu"> #DEFAULT: kernel='rbf' </strong></p><p id="507f" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu"> <em class="kf">剧情关系:</em> </strong></p><blockquote class="kc kd ke"><p id="e4a8" class="iq ir kf is b it iu iv iw ix iy iz ja kg jc jd je kh jg jh ji ki jk jl jm jn hm dt translated">将matplotlib.pyplot作为plt导入</p><p id="9b79" class="iq ir kf is b it iu iv iw ix iy iz ja kg jc jd je kh jg jh ji ki jk jl jm jn hm dt translated">plt.scatter(df['去皮重量']，df['年龄'])</p></blockquote><p id="eae1" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu">#其他参数试试</strong></p><figure class="kk kl km kn fq ko fe ff paragraph-image"><div class="fe ff ng"><img src="../Images/cd0b072f6fc5f5b5d26242d4e885a549.png" data-original-src="https://miro.medium.com/v2/resize:fit:744/format:webp/1*orTnSffgjdiWHHiOhZEL0g.png"/></div></figure><p id="80c9" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu">分成训练和测试组</strong></p><blockquote class="kc kd ke"><p id="345c" class="iq ir kf is b it iu iv iw ix iy iz ja kg jc jd je kh jg jh ji ki jk jl jm jn hm dt translated">从sklearn.model_selection导入训练_测试_拆分</p><p id="18c6" class="iq ir kf is b it iu iv iw ix iy iz ja kg jc jd je kh jg jh ji ki jk jl jm jn hm dt translated">xtrain，xtest，ytrain，ytest=train_test_split(x，y)</p></blockquote><p id="2dac" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu">拟合模型做预测</strong></p><blockquote class="kc kd ke"><p id="0481" class="iq ir kf is b it iu iv iw ix iy iz ja kg jc jd je kh jg jh ji ki jk jl jm jn hm dt translated">regressor.fit(xtrain，ytrain)</p><p id="ab8e" class="iq ir kf is b it iu iv iw ix iy iz ja kg jc jd je kh jg jh ji ki jk jl jm jn hm dt translated">pred = regressor . predict(xtest<strong class="is hu">)</strong></p></blockquote><p id="d98d" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu">检查精度</strong></p><blockquote class="kc kd ke"><p id="b864" class="iq ir kf is b it iu iv iw ix iy iz ja kg jc jd je kh jg jh ji ki jk jl jm jn hm dt translated">print(regressor.score(xtest，ytest))</p><p id="60ca" class="iq ir kf is b it iu iv iw ix iy iz ja kg jc jd je kh jg jh ji ki jk jl jm jn hm dt translated">从sklearn.metrics导入r2_score</p><p id="9333" class="iq ir kf is b it iu iv iw ix iy iz ja kg jc jd je kh jg jh ji ki jk jl jm jn hm dt translated">print(r2_score(ytest，pred))</p></blockquote><p id="9b70" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu"><em class="kf">#注:均有。score()和r2_score给了我们一个准确度分数预测</em> </strong></p><p id="b3ed" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu"> <em class="kf">让我们调整SO参数，看看我们是否能得到更好的分数:</em> </strong></p><blockquote class="kc kd ke"><p id="86aa" class="iq ir kf is b it iu iv iw ix iy iz ja kg jc jd je kh jg jh ji ki jk jl jm jn hm dt translated">regressor=SVR(kernel='rbf '，epsilon = 1.0)<br/>regressor . fit(xtrain，ytrain)<br/>pred = regressor . predict(xtest)<br/>print(regressor . score(xtest，ytest))<br/>print(R2 _ score(ytest，pred))\</p></blockquote><p id="fab6" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu">T15】看这里:T17】</strong></p><blockquote class="kc kd ke"><p id="087d" class="iq ir kf is b it iu iv iw ix iy iz ja kg jc jd je kh jg jh ji ki jk jl jm jn hm dt translated">SVR(核='rbf '，ε= 1.0，度=3)</p></blockquote><blockquote class="kw"><p id="e744" class="kx ky ht bd kz la ll lm ln lo lp jn ek translated"><strong class="ak">#这里我们将内核设置为3度的“rbf”和1.0的ε值</strong></p><p id="3ac7" class="kx ky ht bd kz la lb lc ld le lf jn ek translated"><strong class="ak">#默认情况下内核是‘RBF’度是3，ε是0.1 </strong></p><p id="997a" class="kx ky ht bd kz la lb lc ld le lf jn ek translated"><strong class="ak">#其他内核有→‘线性’，‘多元’(代表多项式)，‘RBF’</strong></p></blockquote></div><div class="ab cl nh ni hb nj" role="separator"><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm"/></div><div class="hm hn ho hp hq"><p id="57d8" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">感谢阅读！</p><p id="6786" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu"> <em class="kf">关注我的博客:</em> </strong></p><div class="mb mc fm fo md me"><a href="https://dataneel.wordpress.com/" rel="noopener  ugc nofollow" target="_blank"><div class="mf ab ej"><div class="mg ab mh cl cj mi"><h2 class="bd hu fv z el mj eo ep mk er et hs dt translated">面向所有人的数据科学</h2><div class="ml l"><h3 class="bd b fv z el mj eo ep mk er et ek translated">多项式回归正如上一篇文章所说，多项式回归是线性回归的特例…</h3></div><div class="mm l"><p class="bd b gc z el mj eo ep mk er et ek translated">dataneel.wordpress.com</p></div></div><div class="mn l"><div class="no l mp mq mr mn ms kp me"/></div></div></a></div><p id="fb25" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu"> <em class="kf">多项式回归:</em> </strong></p><div class="mb mc fm fo md me"><a href="https://dataneel.wordpress.com/2018/06/22/polynomial-regression/" rel="noopener  ugc nofollow" target="_blank"><div class="mf ab ej"><div class="mg ab mh cl cj mi"><h2 class="bd hu fv z el mj eo ep mk er et hs dt translated">多项式回归</h2><div class="ml l"><h3 class="bd b fv z el mj eo ep mk er et ek translated">多项式回归正如上一篇文章所说，多项式回归是线性回归的特例…</h3></div><div class="mm l"><p class="bd b gc z el mj eo ep mk er et ek translated">dataneel.wordpress.com</p></div></div><div class="mn l"><div class="np l mp mq mr mn ms kp me"/></div></div></a></div><p id="dec7" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu"> <em class="kf">多元回归</em> </strong></p><div class="mb mc fm fo md me"><a href="https://dataneel.wordpress.com/2018/06/11/linear-regression-part-2/" rel="noopener  ugc nofollow" target="_blank"><div class="mf ab ej"><div class="mg ab mh cl cj mi"><h2 class="bd hu fv z el mj eo ep mk er et hs dt translated">多元回归/回归第2部分:</h2><div class="ml l"><h3 class="bd b fv z el mj eo ep mk er et ek translated">正如我们在前面的后线性回归第一部分线性回归第一部分中所讨论的，当…</h3></div><div class="mm l"><p class="bd b gc z el mj eo ep mk er et ek translated">dataneel.wordpress.com</p></div></div><div class="mn l"><div class="nq l mp mq mr mn ms kp me"/></div></div></a></div><p id="a8a4" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu"> <em class="kf">线性回归</em> </strong></p><div class="mb mc fm fo md me"><a href="https://dataneel.wordpress.com/2018/06/09/linear-regression-part-1/" rel="noopener  ugc nofollow" target="_blank"><div class="mf ab ej"><div class="mg ab mh cl cj mi"><h2 class="bd hu fv z el mj eo ep mk er et hs dt translated">线性回归第一部分</h2><div class="ml l"><h3 class="bd b fv z el mj eo ep mk er et ek translated">线性回归是最简单的监督学习类型。回归分析的目的是探索…</h3></div><div class="mm l"><p class="bd b gc z el mj eo ep mk er et ek translated">dataneel.wordpress.com</p></div></div><div class="mn l"><div class="nr l mp mq mr mn ms kp me"/></div></div></a></div><blockquote class="kw"><p id="f0c6" class="kx ky ht bd kz la ll lm ln lo lp jn ek translated">加入Coinmonks <a class="ae ma" href="https://t.me/coincodecap" rel="noopener ugc nofollow" target="_blank">电报频道</a>和<a class="ae ma" href="https://www.youtube.com/c/coinmonks/videos" rel="noopener ugc nofollow" target="_blank"> Youtube频道</a>获取每日<a class="ae ma" href="http://coincodecap.com/" rel="noopener ugc nofollow" target="_blank">加密新闻</a></p></blockquote><h2 id="15d6" class="mz na ht bd ns nt nu nv nw nx ny nz oa jb ob oc od jf oe of og jj oh oi oj ok dt translated">另外，阅读</h2><ul class=""><li id="20fb" class="jo jp ht is b it ol ix om jb on jf oo jj op jn oq ju jv jw dt translated"><a class="ae ma" href="http://Top 4 Telegram Channels for Crypto Traders" rel="noopener ugc nofollow" target="_blank">密码电报信号</a> | <a class="ae ma" rel="noopener" href="/coinmonks/crypto-trading-bot-c2ffce8acb2a">密码交易机器人</a></li><li id="14e6" class="jo jp ht is b it jx ix jy jb jz jf ka jj kb jn oq ju jv jw dt translated"><a class="ae ma" rel="noopener" href="/coinmonks/top-10-crypto-copy-trading-platforms-for-beginners-d0c37c7d698c">复制交易</a> | <a class="ae ma" rel="noopener" href="/coinmonks/crypto-tax-software-ed4b4810e338">加密税务软件</a></li><li id="723e" class="jo jp ht is b it jx ix jy jb jz jf ka jj kb jn oq ju jv jw dt translated"><a class="ae ma" href="https://coincodecap.com/grid-trading" rel="noopener ugc nofollow" target="_blank">电网交易</a> | <a class="ae ma" rel="noopener" href="/coinmonks/the-best-cryptocurrency-hardware-wallets-of-2020-e28b1c124069">加密硬件钱包</a></li><li id="f33b" class="jo jp ht is b it jx ix jy jb jz jf ka jj kb jn oq ju jv jw dt translated"><a class="ae ma" rel="noopener" href="/coinmonks/crypto-exchange-dd2f9d6f3769">加密交易所</a> | <a class="ae ma" rel="noopener" href="/coinmonks/buy-bitcoin-in-india-feb50ddfef94">印度的加密应用</a></li></ul></div></div>    
</body>
</html>