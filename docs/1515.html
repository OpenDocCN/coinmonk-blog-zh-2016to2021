<html>
<head>
<title>Convolution Neural Network - In a Nutshell</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">卷积神经网络-简而言之</h1>
<blockquote>原文：<a href="https://medium.com/coinmonks/convolutional-neural-network-in-a-nut-shell-107b5b9364ab?source=collection_archive---------9-----------------------#2018-09-17">https://medium.com/coinmonks/convolutional-neural-network-in-a-nut-shell-107b5b9364ab?source=collection_archive---------9-----------------------#2018-09-17</a></blockquote><div><div class="ef hh hi hj hk hl"/><div class="hm hn ho hp hq"><div class=""/><h1 id="21bd" class="iq ir ht bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn dt translated"><strong class="ak">常规神经网络的局限性</strong></h1><p id="f80d" class="pw-post-body-paragraph jo jp ht jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hm dt translated">在常规神经网络中，输入通过一系列具有多个神经元的隐藏层进行转换。每个神经元都连接到上一层和下一层中的所有神经元。这种排列称为全连接层，最后一层是输出层。在输入是图像的计算机视觉应用中，我们使用<a class="ae km" href="https://engmrk.com/convolutional-neural-network-3/" rel="noopener ugc nofollow" target="_blank">卷积神经网络</a>，因为常规的全连接神经网络效果不佳。这是因为如果图像的每个像素都是一个输入，那么当我们添加更多的层时，参数的数量会呈指数增长。</p><figure class="ko kp kq kr fq ks fe ff paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="fe ff kn"><img src="../Images/661a44bd30bcd8688effaf9ea6b93367.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kDagNIcoGRE1svzNAUB4Gw.jpeg"/></div></div></figure><p id="5d93" class="pw-post-body-paragraph jo jp ht jq b jr kz jt ju jv la jx jy jz lb kb kc kd lc kf kg kh ld kj kk kl hm dt translated">考虑一个例子，其中我们使用大小为1百万像素(1000高X 1000宽)的三色通道图像，那么我们的输入将具有1000 X 1000 X 3 (3百万)个特征。如果我们使用具有1000个隐藏单元的完全连接的隐藏层，那么权重矩阵将具有30亿(300万×1000)个参数。因此，常规神经网络对于图像分类来说是不可扩展的，因为处理如此大的输入在计算上非常昂贵并且不可行。另一个挑战是大量的参数会导致过度拟合。然而，当涉及到图像时，两个位置相近的单个像素之间似乎没有什么关联。这就引出了卷积的思想。</p><h1 id="ad82" class="iq ir ht bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn dt translated">什么是卷积？</h1><p id="517e" class="pw-post-body-paragraph jo jp ht jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hm dt translated"><strong class="jq hu">卷积</strong>是两个函数的数学运算，产生第三个函数，表示一个函数的形状如何被另一个函数修改。术语<em class="le">卷积</em>既指结果函数，也指计算它的过程[1]。在神经网络中，我们将对输入图像矩阵执行卷积运算，以减少其形状。在下面的例子中，我们将一个6×6的灰度图像与一个3×3的叫做过滤器或内核的矩阵进行卷积，得到一个4×4的矩阵。首先，我们将获取过滤器和图像矩阵的前9个元素之间的点积，并填充输出矩阵。然后，我们将在图像上从左到右、从上到下滑动过滤器一个方块，并执行相同的计算。最后，我们将生成一个二维的激活图，它给出了该滤波器在输入图像矩阵的每个空间位置的响应。</p><figure class="ko kp kq kr fq ks"><div class="bz el l di"><div class="lf lg l"/></div></figure><h1 id="706d" class="iq ir ht bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn dt translated">卷积带来的挑战</h1><p id="f25a" class="pw-post-body-paragraph jo jp ht jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hm dt translated"><strong class="jq hu"> 1-收缩输出</strong></p><p id="1ab7" class="pw-post-body-paragraph jo jp ht jq b jr kz jt ju jv la jx jy jz lb kb kc kd lc kf kg kh ld kj kk kl hm dt translated">卷积的一个大挑战是，如果我们在多层中执行卷积运算，我们的图像会不断缩小。比方说，如果我们的深层神经网络中有100个隐藏层，并且我们在每一层中都执行卷积运算，那么在每一个卷积层之后，我们的图像大小都会缩小一点。</p><p id="e558" class="pw-post-body-paragraph jo jp ht jq b jr kz jt ju jv la jx jy jz lb kb kc kd lc kf kg kh ld kj kk kl hm dt translated"><strong class="jq hu"> 2-图像角落的数据丢失</strong></p><p id="71f9" class="pw-post-body-paragraph jo jp ht jq b jr kz jt ju jv la jx jy jz lb kb kc kd lc kf kg kh ld kj kk kl hm dt translated">第二个缺点是，来自图像角落的像素仅在少数输出中使用，而中间区域的像素贡献更多，因此我们丢失了原始图像角落的数据。例如，左上角像素仅涉及一个输出，但是中间像素参与至少9个输出。</p><h1 id="704e" class="iq ir ht bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn dt translated">填料</h1><p id="752d" class="pw-post-body-paragraph jo jp ht jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hm dt translated">为了解决输出收缩和图像角部数据丢失的问题，我们用称为零填充的附加零边界来填充图像。零填充的大小是一个超参数。这允许我们控制输出图像的空间大小。因此，如果我们将F定义为滤波器的大小，S定义为步幅，N定义为图像的大小，P定义为所需的填充量，则图像输出大小由下式给出。</p><figure class="ko kp kq kr fq ks fe ff paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="fe ff lh"><img src="../Images/64c35a3566e384ead6f3c8f78b2f4c37.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zur2qV4PspZxQUOr37ntRA.jpeg"/></div></div><figcaption class="li lj fg fe ff lk ll bd b be z ek">Convolution on 6 x 6 image with zero padding = 1</figcaption></figure><p id="7863" class="pw-post-body-paragraph jo jp ht jq b jr kz jt ju jv la jx jy jz lb kb kc kd lc kf kg kh ld kj kk kl hm dt translated">我们可以看到，通过使用零填充作为1，我们保留了原始图像的大小。填充有两种常见的选择。当我们使用P = 0时,“有效”意味着根本没有填充，而当选择P值使得输出图像的大小等于输入图像的大小时,“相同”。就过滤器尺寸“F”而言，建议选择奇数。常见的选择有1，3，5，7…等。</p><h1 id="caa1" class="iq ir ht bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn dt translated">RGB图像上的卷积</h1><p id="afad" class="pw-post-body-paragraph jo jp ht jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hm dt translated">前面我们看到了灰度图像(6 X 6)的卷积运算。如果我们的图像是RGB，那么尺寸将是6 X 6 X 3，其中3表示颜色通道的数量。为了检测RGB图像中的特征，我们使用具有3维的过滤器，其中第3维将总是等于通道的数量。</p><figure class="ko kp kq kr fq ks"><div class="bz el l di"><div class="lf lg l"/></div></figure><h1 id="5a60" class="iq ir ht bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn dt translated">单层卷积网络</h1><p id="b012" class="pw-post-body-paragraph jo jp ht jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hm dt translated">在卷积网络的一个单层中，我们通过用不同的滤波器卷积我们的图像来检测多个特征。每个卷积运算生成不同的二维矩阵。我们给每个矩阵加上偏置，然后应用非线性。然后将它们全部堆叠在一起，形成一个三维输出。最终输出的第三维将等于卷积运算中使用的滤波器的数量。</p><figure class="ko kp kq kr fq ks"><div class="bz el l di"><div class="lf lg l"/></div></figure><h2 id="95ec" class="lm ir ht bd is ln lo lp iw lq lr ls ja jz lt lu je kd lv lw ji kh lx ly jm lz dt translated">卷积网络的维数</h2><p id="c6fd" class="pw-post-body-paragraph jo jp ht jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hm dt translated">我们将比较卷积层和常规神经网络层，以计算参数和维数的数量。</p><figure class="ko kp kq kr fq ks fe ff paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="fe ff ma"><img src="../Images/0a35cd343140d2a095ccabecdfa52109.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R7wuPKS9tDjrpnW-emxdjw.jpeg"/></div></div><figcaption class="li lj fg fe ff lk ll bd b be z ek">Dimension of Convolutional Layer Parameters</figcaption></figure><h1 id="4ff5" class="iq ir ht bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn dt translated">汇集层</h1><p id="bd8b" class="pw-post-body-paragraph jo jp ht jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hm dt translated">虽然我们的网络的总参数在卷积后减少了，但是我们仍然需要进一步压缩表示的空间大小，以减少网络中的参数和计算的数量。Pooling layer为我们做了这项工作，加快了计算速度，并使一些功能更加突出。在池层中，我们有两个超参数过滤器大小和步幅，它们只固定一次。下面是两种常见的池层类型。</p><h2 id="960e" class="lm ir ht bd is ln lo lp iw lq lr ls ja jz lt lu je kd lv lw ji kh lx ly jm lz dt translated">最大池:</h2><p id="735e" class="pw-post-body-paragraph jo jp ht jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hm dt translated">让我们考虑一个4×4的图像矩阵，我们想把它缩小到2×2。我们将使用步长为2的2×2块。我们将从每个块中获取最大值，并将其捕获到新的矩阵中。</p><figure class="ko kp kq kr fq ks"><div class="bz el l di"><div class="lf lg l"/></div><figcaption class="li lj fg fe ff lk ll bd b be z ek">Max Pooling</figcaption></figure><h2 id="604d" class="lm ir ht bd is ln lo lp iw lq lr ls ja jz lt lu je kd lv lw ji kh lx ly jm lz dt translated">平均池:</h2><p id="b6ad" class="pw-post-body-paragraph jo jp ht jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hm dt translated">在平均池中，我们取每个方块的平均值，而不是四个方块的最大值。</p><figure class="ko kp kq kr fq ks"><div class="bz el l di"><div class="lf lg l"/></div><figcaption class="li lj fg fe ff lk ll bd b be z ek">Average Pooling</figcaption></figure><h1 id="a417" class="iq ir ht bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn dt translated">卷积神经网络的体系结构</h1><p id="fb81" class="pw-post-body-paragraph jo jp ht jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hm dt translated">具有一个或多个卷积层的<a class="ae km" href="https://engmrk.com/module-14-artificial-neural-network/" rel="noopener ugc nofollow" target="_blank">神经网络</a>称为卷积神经网络(CNN)。让我们考虑一个用于图像分类的深度卷积神经网络的例子，其中输入图像大小是28 x 28 x 1(灰度)。在第一层中，我们用32个5 x 5的滤波器进行卷积运算，因此我们的输出将变成24 x 24 x 32。然后，我们将应用2 x 2过滤器池，以减少大小为12 x 12 x 32。在第二层中，我们将对64个大小为5×5的滤波器应用卷积运算。输出尺寸将成为8 x 8 x 64，我们将应用2 x 2过滤器的池层，大小将减少到4 x 4 x 64。最后，我们将通过两个完全连接的层来将我们的图像矩阵转换为分类矩阵。</p><figure class="ko kp kq kr fq ks fe ff paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="fe ff mb"><img src="../Images/d2fe8f9f8ed56b9acdcbeaf545b6f1c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CHs2-J2Gt8VbZcYTr5D3DQ.png"/></div></div><figcaption class="li lj fg fe ff lk ll bd b be z ek">The architecture of Convolutional Neural Network</figcaption></figure><h1 id="48a7" class="iq ir ht bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn dt translated">最后的话</h1><p id="b5c2" class="pw-post-body-paragraph jo jp ht jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hm dt translated">我们学习了卷积层、池化和全连接层。现在的问题是如何将这些层组合起来解决计算机视觉问题。它实际上是一门艺术，可能因问题而异。人们做了大量的研究，提出了许多CNN架构，如LeNet-5、AlexNet、VGG、ResNet等。首先将这些架构应用到您的问题上，然后根据直觉和结果做出必要的改变，这是一个很好的实践。在下一篇文章中，我们将使用Keras 实际上<a class="ae km" href="https://engmrk.com/module-22-implementation-of-cnn-using-keras/" rel="noopener ugc nofollow" target="_blank">实现一个CNN。</a></p><p id="93e8" class="pw-post-body-paragraph jo jp ht jq b jr kz jt ju jv la jx jy jz lb kb kc kd lc kf kg kh ld kj kk kl hm dt translated"><strong class="jq hu">参考文献</strong></p><ol class=""><li id="37d3" class="mc md ht jq b jr kz jv la jz me kd mf kh mg kl mh mi mj mk dt translated"><a class="ae km" href="https://en.wikipedia.org/wiki/Convolution" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Convolution</a></li><li id="ed1c" class="mc md ht jq b jr ml jv mm jz mn kd mo kh mp kl mh mi mj mk dt translated">吴恩达的卷积神经网络。(coursera.org)</li><li id="9fce" class="mc md ht jq b jr ml jv mm jz mn kd mo kh mp kl mh mi mj mk dt translated">神经网络和卷积神经网络基本训练(LinkedIn.com/learning)</li></ol><p id="4dd8" class="pw-post-body-paragraph jo jp ht jq b jr kz jt ju jv la jx jy jz lb kb kc kd lc kf kg kh ld kj kk kl hm dt translated">本文原载于<a class="ae km" href="https://engmrk.com/convolutional-neural-network-3/" rel="noopener ugc nofollow" target="_blank"><em class="le">engmrk.com</em></a></p><blockquote class="mq"><p id="8b78" class="mr ms ht bd mt mu mv mw mx my mz kl ek translated"><a class="ae km" href="https://coincodecap.com/?utm_source=coinmonks" rel="noopener ugc nofollow" target="_blank">直接在您的收件箱中获得最佳软件交易</a></p></blockquote><figure class="nb nc nd ne nf ks fe ff paragraph-image"><a href="https://coincodecap.com/?utm_source=coinmonks"><div class="fe ff na"><img src="../Images/7c0b3dfdcbfea594cc0ae7d4f9bf6fcb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1168/format:webp/0*OJ-qb5G6i863msBB.png"/></div></a></figure></div></div>    
</body>
</html>