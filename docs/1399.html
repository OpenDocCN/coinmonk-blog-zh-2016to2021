<html>
<head>
<title>Apache Spark and RDDs: Distributed resilient in-memory abstraction for ML</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Apache Spark和RDDs:ML的分布式弹性内存抽象</h1>
<blockquote>原文：<a href="https://medium.com/coinmonks/apache-spark-and-rdds-fault-tolerant-distributed-in-memory-data-processing-7e5a763d3236?source=collection_archive---------1-----------------------#2018-08-26">https://medium.com/coinmonks/apache-spark-and-rdds-fault-tolerant-distributed-in-memory-data-processing-7e5a763d3236?source=collection_archive---------1-----------------------#2018-08-26</a></blockquote><div><div class="ef hh hi hj hk hl"/><div class="hm hn ho hp hq"><div class=""/><figure class="fi fk ir is it iu fe ff paragraph-image"><div class="fe ff iq"><img src="../Images/8e34dd2c2ec7b8a9b3700ae441a6250c.png" data-original-src="https://miro.medium.com/v2/resize:fit:752/format:webp/1*Pa7PO1v7bANI7C-eHMS_PQ.png"/></div></figure><h2 id="df6a" class="ix iy ht bd iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju dt translated">介绍</h2><p id="a999" class="pw-post-body-paragraph jv jw ht jx b jy jz ka kb kc kd ke kf ji kg kh ki jm kj kk kl jq km kn ko kp hm dt translated">如今，许多应用程序依赖于繁重的数据处理，并使用迭代算法，如梯度下降或运行交互式数据挖掘查询。这些技术广泛应用于机器学习、数据分析等领域。提供这种能力的流行框架之一是Apache Spark。Spark的基础构建块是一个容错的分布式内存抽象，称为<a class="ae kq" href="https://www.usenix.org/system/files/conference/nsdi12/nsdi12-final138.pdf" rel="noopener ugc nofollow" target="_blank"> RDDs </a>(弹性分布式数据集)。这种抽象和基于它构建的框架在ML、数据挖掘算法方面比Hadoop等现有基础设施高出20倍。让我们在本帖中回顾这篇论文。</p><h2 id="e869" class="ix iy ht bd iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju dt translated">设计目标</h2><p id="7cf1" class="pw-post-body-paragraph jv jw ht jx b jy jz ka kb kc kd ke kf ji kg kh ki jm kj kk kl jq km kn ko kp hm dt translated">有许多算法，如K-means聚类、基于梯度下降的回归，其中算法在同一数据集上迭代操作。这同样适用于交互式数据挖掘查询，在这种情况下，最终用户会对相同的数据子集持续运行不同的查询。过去发明的框架，如MapReduce，使并行数据处理成为可能，但没有为这种数据重用提供有效的机制。在这些框架中执行数据重用的常见方式是将这些数据写入磁盘，然后重用它们。当处理大型数据集时，这可能有点昂贵。</p><p id="f762" class="pw-post-body-paragraph jv jw ht jx b jy kr ka kb kc ks ke kf ji kt kh ki jm ku kk kl jq kv kn ko kp hm dt translated">RDD的设计目标是:</p><ol class=""><li id="3672" class="kw kx ht jx b jy kr kc ks ji ky jm kz jq la kp lb lc ld le dt translated">为分布式共享内存提供通用的高效抽象</li><li id="7317" class="kw kx ht jx b jy lf kc lg ji lh jm li jq lj kp lb lc ld le dt translated">粗粒度的数据访问，即我们感兴趣的是优化和处理一批数据，而不是数据集中的特定键值对，就像在分布式数据库或分布式共享内存(DSM)系统中所做的那样。</li><li id="9464" class="kw kx ht jx b jy lf kc lg ji lh jm li jq lj kp lb lc ld le dt translated">高效容错。这来自最后一颗子弹。在细粒度的DSMs中，容错是昂贵的，并且通过记录键值访问或通过复制大量数据来实现。对于大型数据集来说，这是非常低效的。</li><li id="e0be" class="kw kx ht jx b jy lf kc lg ji lh jm li jq lj kp lb lc ld le dt translated">控制数据分区，以实现高效的并行数据重用和局部性。</li></ol><p id="b19c" class="pw-post-body-paragraph jv jw ht jx b jy kr ka kb kc ks ke kf ji kt kh ki jm ku kk kl jq kv kn ko kp hm dt translated">从上面可以看出，这些目标导致应用程序的解决方案可以从面向批处理的使用中受益——特别是批处理写入，不适合细粒度写入，如修改数据库中的单个值。</p><h2 id="7056" class="ix iy ht bd iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju dt translated">RDD</h2><p id="3220" class="pw-post-body-paragraph jv jw ht jx b jy jz ka kb kc kd ke kf ji kg kh ki jm kj kk kl jq km kn ko kp hm dt translated">Spark实现这些目标的方式是提供一个叫做RDD的抽象。rdd在较高层次上代表一批数据，可以通过跟踪其谱系来重新创建。RDD是通过对输入数据进行某种解析，然后对该数据进行映射或过滤转换，从输入数据集创建的，这就形成了RDD的谱系。如果此RDD丢失，则可以通过对输入数据重新运行地图/过滤器转换来重新创建。因此，rdd只能通过在磁盘数据上运行转换或通过转换其他rdd来创建。这些转变联系在一起，形成了任何给定RDD的谱系。关键点是:在失败后不能通过跟踪谱系图重新创建的rdd，在这个系统中也根本不能被引用。此外，为了提高效率，用户可以控制如何将数据划分到不同的机器上。</p><p id="be30" class="pw-post-body-paragraph jv jw ht jx b jy kr ka kb kc ks ke kf ji kt kh ki jm ku kk kl jq kv kn ko kp hm dt translated"><strong class="jx hu">rdd的编程接口:</strong>程序员使用Scala中面向对象的接口来访问rdd。他们可以使用地图、过滤、连接功能来创建RDD对象。然后，他们可以调用“操作”，如“计数”或“保存”，然后返回这些值。spark中的所有rdd都是在执行一个动作时惰性填充的。程序员可以调用“persist”方法，将数据保存到RAM中，如果没有足够的RAM，就将数据换出到磁盘中。此外，一些特定的数据可以优先考虑持久性。</p><h2 id="3ae1" class="ix iy ht bd iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju dt translated">RDDs和图形谱系</h2><p id="c24c" class="pw-post-body-paragraph jv jw ht jx b jy jz ka kb kc kd ke kf ji kg kh ki jm kj kk kl jq km kn ko kp hm dt translated">让我们看看一个简单的spark程序如何被转换成一个构建RDD谱系的图。本文中的以下示例从包含hdfs相关错误的所有行中返回第三个字段(时间戳)。</p><pre class="lk ll lm ln fq lo lp lq lr aw ls dt"><span id="d01b" class="ix iy ht lp b fv lt lu l lv lw">lines = spark.textFile(logfile)<br/>errors = lines.filter(_.startsWith("ERROR"))<br/>errors.persist()<br/>errors.filter(_.contains("HDFS")).map(_.split("\t")(3)).collect()</span></pre><p id="c77d" class="pw-post-body-paragraph jv jw ht jx b jy kr ka kb kc ks ke kf ji kt kh ki jm ku kk kl jq kv kn ko kp hm dt translated">这就是这个项目中RDD家族的形成过程:</p><figure class="lk ll lm ln fq iu fe ff paragraph-image"><div class="fe ff lx"><img src="../Images/5cade43f254efe93704d66933e9310b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:886/format:webp/1*T2Y7sTZ2Thh9cQ_iKammVg.png"/></div><figcaption class="ly lz fg fe ff ma mb bd b be z ek">time_fields RDD getting created from input log lines. Map and filter transformations along the way extract from the loglines and finally an action is taken to “collect” all the values into time_fields</figcaption></figure><p id="457f" class="pw-post-body-paragraph jv jw ht jx b jy kr ka kb kc ks ke kf ji kt kh ki jm ku kk kl jq kv kn ko kp hm dt translated">当需要收集time_field值时，即延迟收集时，Spark会将这些转换发送到节点，其中一些rdd可能已经缓存在内存中。现在，希望这能清楚地说明容错是如何工作的。如果与“错误”相关的RDD丢失，那么可以通过再次计算“行”上的滤波器变换来容易地恢复。此外，如果程序想要访问time_fields，那么它可能不需要担心“错误”RDD的失败，如果HDFS错误RDD仍然可用。</p><p id="539f" class="pw-post-body-paragraph jv jw ht jx b jy kr ka kb kc ks ke kf ji kt kh ki jm ku kk kl jq kv kn ko kp hm dt translated">还要注意的一个关键点是，RDD是不可变的，这使得恢复更容易—系统不需要担心维护操作日志，该日志跟踪RDD中的单个更改。</p><p id="f696" class="pw-post-body-paragraph jv jw ht jx b jy kr ka kb kc ks ke kf ji kt kh ki jm ku kk kl jq kv kn ko kp hm dt translated">虽然rdd是不可变的，并且适合面向批处理的写操作，但是它们决不会妨碍更细粒度的高效读操作。人们总是可以使用RDD作为阅读的查找表。</p><h2 id="eaca" class="ix iy ht bd iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju dt translated">RDD的主要组件</h2><p id="8f22" class="pw-post-body-paragraph jv jw ht jx b jy jz ka kb kc kd ke kf ji kg kh ki jm kj kk kl jq km kn ko kp hm dt translated">rdd通常使用以下主要组件表示:</p><ol class=""><li id="bde8" class="kw kx ht jx b jy kr kc ks ji ky jm kz jq la kp lb lc ld le dt translated"><em class="mc">分区:</em>分区包含数据集的原子子集。</li><li id="3c44" class="kw kx ht jx b jy lf kc lg ji lh jm li jq lj kp lb lc ld le dt translated"><em class="mc">首选位置(分区):</em>对于优化而言，将分区放在特定位置(如节点)会更有效</li><li id="d3e5" class="kw kx ht jx b jy lf kc lg ji lh jm li jq lj kp lb lc ld le dt translated"><em class="mc">依赖关系:</em>父rdd上的一组依赖关系。依赖关系有两种类型:窄依赖关系和宽依赖关系。窄依赖关系进行从父到子的一对一映射，例如在使用“映射”转换时。而广泛的依赖性是由诸如“连接”之类的转换产生的。这些表可能有一对多类型的依赖关系，因为两个表的连接可能导致更多的分区。</li><li id="1bbe" class="kw kx ht jx b jy lf kc lg ji lh jm li jq lj kp lb lc ld le dt translated"><em class="mc">迭代器(分区，父依赖):</em>通过遍历父上的依赖返回分区的元素。</li><li id="c554" class="kw kx ht jx b jy lf kc lg ji lh jm li jq lj kp lb lc ld le dt translated"><em class="mc">分区器:</em>对RDD进行分区的功能。</li></ol><p id="a9f9" class="pw-post-body-paragraph jv jw ht jx b jy kr ka kb kc ks ke kf ji kt kh ki jm ku kk kl jq kv kn ko kp hm dt translated"><strong class="jx hu">RDD创作的一些例子</strong></p><p id="380c" class="pw-post-body-paragraph jv jw ht jx b jy kr ka kb kc ks ke kf ji kt kh ki jm ku kk kl jq kv kn ko kp hm dt translated">下面是rdd之间在经历某种转换时不同类型的依赖关系的一些例子。</p><figure class="lk ll lm ln fq iu fe ff paragraph-image"><div class="fe ff md"><img src="../Images/51ad14d23b7309072e33d54a56790dc1.png" data-original-src="https://miro.medium.com/v2/resize:fit:882/format:webp/1*QLCzMO3WqtGbQ6gqidhSEQ.png"/></div><figcaption class="ly lz fg fe ff ma mb bd b be z ek">Each blue box is an RDD enclosed in partitions represented by rectangles</figcaption></figure><h2 id="bdc1" class="ix iy ht bd iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju dt translated">集群上的RDD调度</h2><p id="f611" class="pw-post-body-paragraph jv jw ht jx b jy jz ka kb kc kd ke kf ji kg kh ki jm kj kk kl jq km kn ko kp hm dt translated">在高层次上，当用户启动一个程序时，会创建一个驱动程序。驱动程序将启动工作线程，并为RDD使用的不同节点上的工作线程安排任务。</p><figure class="lk ll lm ln fq iu fe ff paragraph-image"><div class="fe ff me"><img src="../Images/ba41dc6de1550fdc21111646860f51af.png" data-original-src="https://miro.medium.com/v2/resize:fit:810/format:webp/1*cs-Qighb4JooC3G42xJrvw.png"/></div><figcaption class="ly lz fg fe ff ma mb bd b be z ek">Workers reading data blocks and then creating RDDs that get persisted to memory.</figcaption></figure><p id="49a0" class="pw-post-body-paragraph jv jw ht jx b jy kr ka kb kc ks ke kf ji kt kh ki jm ku kk kl jq kv kn ko kp hm dt translated">更详细地讨论调度，当在RDD上调用“计数”或“收集”这样的动作时，调度就开始了。它为这个程序计算rdd的谱系图。然后，它尝试构建阶段，使每个阶段包含尽可能多的rdd，这些rdd具有狭窄依赖性的流水线转换，以实现更好的协同定位。如果有任何广泛的依赖性，那么这意味着需要另一个阶段。然后，调度程序启动任务来计算每个阶段缺失的RDD分区。这一直持续到从给定阶段获得必需的rdd。</p><p id="ab69" class="pw-post-body-paragraph jv jw ht jx b jy kr ka kb kc ks ke kf ji kt kh ki jm ku kk kl jq kv kn ko kp hm dt translated">我们来举个例子。如下图所示，蓝色和灰色填充的矩形是构成相应rdd的分区。灰色分区已经在RAM中，所以不需要重新创建。首先，所有狭窄的依赖关系被映射到阶段1到3。要在G，B上执行操作，需要RDD。但是B已经在RAM中，所以调度程序可以转到阶段2。然后，它将计算缺失的分区，以得到RDD f。E中的一个分区已经可用，因此不需要创建它。一旦创建了F，就会执行导致阶段3的宽依赖(连接)。</p><figure class="lk ll lm ln fq iu fe ff paragraph-image"><div class="fe ff mf"><img src="../Images/dafa8aef4c73a25d6691552a63f91f53.png" data-original-src="https://miro.medium.com/v2/resize:fit:774/format:webp/1*kvJYhnrt_ZWDEJyHCTja2Q.png"/></div><figcaption class="ly lz fg fe ff ma mb bd b be z ek">A scheduling that illustrates A-G RDDs with action to be run on RDD G</figcaption></figure><p id="d6a1" class="pw-post-body-paragraph jv jw ht jx b jy kr ka kb kc ks ke kf ji kt kh ki jm ku kk kl jq kv kn ko kp hm dt translated">现在需要将任务映射到机器上。通常，如果任何节点对于给定的RDD具有可用的数据分区，则任务被发送到那里。如果对于给定的RDD有任何“优选位置”，那么任务被发送到那里。对于广泛的依赖性，调度程序尝试将rdd放在父rdd附近。详细的调度算法在这篇<a class="ae kq" href="https://cs.stanford.edu/~matei/papers/2010/eurosys_delay_scheduling.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>中有所涉及。这种延迟调度算法高级目标是:</p><ol class=""><li id="38e3" class="kw kx ht jx b jy kr kc ks ji ky jm kz jq la kp lb lc ld le dt translated">使用<a class="ae kq" href="https://en.wikipedia.org/wiki/Max-min_fairness" rel="noopener ugc nofollow" target="_blank">最小-最大公平调度</a>维护来话任务的资源公平。这通常是关键问题，也是需要处理的问题——当一份新工作到来时，该怎么办？我们如何以及何时为其分配资源？如果集群被两个任务占据，每个任务使用50%或资源，并且有一个新的任务进来，那么理想的情况是，这三个任务都应该得到1/3或资源。但是，既然任务已经在运行，我们应该终止任务还是等待它完成？像在内核调度器中一样，在大型分布式系统中，抢占是很昂贵的——节省状态不是小事。上面提到的论文更详细地描述了在有限的时间内等待工作完成(稍微放松一下公平性)是如何工作的，也有助于将任务放在包含数据的节点上。</li><li id="024d" class="kw kx ht jx b jy lf kc lg ji lh jm li jq lj kp lb lc ld le dt translated">使用数据局部性，将任务放置在数据所在的位置，以实现高效的执行模式</li></ol><p id="f634" class="pw-post-body-paragraph jv jw ht jx b jy kr ka kb kc ks ke kf ji kt kh ki jm ku kk kl jq kv kn ko kp hm dt translated">显然，有些任务可能无法运行，或者可能因为早期的失败而被阻止。在这种情况下，问题会回到为谱系中失败的rdd重新提交任务。</p><h2 id="4cea" class="ix iy ht bd iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju dt translated">检查点</h2><p id="8b11" class="pw-post-body-paragraph jv jw ht jx b jy jz ka kb kc kd ke kf ji kg kh ki jm kj kk kl jq km kn ko kp hm dt translated">正如我们之前提到的，rdd是不可变的，并且它们可以从谱系图中恢复。在一些使用RDD范式的例子中，谱系图可以增长很多。考虑一个像PageRank这样的迭代例子。在PageRank中，在每次迭代中，都会对输入文件进行解析，以从中获取链接。然后，它向其链接的文档发送稿件。然后根据收到的稿件计算每份文件的排名。这就是PageRank算法的谱系图在Spark中的样子:</p><figure class="lk ll lm ln fq iu fe ff paragraph-image"><div class="fe ff mg"><img src="../Images/706056b60d41dc9910e7e85d0767c5d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:804/format:webp/1*r8rhECjxlpZgwsE92IFACw.png"/></div><figcaption class="ly lz fg fe ff ma mb bd b be z ek">Page Rank’s graph lineage grows with every iteration as RDDs are immutable and new ranks, contribs RDDs get created</figcaption></figure><p id="320b" class="pw-post-body-paragraph jv jw ht jx b jy kr ka kb kc ks ke kf ji kt kh ki jm ku kk kl jq kv kn ko kp hm dt translated">对于这种情况，检查一些特定的RDD以加快恢复速度可能会有所帮助。对于具有琐碎谱系图的应用程序，检查点是不必要的。由于rdd的不变性，检查点实现更容易——在后台编写。在进行检查点操作时，人们不需要担心rdd的锁定和更改。潜在地，调度程序也可以基于它所拥有的关于RDD计算的知识来进行检查点操作。</p><h2 id="98cf" class="ix iy ht bd iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju dt translated">rdd和使用它表达现有范例</h2><p id="6e12" class="pw-post-body-paragraph jv jw ht jx b jy jz ka kb kc kd ke kf ji kg kh ki jm kj kk kl jq km kn ko kp hm dt translated">让我们看看RDD有多普遍，它如何表达一些现有的范式。</p><p id="0b78" class="pw-post-body-paragraph jv jw ht jx b jy kr ka kb kc ks ke kf ji kt kh ki jm ku kk kl jq kv kn ko kp hm dt translated"><strong class="jx hu"> MapReduce: </strong> Flatmap和group/by-key reduce可以表达这一范式</p><p id="9070" class="pw-post-body-paragraph jv jw ht jx b jy kr ka kb kc ks ke kf ji kt kh ki jm ku kk kl jq kv kn ko kp hm dt translated"><a class="ae kq" href="https://www.microsoft.com/en-us/research/project/dryadlinq/" rel="noopener ugc nofollow" target="_blank"><strong class="jx hu">DyradLINQ</strong></a><strong class="jx hu">:</strong>我以前对这个框架没有太多的了解。但是它允许人们使用SQL来表达对跨多个集群的大型数据集的查询。它主要支持对可以用rdd表示的大数据进行批量操作。</p><p id="3f60" class="pw-post-body-paragraph jv jw ht jx b jy kr ka kb kc ks ke kf ji kt kh ki jm ku kk kl jq kv kn ko kp hm dt translated"><strong class="jx hu"> Pregel: </strong> Pregel对于基于图形的算法很有用，比如PageRank和最短路径。在每一步中，Pregel将相同的函数应用于由pregel图中的顶点表示的数据。所以每个顶点数据可以用rdd来表示，然后函数可以被映射到变换。</p><p id="0d72" class="pw-post-body-paragraph jv jw ht jx b jy kr ka kb kc ks ke kf ji kt kh ki jm ku kk kl jq kv kn ko kp hm dt translated"><strong class="jx hu">迭代MapReduce: </strong>这些应用程序对相同的数据运行多次map-reduce迭代。这非常符合RDD模式。Spark作者能够用200行代码实现HaLoop。</p><p id="8d74" class="pw-post-body-paragraph jv jw ht jx b jy kr ka kb kc ks ke kf ji kt kh ki jm ku kk kl jq kv kn ko kp hm dt translated"><strong class="jx hu">批量流处理:</strong>许多应用使用最近几分钟的状态来更新模型的当前状态，例如使用最近窗口的点击流数据来进行实时广告决策。这些系统对相同的数据进行转换，然后将其存储在磁盘上。他们可以通过将这些中间结果存储在RDD中，使用RDD模型进行更快的处理。</p><h2 id="e321" class="ix iy ht bd iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju dt translated">结论</h2><p id="74e9" class="pw-post-body-paragraph jv jw ht jx b jy jz ka kb kc kd ke kf ji kg kh ki jm kj kk kl jq km kn ko kp hm dt translated">虽然rdd看起来因为不变性和批量操作依赖性而受到根本限制，但这些是在数据繁重的并行集群计算系统中使用的基本原语。所以rdd非常适合这一点。内存中的计算对于加速来说是显而易见的，但是基于图谱系的方法有助于容错机制，这对于严重依赖内存操作的系统来说是必需的。</p><blockquote class="mh"><p id="4c1e" class="mi mj ht bd mk ml mm mn mo mp mq kp ek translated"><a class="ae kq" href="https://coincodecap.com/?utm_source=coinmonks" rel="noopener ugc nofollow" target="_blank">直接在您的收件箱中获得最佳软件交易</a></p></blockquote><figure class="ms mt mu mv mw iu fe ff paragraph-image"><a href="https://coincodecap.com/?utm_source=coinmonks"><div class="fe ff mr"><img src="../Images/7c0b3dfdcbfea594cc0ae7d4f9bf6fcb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1168/format:webp/0*OJ-qb5G6i863msBB.png"/></div></a></figure></div></div>    
</body>
</html>