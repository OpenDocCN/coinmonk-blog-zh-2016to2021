<html>
<head>
<title>Review: AlexNet, CaffeNet — Winner of ILSVRC 2012 (Image Classification)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">回顾:AlexNet，CaffeNet——2012年ILSVRC(图像分类)获奖者</h1>
<blockquote>原文：<a href="https://medium.com/coinmonks/paper-review-of-alexnet-caffenet-winner-in-ilsvrc-2012-image-classification-b93598314160?source=collection_archive---------0-----------------------#2018-08-09">https://medium.com/coinmonks/paper-review-of-alexnet-caffenet-winner-in-ilsvrc-2012-image-classification-b93598314160?source=collection_archive---------0-----------------------#2018-08-09</a></blockquote><div><div class="ef hh hi hj hk hl"/><div class="hm hn ho hp hq"><div class=""/><p id="8dfa" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">在这个故事中，<strong class="is hu"> AlexNet </strong>和<strong class="is hu"> CaffeNet </strong>被回顾。AlexNet是ILSVRC (  <a class="ae jo" href="http://www.image-net.org/challenges/LSVRC/" rel="noopener ugc nofollow" target="_blank"> <strong class="is hu"> ImageNet大规模视觉识别竞赛</strong> </a> <strong class="is hu"> ) 2012 </strong>的<strong class="is hu">冠军，这是一项图像分类竞赛。</strong></p><p id="5ffd" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">这是2012年NIPS的一篇论文，来自辛顿教授的小组，在我写这篇文章的时候，引用了大约28000次。在深度学习方面有了<strong class="is hu">的本质突破，大幅降低了ILSVRC 2012 </strong>的错误率，如下图所示。因此，这是一篇必读的论文！！(<a class="jp jq gr" href="https://medium.com/u/aff72a0c1243?source=post_page-----b93598314160--------------------------------" rel="noopener" target="_blank"> Sik-Ho Tsang </a> @中)</p><p id="513d" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">ImageNet是一个数据集，包含超过1500万张带有标签的高分辨率图像，大约有22，000个类别。ILSVRC在1000个类别中的每个类别中使用大约1000个图像的ImageNet子集。总的来说，大约有120万幅训练图像、50，000幅验证图像和150，000幅测试图像。</p><figure class="js jt ju jv fq jw fe ff paragraph-image"><div class="fe ff jr"><img src="../Images/f3480dc2e315a172500ab7546fe03706.png" data-original-src="https://miro.medium.com/v2/resize:fit:1316/format:webp/1*BASjitcB1kbfc0LH-Jtwjw.png"/></div><figcaption class="jz ka fg fe ff kb kc bd b be z ek"><strong class="bd kd">AlexNet, the winner in ILSVRC 2012 image classification with remarkable lower error rate</strong></figcaption></figure><p id="a69a" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">A.对于<strong class="is hu"> AlexNet </strong>，我们将涵盖:</p><ol class=""><li id="2155" class="ke kf ht is b it iu ix iy jb kg jf kh jj ki jn kj kk kl km dt translated"><strong class="is hu">建筑</strong></li><li id="a8d2" class="ke kf ht is b it kn ix ko jb kp jf kq jj kr jn kj kk kl km dt translated"><strong class="is hu"> ReLU(整流线性单元)</strong></li><li id="ab7b" class="ke kf ht is b it kn ix ko jb kp jf kq jj kr jn kj kk kl km dt translated"><strong class="is hu">多个GPU</strong></li><li id="9b34" class="ke kf ht is b it kn ix ko jb kp jf kq jj kr jn kj kk kl km dt translated"><strong class="is hu">局部反应正常化</strong></li><li id="1f2b" class="ke kf ht is b it kn ix ko jb kp jf kq jj kr jn kj kk kl km dt translated"><strong class="is hu">重叠池</strong></li><li id="373f" class="ke kf ht is b it kn ix ko jb kp jf kq jj kr jn kj kk kl km dt translated"><strong class="is hu">数据扩充</strong></li><li id="e89d" class="ke kf ht is b it kn ix ko jb kp jf kq jj kr jn kj kk kl km dt translated"><strong class="is hu">辍学</strong></li><li id="6ca3" class="ke kf ht is b it kn ix ko jb kp jf kq jj kr jn kj kk kl km dt translated"><strong class="is hu">学习参数的其他细节</strong></li><li id="f22c" class="ke kf ht is b it kn ix ko jb kp jf kq jj kr jn kj kk kl km dt translated"><strong class="is hu">结果</strong></li></ol><p id="242a" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">B.对于<strong class="is hu"> CaffeNet </strong>，它只是一个<strong class="is hu">单GPU版本的AlexNet </strong>。由于通常情况下，人们只会有一个GPU，CaffeNet是一个模拟AlexNet的单GPU网络。在这个故事的结尾，我们也会谈到这一点。</p><p id="72af" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">通过浏览每个组件，我们可以知道每个组件的重要性。其中一些现在已经没什么用了。但它们确实激发了其他网络的发明。</p></div><div class="ab cl ks kt hb ku" role="separator"><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx"/></div><div class="hm hn ho hp hq"><h1 id="4fca" class="kz la ht bd lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw dt translated"><strong class="ak"> A. AlexNet </strong></h1><h2 id="4a38" class="lx la ht bd lb ly lz ma lf mb mc md lj jb me mf ln jf mg mh lr jj mi mj lv mk dt translated">1.体系结构</h2><figure class="js jt ju jv fq jw fe ff paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="fe ff ml"><img src="../Images/0548fc6e2efa5f1633d6475f91659587.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wzflNwJw9QkjWWvTosXhNw.png"/></div></div><figcaption class="jz ka fg fe ff kb kc bd b be z ek"><strong class="bd kd">AlexNet</strong></figcaption></figure><p id="c0a6" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">AlexNet包含<strong class="is hu">八层</strong>:</p><p id="3431" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">输入:227×227×3的输入图像(文中和图中提到了224×224×3的大小，但后来指出应该是227，或者在第一次卷积时填充了224×224×3。)</p><p id="03bb" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu">第1层:卷积层:2组48个核，大小11×11×3 <br/>(步距:4，填充:0)</strong>T3】输出55×55 ×48特征图×2组<br/>然后<strong class="is hu"> 3×3重叠最大池(步距:2) <br/> </strong>输出27×27 ×48特征图×2组<br/>然后<strong class="is hu">局部响应归一化<br/> </strong>输出27×27 ×48特征图×2组</p><p id="6bca" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu">第二:卷积层:2组128个大小为5×5×48的核<br/>(步距:1，填充:2) <br/> </strong>输出27×27 ×128个特征映射×2组<strong class="is hu"> <br/> </strong>然后<strong class="is hu"> 3×3重叠最大池(步距:2) <br/> </strong>输出13×13 ×128个特征映射×2组<br/>然后<strong class="is hu">局部响应归一化<br/> </strong>输出</p><p id="ea5c" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu">第三:卷积层:2组192个大小为3×3×256的核<br/>(步距:1，pad: 1) <br/> </strong>输出13×13 ×192个特征图×2组</p><p id="cbee" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu">第四:卷积层:2组192个大小为3×3×192的核<br/> (stride: 1，pad: 1) <br/> </strong>输出13×13 ×192个特征图×2组</p><p id="02cd" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu">第5:卷积层:256个大小为3×3×192的核<br/>(步距:1，填充:1) <br/> </strong>输出13×13 ×128个特征图×2组<br/>然后<strong class="is hu"> 3×3重叠最大池(步距:2) <br/> </strong>输出6×6 ×128个特征图×2组</p><p id="48ac" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu">第六层:<br/> </strong> 4096神经元的全连接(密集)层</p><p id="e55a" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu">第7层:<br/> </strong> 4096神经元的全连接(密集)层</p><p id="dd3c" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu">第8层:<br/> </strong>全连接(密集)层输出1000个神经元(既然有1000个类)<br/> <strong class="is hu"> Softmax </strong>用于计算损耗。</p><p id="c9e6" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">总共有6000万个参数需要训练！！！</p></div><div class="ab cl ks kt hb ku" role="separator"><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx"/></div><div class="hm hn ho hp hq"><h2 id="34e9" class="lx la ht bd lb ly lz ma lf mb mc md lj jb me mf ln jf mg mh lr jj mi mj lv mk dt translated">2.热卢</h2><figure class="js jt ju jv fq jw fe ff paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="fe ff mq"><img src="../Images/d3c34779e0e432fd68d7285622f595a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0xbrAtkfZxVDl3RXUvAM_A.png"/></div></div><figcaption class="jz ka fg fe ff kb kc bd b be z ek"><strong class="bd kd">Activation function</strong></figcaption></figure><p id="7581" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">在Alexnet之前，使用的是Tanh。<strong class="is hu"> ReLU是AlexNet中介绍的。</strong><br/><strong class="is hu">ReLU比Tanh </strong>快6倍达到25%的训练错误率。</p></div><div class="ab cl ks kt hb ku" role="separator"><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx"/></div><div class="hm hn ho hp hq"><h2 id="9133" class="lx la ht bd lb ly lz ma lf mb mc md lj jb me mf ln jf mg mh lr jj mi mj lv mk dt translated">3.<strong class="ak">多个GPU</strong></h2><p id="3837" class="pw-post-body-paragraph iq ir ht is b it mr iv iw ix ms iz ja jb mt jd je jf mu jh ji jj mv jl jm jn hm dt translated">目前使用的是NVIDIA GTX 580 GPU，只有3GB内存。因此，我们可以在架构中看到，它们分成两条路径，并使用2个GPU进行卷积。内部通信只发生在一个特定的卷积层。</p><p id="462a" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu">因此，使用2个GPU，是由于内存问题，而不是为了加快训练过程。</strong></p><p id="8c7d" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">全网<strong class="is hu">与只有一半内核</strong>(只有一条路径)的网相比，<strong class="is hu"> Top-1和top-5错误率分别降低1.7%和1.2%。</strong></p></div><div class="ab cl ks kt hb ku" role="separator"><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx"/></div><div class="hm hn ho hp hq"><h2 id="c26d" class="lx la ht bd lb ly lz ma lf mb mc md lj jb me mf ln jf mg mh lr jj mi mj lv mk dt translated"><strong class="ak"> 4。本地响应标准化</strong></h2><figure class="js jt ju jv fq jw fe ff paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="fe ff mw"><img src="../Images/8bd939c6c763249c1bd1379c11a0b83c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*78qCGHQ7HQwPdCiEQhQJaQ.png"/></div></div><figcaption class="jz ka fg fe ff kb kc bd b be z ek"><strong class="bd kd">Normalization</strong></figcaption></figure><p id="fc7e" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu">在AlexNet中，使用局部响应归一化</strong>。正如我们在方程中看到的，它不同于批量归一化。标准化有助于加速收敛。现在使用批量规范化，而不是使用局部响应规范化。</p><p id="9837" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu">通过局部响应归一化，前1名和前5名错误率分别降低了1.4%和1.2%。</strong></p></div><div class="ab cl ks kt hb ku" role="separator"><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx"/></div><div class="hm hn ho hp hq"><h2 id="a33b" class="lx la ht bd lb ly lz ma lf mb mc md lj jb me mf ln jf mg mh lr jj mi mj lv mk dt translated"><strong class="ak"> 5。重叠池</strong></h2><p id="3254" class="pw-post-body-paragraph iq ir ht is b it mr iv iw ix ms iz ja jb mt jd je jf mu jh ji jj mv jl jm jn hm dt translated">重叠池是跨度小于内核大小的池，而非重叠池是跨度等于或大于内核大小的池。</p><p id="ddd8" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu">通过重叠池，前1名和前5名的错误率分别降低了0.4%和0.3%。</strong></p></div><div class="ab cl ks kt hb ku" role="separator"><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx"/></div><div class="hm hn ho hp hq"><h2 id="a4ac" class="lx la ht bd lb ly lz ma lf mb mc md lj jb me mf ln jf mg mh lr jj mi mj lv mk dt translated"><strong class="ak"> 6。数据扩充</strong></h2><p id="b434" class="pw-post-body-paragraph iq ir ht is b it mr iv iw ix ms iz ja jb mt jd je jf mu jh ji jj mv jl jm jn hm dt translated">数据扩充的两种形式。</p><p id="7c5b" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu">首先:图像平移和水平反射(镜像)</strong></p><p id="5427" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">从一幅256×256加上水平反射的图像中提取随机的224×224。训练集的大小增加了2048倍。这可以通过以下方式计算:</p><p id="c767" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">通过图像转换:(256–224)= 32 = 1024</p><p id="f257" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">水平反射:1024 × 2 = 2048</p><p id="cfcf" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">在测试时，使用四个角点补片加上中心补片及其对应的水平反射(共10个补片)进行预测，并对所有结果取平均值，得到最终的分类结果。</p><p id="ef27" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu">第二:改变强度</strong></p><p id="ded7" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">在训练集上执行PCA。对于每个训练图像，添加数量:</p><figure class="js jt ju jv fq jw fe ff paragraph-image"><div class="fe ff mx"><img src="../Images/8cb51a6629987a1f0ba2d0476250143a.png" data-original-src="https://miro.medium.com/v2/resize:fit:842/format:webp/1*LJHkWJIsUpE643bsAJ3fSg.png"/></div><figcaption class="jz ka fg fe ff kb kc bd b be z ek"><strong class="bd kd">Quantity of intensity altered</strong></figcaption></figure><p id="afaf" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">其中pi和λi分别是RGB像素值的3×3协方差矩阵的第I个特征向量和特征值，αi是均值为0、标准差为0.1的随机变量。</p><p id="9f11" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu">通过数据扩充增加训练集的规模，Top-1错误率降低了1%以上。</strong></p></div><div class="ab cl ks kt hb ku" role="separator"><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx"/></div><div class="hm hn ho hp hq"><h2 id="272f" class="lx la ht bd lb ly lz ma lf mb mc md lj jb me mf ln jf mg mh lr jj mi mj lv mk dt translated"><strong class="ak"> 7。辍学</strong></h2><figure class="js jt ju jv fq jw fe ff paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="fe ff my"><img src="../Images/4bf434bb0995a905476ddc6b73a3d740.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Kpi65HoIfRmXF070Tvn3yQ.png"/></div></div><figcaption class="jz ka fg fe ff kb kc bd b be z ek"><strong class="bd kd">Dropout</strong></figcaption></figure><p id="9c00" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">在使用丢弃的层中，在训练期间，每个神经元都有可能不对前馈传递做出贡献并参与反向传播。因此，每个神经元可以有更大的机会被训练，而不是太依赖于一些非常“强”的神经元。</p><p id="2405" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">在测试期间，不会出现辍学现象。</p><p id="03cb" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu">在AlexNet中，概率0.5用于前两个全连接层。丢弃是一种减少过拟合的正则化技术。</strong></p></div><div class="ab cl ks kt hb ku" role="separator"><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx"/></div><div class="hm hn ho hp hq"><h2 id="ee69" class="lx la ht bd lb ly lz ma lf mb mc md lj jb me mf ln jf mg mh lr jj mi mj lv mk dt translated">8.<strong class="ak">学习参数的其他细节</strong></h2><p id="b12c" class="pw-post-body-paragraph iq ir ht is b it mr iv iw ix ms iz ja jb mt jd je jf mu jh ji jj mv jl jm jn hm dt translated">批量:128 <br/>动量v: 0.9 <br/>重量衰减:0.0005 <br/>学习率ϵ: 0.01，验证错误率停止改善时手动减少10，减少3倍。</p><figure class="js jt ju jv fq jw fe ff paragraph-image"><div class="fe ff mz"><img src="../Images/4c379d15f3166bc0880ca96d1263c7d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1372/format:webp/1*IS_6CXy7n2OuzwLza3HMbg.png"/></div><figcaption class="jz ka fg fe ff kb kc bd b be z ek"><strong class="bd kd">The update of momentum v and weight w</strong></figcaption></figure><p id="55de" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">120万幅图像的训练集。网络被训练大约90个周期。在两个英伟达GTX 580 3GB GPU上运行五到六天。</p></div><div class="ab cl ks kt hb ku" role="separator"><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx"/></div><div class="hm hn ho hp hq"><h2 id="2d20" class="lx la ht bd lb ly lz ma lf mb mc md lj jb me mf ln jf mg mh lr jj mi mj lv mk dt translated">9.结果</h2><figure class="js jt ju jv fq jw fe ff paragraph-image"><div class="fe ff na"><img src="../Images/c747f4a015ed0abefe93709a80776608.png" data-original-src="https://miro.medium.com/v2/resize:fit:996/format:webp/1*smRLSU3A36OobD3VWpr97w.png"/></div><figcaption class="jz ka fg fe ff kb kc bd b be z ek"><strong class="bd kd">Error Rate in ILSVRC 2010</strong></figcaption></figure><p id="55ec" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu">对于ILSVRC 2010，AlexNet获得了前1名和前5名的错误率，分别为37.5%和17.0%，优于其他方法。</strong></p><p id="2c93" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu">没有通过数据增强对十个补丁的十个预测</strong>进行平均，<strong class="is hu"> AlexNet只得到前1名和前5名的错误率，分别为39.0%和18.3%。</strong></p><figure class="js jt ju jv fq jw fe ff paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="fe ff nb"><img src="../Images/317e10a72d6d36114aeaf1dbb6aac042.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bnwxbfnMjl1Qdu1u6fw0Jw.png"/></div></div><figcaption class="jz ka fg fe ff kb kc bd b be z ek"><strong class="bd kd">Error Rate in ILSVRC 2012</strong></figcaption></figure><p id="929e" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">通过<strong class="is hu"> 1 AlexNet (1 CNN) </strong>，验证错误率为<strong class="is hu"> 18.2% </strong>。</p><p id="fe50" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">通过<strong class="is hu">平均来自5个AlexNet (5个CNN)</strong>的预测，错误率降低到<strong class="is hu"> 16.4% </strong>。这是一种已经在LeNet中用于数字分类的增强技术。</p><p id="2bf2" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">通过<strong class="is hu">在AlexNet (1 CNN*) </strong>上多加一层卷积层，验证错误率降低到<strong class="is hu"> 16.6% </strong>。</p><p id="fabf" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">通过<strong class="is hu">对2个修改后的AlexNet和5个原始AlexNet (7个CNNs*) </strong>的预测进行平均，验证错误率降低到<strong class="is hu"> 15.4% </strong>。</p><figure class="js jt ju jv fq jw fe ff paragraph-image"><div class="fe ff nc"><img src="../Images/32e7b984564d7654bef8fbc8e838ca55.png" data-original-src="https://miro.medium.com/v2/resize:fit:1116/format:webp/1*tnFwtQfQUsPsmFmOlJtUSw.png"/></div><figcaption class="jz ka fg fe ff kb kc bd b be z ek"><strong class="bd kd">Some Top-5 results by AlexNet</strong></figcaption></figure></div><div class="ab cl ks kt hb ku" role="separator"><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx"/></div><div class="hm hn ho hp hq"><h1 id="6992" class="kz la ht bd lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw dt translated">B.卡芬内</h1><p id="d64c" class="pw-post-body-paragraph iq ir ht is b it mr iv iw ix ms iz ja jb mt jd je jf mu jh ji jj mv jl jm jn hm dt translated"><strong class="is hu"> CaffeNet是AlexNet </strong>的1-GPU版本。该架构是:</p><figure class="js jt ju jv fq jw fe ff paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="fe ff ml"><img src="../Images/c2547c42700fc0bcb71b52f7b9a7e4d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UDH-Shn5KbVTeuxt5mzHaA.png"/></div></div><figcaption class="jz ka fg fe ff kb kc bd b be z ek"><strong class="bd kd">CaffeNet</strong></figcaption></figure><p id="fbe1" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">我们可以看到，AlexNet中的2条路径合并成了一条路径。</p><p id="6228" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">值得注意的是，对于早期版本的CaffeNet，池化和规范化层的顺序是颠倒的，这是偶然的。但是在Caffe提供的CaffeNet的当前版本中，它已经为Caffenet提供了池化和规范化层的正确顺序。</p></div><div class="ab cl ks kt hb ku" role="separator"><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx"/></div><div class="hm hn ho hp hq"><p id="4955" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">逐一考察每一个成分，就可以知道每一个成分的有效性。: )</p><p id="c1ad" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">有兴趣的话，还有一个关于使用Nvidia-Docker和Caffe的<a class="ae jo" rel="noopener" href="/@sh.tsang/very-quick-setup-of-caffenet-alexnet-for-image-classification-using-nvidia-docker-2-0-c3b75bb8c7a8"> CaffeNet快速设置教程</a>【3】。</p></div><div class="ab cl ks kt hb ku" role="separator"><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx"/></div><div class="hm hn ho hp hq"><h1 id="d752" class="kz la ht bd lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw dt translated">参考</h1><ol class=""><li id="b793" class="ke kf ht is b it mr ix ms jb nd jf ne jj nf jn kj kk kl km dt translated">【2012 NIPS】【Alex net】<br/><a class="ae jo" href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf" rel="noopener ugc nofollow" target="_blank">使用深度卷积神经网络的ImageNet分类</a></li><li id="0111" class="ke kf ht is b it kn ix ko jb kp jf kq jj kr jn kj kk kl km dt translated">【2014 ACM MM】【CaffeNet】<br/><a class="ae jo" href="https://ucb-icsi-vision-group.github.io/caffe-paper/caffe.pdf" rel="noopener ugc nofollow" target="_blank">Caffe:用于快速特征嵌入的卷积架构</a></li><li id="68ea" class="ke kf ht is b it kn ix ko jb kp jf kq jj kr jn kj kk kl km dt translated"><a class="ae jo" rel="noopener" href="/@sh.tsang/very-quick-setup-of-caffenet-alexnet-for-image-classification-using-nvidia-docker-2-0-c3b75bb8c7a8">使用Nvidia-Docker 2.0+CUDA+cud nn+Jupyter Notebook+Caffe快速设置CaffeNet (AlexNet)进行图像分类</a></li><li id="d656" class="ke kf ht is b it kn ix ko jb kp jf kq jj kr jn kj kk kl km dt translated">ils vrc<br/>T35】ImageNet大型视觉识别比赛</li></ol><blockquote class="ng"><p id="a7c0" class="nh ni ht bd nj nk nl nm nn no np jn ek translated">加入Coinmonks <a class="ae jo" href="https://t.me/coincodecap" rel="noopener ugc nofollow" target="_blank">电报频道</a>和<a class="ae jo" href="https://www.youtube.com/c/coinmonks/videos" rel="noopener ugc nofollow" target="_blank"> Youtube频道</a>获取每日<a class="ae jo" href="http://coincodecap.com/" rel="noopener ugc nofollow" target="_blank">加密新闻</a></p></blockquote><h2 id="15d6" class="lx la ht bd lb ly nq ma lf mb nr md lj jb ns mf ln jf nt mh lr jj nu mj lv mk dt translated">另外，阅读</h2><ul class=""><li id="20fb" class="ke kf ht is b it mr ix ms jb nd jf ne jj nf jn nv kk kl km dt translated"><a class="ae jo" rel="noopener" href="/coinmonks/top-10-crypto-copy-trading-platforms-for-beginners-d0c37c7d698c">复制交易</a> | <a class="ae jo" rel="noopener" href="/coinmonks/crypto-tax-software-ed4b4810e338">加密税务软件</a></li><li id="723e" class="ke kf ht is b it kn ix ko jb kp jf kq jj kr jn nv kk kl km dt translated"><a class="ae jo" href="https://coincodecap.com/grid-trading" rel="noopener ugc nofollow" target="_blank">网格交易</a> | <a class="ae jo" rel="noopener" href="/coinmonks/the-best-cryptocurrency-hardware-wallets-of-2020-e28b1c124069">加密硬件钱包</a></li><li id="874f" class="ke kf ht is b it kn ix ko jb kp jf kq jj kr jn nv kk kl km dt translated"><a class="ae jo" href="http://Top 4 Telegram Channels for Crypto Traders" rel="noopener ugc nofollow" target="_blank">密码电报信号</a> | <a class="ae jo" rel="noopener" href="/coinmonks/crypto-trading-bot-c2ffce8acb2a">密码交易机器人</a></li><li id="f33b" class="ke kf ht is b it kn ix ko jb kp jf kq jj kr jn nv kk kl km dt translated"><a class="ae jo" rel="noopener" href="/coinmonks/crypto-exchange-dd2f9d6f3769">最佳加密交易所</a> | <a class="ae jo" rel="noopener" href="/coinmonks/bitcoin-exchange-in-india-7f1fe79715c9">印度最佳加密交易所</a></li><li id="47a8" class="ke kf ht is b it kn ix ko jb kp jf kq jj kr jn nv kk kl km dt translated">开发人员的最佳加密API</li><li id="b359" class="ke kf ht is b it kn ix ko jb kp jf kq jj kr jn nv kk kl km dt translated">最佳<a class="ae jo" rel="noopener" href="/coinmonks/top-5-crypto-lending-platforms-in-2020-that-you-need-to-know-a1b675cec3fa">密码借贷平台</a></li><li id="9487" class="ke kf ht is b it kn ix ko jb kp jf kq jj kr jn nv kk kl km dt translated">杠杆代币的终极指南</li></ul></div></div>    
</body>
</html>