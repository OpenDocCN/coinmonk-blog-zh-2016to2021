<html>
<head>
<title>Dealing with Missing Data using R</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用R处理缺失数据</h1>
<blockquote>原文：<a href="https://medium.com/coinmonks/dealing-with-missing-data-using-r-3ae428da2d17?source=collection_archive---------1-----------------------#2018-06-29">https://medium.com/coinmonks/dealing-with-missing-data-using-r-3ae428da2d17?source=collection_archive---------1-----------------------#2018-06-29</a></blockquote><div><div class="ef hh hi hj hk hl"/><div class="hm hn ho hp hq"><div class=""/><p id="8f07" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">大家好，</p><p id="2fd3" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">我是Harshitha，这是我第一篇关于媒体的文章。我打算尽我所能帮助我的数据科学爱好者，所以我在这里写了一个每个人都应该掌握的重要主题。</p><p id="c5ed" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">数据科学融合了三个主要领域:<strong class="is hu">数学、技术和商业战略。</strong>数学是数据科学的心脏和核心。在我们对数据应用任何算法之前，很明显，数据应该是整齐的或结构化的。但在现实世界中，我们最初看到的数据大多是非结构化的。因此，为了使其整洁，并进一步应用任何算法来获得洞察力，必须清理数据。数据不整齐的主要原因是因为缺失值和异常值的存在。</p><figure class="jo jp jq jr fq js"><div class="bz el l di"><div class="jt ju l"/></div></figure><p id="8e0a" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">在我们处理缺失数据之前，最好先检查缺失数据的数量。在R中，我们有不同的包来处理丢失的数据。</p><blockquote class="jv jw jx"><p id="f311" class="iq ir jy is b it iu iv iw ix iy iz ja jz jc jd je ka jg jh ji kb jk jl jm jn hm dt translated">例如:为了检查丢失的数据，我们在R</p></blockquote><ul class=""><li id="8212" class="kc kd ht is b it iu ix iy jb ke jf kf jj kg jn kh ki kj kk dt translated">以下命令按列给出整个数据框中缺失值的总和:</li></ul><p id="2269" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu"> <em class="jy"> colsum(is.na(数据帧))</em> </strong></p><ul class=""><li id="8b59" class="kc kd ht is b it iu ix iy jb ke jf kf jj kg jn kh ki kj kk dt translated">以下命令给出特定列中缺失值的总和。此命令也可能会产生误导，因为缺失值实际上被视为空值，而不是na，sum(is.na())只对数据集中值被赋为NA的值求和。因此，在读取r中的数据集时，设置<strong class="is hu"> na.string = True </strong>。</li></ul><p id="0391" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu"> <em class="jy"> sum(is.na(数据帧$列名)</em> </strong></p><p id="fea5" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu">缺失值可以用以下方法处理</strong>:</p><ol class=""><li id="b552" class="kc kd ht is b it iu ix iy jb ke jf kf jj kg jn kl ki kj kk dt translated"><strong class="is hu">删除:</strong>当缺失变量的概率对于所有观测值都相同时，使用删除方法。</li></ol><blockquote class="jv jw jx"><p id="b750" class="iq ir jy is b it iu iv iw ix iy iz ja jz jc jd je ka jg jh ji kb jk jl jm jn hm dt translated">例如:数据收集过程中的受访者决定在抛公平硬币后宣布他们的收入。如果出现head，被调查者申报他/她的收入，反之亦然。在这里，每个观察值都有相同的丢失值的机会。</p></blockquote><p id="5b6b" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">删除可以以两种方式执行:列表删除和成对删除。</p><ul class=""><li id="38d3" class="kc kd ht is b it iu ix iy jb ke jf kf jj kg jn kh ki kj kk dt translated">在列表删除中，我们删除任何变量缺失的观察值。简单是这种方法的主要优点之一，但是这种方法降低了模型的功效，因为它减少了样本量。为了简单起见，我们可以说，这种方法删除了数据缺失的整行观察值。</li><li id="8b47" class="kc kd ht is b it km ix kn jb ko jf kp jj kq jn kh ki kj kk dt translated">在成对删除中，我们对存在感兴趣的变量的所有情况进行分析。这种方法的优点是，它保持尽可能多的案例可供分析。这种方法的一个缺点是，它对不同的变量使用不同的样本量。</li></ul><figure class="jo jp jq jr fq js fe ff paragraph-image"><div class="fe ff kr"><img src="../Images/9478562d8ab9e92112bdaa54bb248a51.png" data-original-src="https://miro.medium.com/v2/resize:fit:888/format:webp/1*O_f-msrDfLc7P_wb6fIekA.png"/></div></figure><p id="40df" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu"> 2。均值/众数/中位数插补:</strong>插补是一种用估计值填充缺失值的方法。目标是利用已知的关系，这些关系可以在数据集的有效值中识别，以帮助估计缺失值。均值/众数/中位数插补是最常用的方法之一。它包括用该变量所有已知值的平均值或中值(定量属性)或众数(定性属性)替换给定属性的缺失数据。它可以有两种类型:-</p><ul class=""><li id="2ef1" class="kc kd ht is b it iu ix iy jb ke jf kf jj kg jn kh ki kj kk dt translated"><strong class="is hu">广义插补:</strong>在这种情况下，我们计算该变量所有非缺失值的平均值或中值，然后用平均值或中值替换缺失值。如上表所示，变量“<strong class="is hu">人力”</strong>缺失，因此我们取“<strong class="is hu">人力”</strong> ( <strong class="is hu"> 28.33 </strong>)所有非缺失值的平均值，然后用它替换缺失值。</li><li id="802d" class="kc kd ht is b it km ix kn jb ko jf kp jj kq jn kh ki kj kk dt translated"><strong class="is hu">类似情况插补:</strong>在这种情况下，我们分别计算非缺失值的性别“<strong class="is hu">男“</strong>”(29.75)和“<strong class="is hu">女</strong>”(25)的平均值，然后根据性别替换缺失值。对于“<strong class="is hu">男</strong>”，我们将用29.75替换缺失的人力值，对于“<strong class="is hu">女</strong>”用25替换缺失的人力值。</li></ul><p id="aded" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu"> 3。预测模型</strong>:预测模型是处理缺失数据的复杂方法之一。在这里，我们创建了一个预测模型来估计将替代缺失数据的值。在这种情况下，我们将数据集分成两组:一组没有变量的缺失值，另一组有缺失值。第一个数据集成为模型的训练数据集，而具有缺失值的第二个数据集是测试数据集，并且具有缺失值的变量被视为目标变量。接下来，我们创建一个模型，根据训练数据集的其他属性预测目标变量，并填充测试数据集的缺失值。我们可以使用回归、方差分析、逻辑回归和各种建模技术来实现这一点。这种方法有两个缺点:</p><ol class=""><li id="a477" class="kc kd ht is b it iu ix iy jb ke jf kf jj kg jn kl ki kj kk dt translated">模型估计值通常比真实值表现得更好</li><li id="615a" class="kc kd ht is b it km ix kn jb ko jf kp jj kq jn kl ki kj kk dt translated">如果与数据集中的属性和具有缺失值的属性没有关系，那么模型对于估计缺失值将是不精确的。</li></ol><p id="ed11" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu"> 4。KNN插补:</strong>在这种插补方法中，使用与缺失值的属性最相似的给定数量的属性对属性的缺失值进行插补。使用距离函数来确定两个属性的相似性。众所周知它也有一定的优点&amp;缺点。</p><p id="6ec7" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu">优点:</strong></p><ul class=""><li id="f320" class="kc kd ht is b it iu ix iy jb ke jf kf jj kg jn kh ki kj kk dt translated">k近邻可以预测定性和定量属性</li><li id="b910" class="kc kd ht is b it km ix kn jb ko jf kp jj kq jn kh ki kj kk dt translated">不需要为具有缺失数据的每个属性创建预测模型</li><li id="780e" class="kc kd ht is b it km ix kn jb ko jf kp jj kq jn kh ki kj kk dt translated">具有多个缺失值的属性很容易处理</li><li id="9bb2" class="kc kd ht is b it km ix kn jb ko jf kp jj kq jn kh ki kj kk dt translated">考虑数据的相关结构</li></ul><p id="b6c0" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu">缺点:</strong></p><ul class=""><li id="dec0" class="kc kd ht is b it iu ix iy jb ke jf kf jj kg jn kh ki kj kk dt translated">KNN算法在分析大型数据库时非常耗时。它在所有数据集中搜索最相似的实例。</li><li id="16d7" class="kc kd ht is b it km ix kn jb ko jf kp jj kq jn kh ki kj kk dt translated">k值的选择非常关键。较高的k值将包括与我们所需要的显著不同的属性，而较低的k值意味着遗漏了重要的属性。</li></ul><p id="d288" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">尽管有上述方法，R有各种包来处理丢失的数据。</p><h1 id="84d6" class="ku kv ht bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr dt translated">R包列表</h1><ol class=""><li id="b1e9" class="kc kd ht is b it ls ix lt jb lu jf lv jj lw jn kl ki kj kk dt translated">老鼠</li><li id="2aa3" class="kc kd ht is b it km ix kn jb ko jf kp jj kq jn kl ki kj kk dt translated">无肢</li><li id="ce52" class="kc kd ht is b it km ix kn jb ko jf kp jj kq jn kl ki kj kk dt translated">错过森林</li><li id="a21c" class="kc kd ht is b it km ix kn jb ko jf kp jj kq jn kl ki kj kk dt translated">Hmisc</li><li id="3be2" class="kc kd ht is b it km ix kn jb ko jf kp jj kq jn kl ki kj kk dt translated">大音阶的第三音</li></ol><h1 id="6a8e" class="ku kv ht bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr dt translated">MICE包装</h1><p id="9371" class="pw-post-body-paragraph iq ir ht is b it ls iv iw ix lt iz ja jb lx jd je jf ly jh ji jj lz jl jm jn hm dt translated">MICE(通过链式方程的多变量插补)是R用户常用的软件包之一。与单一插补(如平均值)相比，创建多重插补可解决缺失值的不确定性。</p><p id="223a" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">MICE假设缺失数据是随机缺失的(MAR)，这意味着值缺失的概率仅取决于观察值，并且可以使用它们进行预测。它通过为每个变量指定一个插补模型，对每个变量的数据进行插补。</p><p id="8a36" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu">例如:</strong>假设我们有X1，X2…Xk变量。如果X1有缺失值，那么它将在其他变量X2到Xk上回归。然后，X1中缺失的值将被获得的预测值替换。类似地，如果X2有缺失值，那么X1，X3到Xk变量将在预测模型中作为独立变量使用。稍后，缺失值将被预测值替换。</p><p id="f77a" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">默认情况下，线性回归用于预测连续缺失值。逻辑回归用于分类缺失值。一旦这个循环完成，就会产生多个数据集。这些数据集的不同之处仅在于估算缺失值。一般来说，在这些数据集上分别建立模型并组合它们的结果被认为是一个好的实践。</p><p id="d239" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">确切地说，这个包使用的方法是:</p><ol class=""><li id="8623" class="kc kd ht is b it iu ix iy jb ke jf kf jj kg jn kl ki kj kk dt translated">PMM(预测均值匹配)—用于数值变量</li><li id="24b9" class="kc kd ht is b it km ix kn jb ko jf kp jj kq jn kl ki kj kk dt translated">logreg(逻辑回归)—用于二元变量(有两个级别)</li><li id="7100" class="kc kd ht is b it km ix kn jb ko jf kp jj kq jn kl ki kj kk dt translated">polyreg(贝叶斯同态回归)—用于因子变量(&gt; = 2级)</li><li id="70a4" class="kc kd ht is b it km ix kn jb ko jf kp jj kq jn kl ki kj kk dt translated">比例优势模型(有序，&gt; = 2级)</li></ol><p id="8587" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">现在就来实际了解一下吧。</p><p id="241d" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><code class="eh ma mb mc md b">#load data</code> <br/> <code class="eh ma mb mc md b">&gt; data &lt;- iris</code></p><p id="b516" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><code class="eh ma mb mc md b">#Get summary</code><br/>T3】</p><p id="5f05" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">因为，老鼠假设随机值缺失。让我们使用prodNA函数在数据集中播种缺失值。您可以通过安装missForest包来访问该功能。</p><p id="20d0" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><code class="eh ma mb mc md b">#Generate 10% missing values at Random </code>T12<code class="eh ma mb mc md b">&gt; iris.mis &lt;- prodNA(iris, noNA = 0.1)</code></p><p id="f22f" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><code class="eh ma mb mc md b">#Check missing values introduced in the data</code><br/>T1】</p><p id="8f33" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">我去掉了分类变量。让我们在这里关注连续值。要处理分类变量，只需对级别进行编码并遵循以下程序。</p><p id="261b" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><code class="eh ma mb mc md b"># Removing categorical data</code></p><p id="eed9" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><code class="eh ma mb mc md b">&gt; iris.mis &lt;- subset(iris.mis, select = -c(Species))</code> <br/> <code class="eh ma mb mc md b">&gt; summary(iris.<em class="jy">mis)</em></code></p><p id="6c47" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><em class="jy"> #安装鼠标</em> <br/> <code class="eh ma mb mc md b">&gt; install.packages("mice")</code> <br/> <code class="eh ma mb mc md b">&gt; library(mice)</code></p><p id="8aa1" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">mice包有一个函数叫做<em class="jy"> md.pattern()。</em>它以表格形式返回数据集中每个变量的缺失值。</p><p id="279b" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">&gt; md.pattern(虹膜. mis)</p><p id="4bc9" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">让我们来理解这张表。有98个观察值没有缺失值。萼片长度中有10个观察值缺失。同样，萼片中有13个值缺失。宽度等等。</p><p id="4c92" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">这看起来很丑。对吗？我们还可以创建一个视觉来表示缺失的值。它看起来也很酷。我们去看看。</p><p id="2950" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><code class="eh ma mb mc md b">&gt; install.packages("VIM")</code><br/><code class="eh ma mb mc md b">&gt; library(VIM)</code><br/><code class="eh ma mb mc md b">&gt; mice_plot &lt;- aggr(iris.mis, col=c('navyblue','yellow'),</code><br/><code class="eh ma mb mc md b"> numbers=TRUE, sortVars=TRUE,</code><br/><code class="eh ma mb mc md b"> labels=names(iris.mis), cex.axis=.7,</code><br/><code class="eh ma mb mc md b"> gap=3, ylab=c("Missing data","Pattern"))</code></p><figure class="jo jp jq jr fq js fe ff paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="fe ff me"><img src="../Images/a9f5b33f373b9246b26e386ad1fec365.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3hfMHl3nf46P8RaphYtjWw.png"/></div></div></figure><p id="6a72" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">我们来快速了解一下这个。数据集中有67%的值没有缺失值。花瓣中有10%的值缺失。长度，花瓣中缺少8%的值。宽度等等。您还可以查看直方图，它清楚地描述了变量中缺失值的影响。</p><p id="30b4" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">现在，让我们估算缺失值。</p><p id="f5bb" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><code class="eh ma mb mc md b">&gt; imputed_Data &lt;- mice(iris.mis, m=5, maxit = 50, method = 'pmm', seed = 500)</code> <br/> <code class="eh ma mb mc md b">&gt; summary(imputed_Data)</code></p><p id="d899" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">输出:</p><p id="223c" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><code class="eh ma mb mc md b">Multiply imputed data set</code><br/><code class="eh ma mb mc md b">Call:</code><br/><code class="eh ma mb mc md b">mice(data = iris.mis, m = 5, method = "pmm", maxit = 50, seed = 500)</code><br/><code class="eh ma mb mc md b">Number of multiple imputations: 5</code><br/><code class="eh ma mb mc md b">Missing cells per column:</code><br/><code class="eh ma mb mc md b">Sepal.Length Sepal.Width Petal.Length Petal.Width </code><br/><code class="eh ma mb mc md b">13 14 16 15 </code><br/><code class="eh ma mb mc md b">Imputation methods:</code><br/><code class="eh ma mb mc md b">Sepal.Length Sepal.Width Petal.Length Petal.Width </code><br/><code class="eh ma mb mc md b">"pmm" "pmm" "pmm" "pmm" </code><br/><code class="eh ma mb mc md b">VisitSequence:</code><br/><code class="eh ma mb mc md b">Sepal.Length Sepal.Width Petal.Length Petal.Width </code><br/><code class="eh ma mb mc md b">1 2 3 4 </code><br/><code class="eh ma mb mc md b">PredictorMatrix:</code><br/><code class="eh ma mb mc md b"> Sepal.Length Sepal.Width Petal.Length Petal.Width</code><br/><code class="eh ma mb mc md b">Sepal.Length 0 1 1 1</code><br/><code class="eh ma mb mc md b">Sepal.Width 1 0 1 1</code><br/><code class="eh ma mb mc md b">Petal.Length 1 1 0 1</code><br/><code class="eh ma mb mc md b">Petal.Width 1 1 1 0</code><br/></p><p id="e262" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">以下是对所用参数的解释:</p><ol class=""><li id="f649" class="kc kd ht is b it iu ix iy jb ke jf kf jj kg jn kl ki kj kk dt translated">m —指5个估算数据集</li><li id="54e7" class="kc kd ht is b it km ix kn jb ko jf kp jj kq jn kl ki kj kk dt translated">maxit指用于估算缺失值的迭代次数</li><li id="7f75" class="kc kd ht is b it km ix kn jb ko jf kp jj kq jn kl ki kj kk dt translated">方法——指插补中使用的方法。我们使用预测平均匹配。</li></ol><p id="9957" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><code class="eh ma mb mc md b">#check imputed values</code> <br/> <code class="eh ma mb mc md b">&gt; imputed_Data$imp$Sepal.Width</code></p><p id="0f1b" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">由于有5个估算数据集，您可以使用<em class="jy"> complete() </em>功能选择任何一个。</p><p id="9838" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><code class="eh ma mb mc md b">#get complete data ( 2nd out of 5)</code> <br/> <code class="eh ma mb mc md b">&gt; completeData &lt;- complete(imputed_Data,2)</code></p><p id="1eba" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">此外，如果您希望在所有5个数据集上构建模型，您可以使用带有()命令的<em class="jy">一次完成。您还可以使用<em class="jy"> pool() </em>命令组合这些模型的结果并获得一个合并的输出。</em></p><p id="89b7" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><code class="eh ma mb mc md b">#build predictive model</code> <br/> <code class="eh ma mb mc md b">&gt; fit &lt;- with(data = iris.mis, exp = lm(Sepal.Width ~ Sepal.Length + Petal.Width))</code></p><p id="1e2b" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><code class="eh ma mb mc md b">#combine results of all 5 models</code> <br/> <code class="eh ma mb mc md b">&gt; combine &lt;- pool(fit)<br/>&gt; summary(combine)</code></p><p id="e3c2" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">请注意，我使用上面的命令只是为了演示。你可以替换你那端的变量值，试试看。</p><h1 id="bfc1" class="ku kv ht bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr dt translated">无肢</h1><p id="880f" class="pw-post-body-paragraph iq ir ht is b it ls iv iw ix lt iz ja jb lx jd je jf ly jh ji jj lz jl jm jn hm dt translated">该软件包还执行多重插补(生成插补数据集)来处理缺失值。多重插补有助于减少偏差和提高效率。它启用了基于EMB算法的bootstrap，使其能够更快、更稳健地估算许多变量，包括横截面、时间序列数据等。此外，它还支持使用多核CPU的并行插补功能。</p><p id="ca96" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">它做出以下假设:</p><ol class=""><li id="7120" class="kc kd ht is b it iu ix iy jb ke jf kf jj kg jn kl ki kj kk dt translated">数据集中的所有变量都具有多元正态分布(MVN)。它使用均值和协方差来汇总数据。</li><li id="76e3" class="kc kd ht is b it km ix kn jb ko jf kp jj kq jn kl ki kj kk dt translated">缺失数据本质上是随机的(随机缺失)</li></ol><p id="65b0" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">它是这样工作的。首先，它取m个自举样本，并对每个样本应用EMB算法。均值和方差的m个估计值是不同的。最后，第一组估计值用于通过回归估算第一组缺失值，然后第二组估计值用于第二组，依此类推。</p><p id="fa10" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">与MICE相比，MVN在一些关键方面存在差距，例如:</p><ol class=""><li id="108d" class="kc kd ht is b it iu ix iy jb ke jf kf jj kg jn kl ki kj kk dt translated">MICE以变量为基础估算数据，而MVN使用基于多元正态分布的联合建模方法。</li><li id="06ed" class="kc kd ht is b it km ix kn jb ko jf kp jj kq jn kl ki kj kk dt translated">MICE能够处理不同类型的变量，而MVN的变量需要正态分布或转换为近似正态分布。</li><li id="d1cb" class="kc kd ht is b it km ix kn jb ko jf kp jj kq jn kl ki kj kk dt translated">此外，MICE可以管理在数据子集上定义的变量插补，而MVN则不能。</li></ol><p id="4630" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">因此，当数据具有多变量正态分布时，该软件包工作得最好。如果不是，就要进行转换，使数据接近正常。</p><p id="0c11" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">现在就来实际了解一下吧。</p><p id="3685" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><code class="eh ma mb mc md b">#install package and load library</code><br/><code class="eh ma mb mc md b">&gt; install.packages("Amelia")</code><br/>T2】</p><p id="4e10" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><code class="eh ma mb mc md b">#load data</code> <br/> <code class="eh ma mb mc md b">&gt; data("iris")</code></p><p id="9cd4" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">唯一需要注意的是对变量进行分类。它有3个参数:</p><ol class=""><li id="07a2" class="kc kd ht is b it iu ix iy jb ke jf kf jj kg jn kl ki kj kk dt translated">idvars保留所有ID变量和其他不想估算的变量</li><li id="f01e" class="kc kd ht is b it km ix kn jb ko jf kp jj kq jn kl ki kj kk dt translated">noms在此保留名义变量</li></ol><p id="db05" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><code class="eh ma mb mc md b">#seed 10% missing values</code> <br/> <code class="eh ma mb mc md b">&gt; iris.mis &lt;- prodNA(iris, noNA = 0.1)</code> <br/> <code class="eh ma mb mc md b">&gt; summary(iris.mis)</code></p><p id="9865" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><code class="eh ma mb mc md b">#specify columns and run amelia</code> <br/> <code class="eh ma mb mc md b">&gt; amelia_fit &lt;- amelia(iris.mis, m=5, parallel = "multicore", noms = "Species")</code></p><p id="ffc7" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><code class="eh ma mb mc md b">#access imputed outputs</code><br/><code class="eh ma mb mc md b">&gt; amelia_fit$imputations[[1]]</code><br/><code class="eh ma mb mc md b">&gt; amelia_fit$imputations[[2]]</code><br/><code class="eh ma mb mc md b">&gt; amelia_fit$imputations[[3]]</code><br/><code class="eh ma mb mc md b">&gt; amelia_fit$imputations[[4]]</code><br/><code class="eh ma mb mc md b">&gt; amelia_fit$imputations[[5]]</code></p><p id="1efa" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">要检查数据集中的特定列，请使用以下命令</p><p id="1370" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><code class="eh ma mb mc md b">&gt; amelia_fit$imputations[[5]]$Sepal.Length</code></p><p id="4ff8" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><code class="eh ma mb mc md b">#export the outputs to csv files</code> <br/> <code class="eh ma mb mc md b">&gt; write.amelia(amelia_fit, file.stem = "imputed_data_set")</code></p><h1 id="9b27" class="ku kv ht bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr dt translated">错过森林</h1><p id="d435" class="pw-post-body-paragraph iq ir ht is b it ls iv iw ix lt iz ja jb lx jd je jf ly jh ji jj lz jl jm jn hm dt translated">顾名思义，missForest是<a class="ae mj" href="https://www.analyticsvidhya.com/blog/2015/09/random-forest-algorithm-multiple-challenges/" rel="noopener ugc nofollow" target="_blank">随机森林</a>算法的一个实现。这是一种适用于各种变量类型的非参数插补方法。那么，什么是非参数方法呢？</p><p id="3bb6" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">非参数方法不对<em class="jy"> f </em>(任意函数)的函数形式做出明确的假设。相反，它试图估算出<em class="jy"> f </em>，使其尽可能接近数据点而不显得不切实际。</p><p id="6f9f" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">它是如何工作的？简而言之，它为每个变量构建了一个随机森林模型。然后，它使用模型在观察值的帮助下预测变量中缺失的值。</p><p id="582c" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">它产生OOB(袋外)插补误差估计。此外，它还提供了对插补流程的高度控制。它可以选择单独返回OOB(对于每个变量)，而不是在整个数据矩阵上聚合。这有助于更仔细地观察模型对每个变量的估算值的准确程度。</p><p id="8a54" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">让我们实际地理解它。因为bagging在分类变量上也工作得很好，所以我们不需要在这里删除它们。它很好地处理了与变量类型相关的缺失值:</p><p id="146a" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><code class="eh ma mb mc md b">#missForest</code><br/><code class="eh ma mb mc md b">&gt; install.packages("missForest")</code><br/>T5】</p><p id="a8c2" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><code class="eh ma mb mc md b">#load data</code> <br/> <code class="eh ma mb mc md b">&gt; data("iris")</code></p><p id="5c69" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><code class="eh ma mb mc md b">#seed 10% missing values</code> <br/> <code class="eh ma mb mc md b">&gt; iris.mis &lt;- prodNA(iris, noNA = 0.1)</code> <br/> <code class="eh ma mb mc md b">&gt; summary(iris.mis)</code></p><p id="8f01" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><code class="eh ma mb mc md b">#impute missing values, using all parameters as default values</code> <br/> <code class="eh ma mb mc md b">&gt; iris.imp &lt;- missForest(iris.mis)</code></p><p id="f38e" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><code class="eh ma mb mc md b">#check imputed values</code>T32<code class="eh ma mb mc md b">&gt; iris.imp$ximp</code></p><p id="383c" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><code class="eh ma mb mc md b">#check imputation error</code> <br/> <code class="eh ma mb mc md b">&gt; iris.imp$OOBerror</code></p><p id="a8b0" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><code class="eh ma mb mc md b">NRMSE PFC </code> <br/> <code class="eh ma mb mc md b">0.14148554 0.02985075</code></p><p id="b18e" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">NRMSE是归一化均方误差。它用于表示因输入连续值而产生的误差。PFC(错误分类的比例)用于表示从输入分类值中得出的误差。</p><p id="2f9e" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><code class="eh ma mb mc md b">#comparing actual data accuracy</code><br/><code class="eh ma mb mc md b">&gt; iris.err &lt;- mixError(iris.imp$ximp, iris.mis, iris)</code><br/>T2】</p><p id="e606" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><code class="eh ma mb mc md b">NRMSE PFC </code><br/>T4】</p><p id="d95a" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">这表明分类变量的估算误差为6%，连续变量的估算误差为15%。这可以通过调整<em class="jy"> mtry </em>和<em class="jy"> ntree </em>参数的值来改善。mtry是指每次分割时随机抽样的变量数量。ntree是指森林中生长的树木数量。</p><h1 id="488c" class="ku kv ht bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr dt translated">Hmisc</h1><p id="ad40" class="pw-post-body-paragraph iq ir ht is b it ls iv iw ix lt iz ja jb lx jd je jf ly jh ji jj lz jl jm jn hm dt translated">Hmisc是一个多用途软件包，可用于数据分析、高级图形、输入缺失值、高级表格制作、模型拟合和诊断(线性回归、逻辑回归和cox回归)等。在这个软件包包含的广泛的函数中，它提供了2个强大的输入缺失值的函数。它们是<em class="jy">估算()</em>和<em class="jy">精确计算()</em>。虽然它也有<em class="jy"> transcan() </em>功能，但是aregImpute()更好用。</p><p id="5892" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><em class="jy"> impute() </em>函数使用用户定义的统计方法(平均值、最大值、平均值)简单地估算缺失值。它的默认值是中值。另一方面，<em class="jy"> aregImpute() </em>允许使用加法回归、自举和预测均值匹配进行均值插补。</p><p id="00f5" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">在bootstrapping中，不同的bootstrap重采样用于多次插补中的每一次。然后，一个灵活的加性模型(非参数回归方法)适用于从原始数据和缺失值(作为因变量)使用非缺失值(自变量)预测替代样本。</p><p id="de64" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">然后，它使用预测均值匹配(默认)来估算缺失值。预测平均匹配适用于连续和分类(二进制和多级)，无需计算残差和最大似然拟合。</p><p id="ede0" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">以下是该软件包的一些重要亮点:</p><ol class=""><li id="8025" class="kc kd ht is b it iu ix iy jb ke jf kf jj kg jn kl ki kj kk dt translated">它假设被预测的变量是线性的。</li><li id="6432" class="kc kd ht is b it km ix kn jb ko jf kp jj kq jn kl ki kj kk dt translated"><a class="ae mj" href="https://en.wikipedia.org/wiki/Scoring_algorithm" rel="noopener ugc nofollow" target="_blank">费希尔最优评分</a>法用于预测分类变量。</li></ol><p id="6cb9" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">让我们实际地理解它。</p><p id="0bbb" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><code class="eh ma mb mc md b">#install package and load library</code> <br/> <code class="eh ma mb mc md b">&gt; install.packages("Hmisc")</code> <br/> <code class="eh ma mb mc md b">&gt; library(Hmisc)</code></p><p id="7b5a" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><code class="eh ma mb mc md b">#load data</code> <br/> <code class="eh ma mb mc md b">&gt; data("iris")</code></p><p id="8057" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><code class="eh ma mb mc md b">#seed missing values ( 10% )</code> <br/> <code class="eh ma mb mc md b">&gt; iris.mis &lt;- prodNA(iris, noNA = 0.1)</code> <br/> <code class="eh ma mb mc md b">&gt; summary(iris.mis)</code></p><p id="4156" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><code class="eh ma mb mc md b"># impute with mean value</code> <br/> <code class="eh ma mb mc md b">&gt; iris.mis$imputed_age &lt;- with(iris.mis, impute(Sepal.Length, mean))</code></p><p id="4050" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><code class="eh ma mb mc md b"># impute with random value</code> <br/> <code class="eh ma mb mc md b">&gt; iris.mis$imputed_age2 &lt;- with(iris.mis, impute(Sepal.Length, 'random'))</code></p><p id="c917" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><code class="eh ma mb mc md b">#similarly you can use min, max, median to impute missing value</code></p><p id="5c34" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><code class="eh ma mb mc md b">#using argImpute</code> <br/> <code class="eh ma mb mc md b">&gt; impute_arg &lt;- aregImpute(~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width +<br/>Species, data = iris.mis, n.impute = 5)</code></p><p id="3152" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">argImpute()自动识别变量类型并相应地处理它们。</p><p id="8666" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><code class="eh ma mb mc md b">&gt; impute_arg</code></p><figure class="jo jp jq jr fq js fe ff paragraph-image"><div class="fe ff mk"><img src="../Images/491c1dea703ef6dc2463e2e77cd9682f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1230/format:webp/1*CyveMkY9p0-dxIG0Z1gFaw.png"/></div></figure><p id="a65b" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">输出显示了预测缺失值的R值。该值越高，预测的值越好。您也可以使用以下命令检查估算值</p><p id="990e" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><code class="eh ma mb mc md b">#check imputed variable Sepal.Length</code> <br/> <code class="eh ma mb mc md b">&gt; impute_arg$imputed$Sepal.Length</code></p><h1 id="038d" class="ku kv ht bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr dt translated">大音阶的第三音</h1><p id="6eb7" class="pw-post-body-paragraph iq ir ht is b it ls iv iw ix lt iz ja jb lx jd je jf ly jh ji jj lz jl jm jn hm dt translated">mi(带诊断的多重插补)软件包提供了几个处理缺失值的功能。与其他软件包一样，它也构建了多个插补模型来逼近缺失值。并且，使用预测平均匹配方法。</p><p id="40e2" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">虽然，我已经在上面解释了预测均值匹配(pmm ),但是如果你还没有理解，这里有一个更简单的版本:对于一个变量中的每个具有缺失值的观察值，我们(从可用值中)找到具有最接近该变量的预测均值的观察值。这个“匹配”的观察值然后被用作估算值。</p><p id="5719" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">以下是该产品包的一些独特特征:</p><ol class=""><li id="2431" class="kc kd ht is b it iu ix iy jb ke jf kf jj kg jn kl ki kj kk dt translated">它允许插补模型的图形诊断和插补过程的收敛。</li><li id="3164" class="kc kd ht is b it km ix kn jb ko jf kp jj kq jn kl ki kj kk dt translated">它使用贝叶斯版本的回归模型来处理分离问题。</li><li id="5f09" class="kc kd ht is b it km ix kn jb ko jf kp jj kq jn kl ki kj kk dt translated">插补模型规范类似于R中的回归输出</li><li id="6a1b" class="kc kd ht is b it km ix kn jb ko jf kp jj kq jn kl ki kj kk dt translated">它自动检测数据中的不规则性，如变量之间的高度共线性。</li><li id="6730" class="kc kd ht is b it km ix kn jb ko jf kp jj kq jn kl ki kj kk dt translated">同时，在插补过程中加入噪声，解决了附加约束问题。</li></ol><p id="16f1" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">让我们实际地理解它。</p><p id="c499" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><code class="eh ma mb mc md b">#install package and load library</code> <br/> <code class="eh ma mb mc md b">&gt; install.packages("mi")</code> <br/> <code class="eh ma mb mc md b">&gt; library(mi)</code></p><p id="2955" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><code class="eh ma mb mc md b">#load data</code> <br/> <code class="eh ma mb mc md b">&gt; data("iris")</code></p><p id="a354" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><code class="eh ma mb mc md b">#seed missing values ( 10% )</code> <br/> <code class="eh ma mb mc md b">&gt; iris.mis &lt;- prodNA(iris, noNA = 0.1)</code> <br/> <code class="eh ma mb mc md b">&gt; summary(iris.mis)</code></p><p id="7589" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><code class="eh ma mb mc md b">#imputing missing value with mi</code> <br/> <code class="eh ma mb mc md b">&gt; mi_data &lt;- mi(iris.mis, seed = 335)</code></p><p id="8fba" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">我使用了参数的默认值，即:</p><ol class=""><li id="cde6" class="kc kd ht is b it iu ix iy jb ke jf kf jj kg jn kl ki kj kk dt translated">rand.imp.method作为“引导”</li><li id="19bf" class="kc kd ht is b it km ix kn jb ko jf kp jj kq jn kl ki kj kk dt translated">n.imp(多重插补次数)为3</li><li id="bc19" class="kc kd ht is b it km ix kn jb ko jf kp jj kq jn kl ki kj kk dt translated">n.iter(迭代次数)为30</li></ol><p id="179b" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><code class="eh ma mb mc md b">&gt; summary(mi_data)</code></p><figure class="jo jp jq jr fq js fe ff paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="fe ff ml"><img src="../Images/a52357d31424c783ab2ee24476fe113f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*069xMGhqjhBZeussgFlOCQ.png"/></div></div></figure><p id="a7ff" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">这里是输入缺失值后mi包的摘要输出的快照。如图所示，它使用汇总统计数据来定义估算值。</p><p id="577d" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">资料来源:AnalyticsVidhya</p><p id="05b5" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">如果您喜欢这篇文章，请关注我，获取更多与数据科学相关的文章。</p><blockquote class="mm"><p id="3567" class="mn mo ht bd mp mq mr ms mt mu mv jn ek translated">加入Coinmonks <a class="ae mj" href="https://t.me/coincodecap" rel="noopener ugc nofollow" target="_blank">电报频道</a>和<a class="ae mj" href="https://www.youtube.com/c/coinmonks/videos" rel="noopener ugc nofollow" target="_blank"> Youtube频道</a>获取每日<a class="ae mj" href="http://coincodecap.com/" rel="noopener ugc nofollow" target="_blank">加密新闻</a></p></blockquote><h2 id="15d6" class="mw kv ht bd kw mx my mz la na nb nc le jb nd ne li jf nf ng lm jj nh ni lq nj dt translated">另外，阅读</h2><ul class=""><li id="20fb" class="kc kd ht is b it ls ix lt jb lu jf lv jj lw jn kh ki kj kk dt translated"><a class="ae mj" href="http://Top 4 Telegram Channels for Crypto Traders" rel="noopener ugc nofollow" target="_blank">密码电报信号</a> | <a class="ae mj" rel="noopener" href="/coinmonks/crypto-trading-bot-c2ffce8acb2a">密码交易机器人</a></li><li id="14e6" class="kc kd ht is b it km ix kn jb ko jf kp jj kq jn kh ki kj kk dt translated"><a class="ae mj" rel="noopener" href="/coinmonks/top-10-crypto-copy-trading-platforms-for-beginners-d0c37c7d698c">复制交易</a> | <a class="ae mj" rel="noopener" href="/coinmonks/crypto-tax-software-ed4b4810e338">加密税务软件</a></li><li id="723e" class="kc kd ht is b it km ix kn jb ko jf kp jj kq jn kh ki kj kk dt translated"><a class="ae mj" href="https://coincodecap.com/grid-trading" rel="noopener ugc nofollow" target="_blank">网格交易</a> | <a class="ae mj" rel="noopener" href="/coinmonks/the-best-cryptocurrency-hardware-wallets-of-2020-e28b1c124069">加密硬件钱包</a></li><li id="f33b" class="kc kd ht is b it km ix kn jb ko jf kp jj kq jn kh ki kj kk dt translated"><a class="ae mj" rel="noopener" href="/coinmonks/crypto-exchange-dd2f9d6f3769">加密交易所</a> | <a class="ae mj" rel="noopener" href="/coinmonks/buy-bitcoin-in-india-feb50ddfef94">印度的加密应用</a></li></ul></div></div>    
</body>
</html>