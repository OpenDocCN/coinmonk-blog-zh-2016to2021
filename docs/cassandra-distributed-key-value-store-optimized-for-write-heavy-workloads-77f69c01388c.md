# Cassandra:针对大量写入工作负载优化的分布式键值存储

> 原文：<https://medium.com/coinmonks/cassandra-distributed-key-value-store-optimized-for-write-heavy-workloads-77f69c01388c?source=collection_archive---------0----------------------->

![](img/88429c9f37b0c4f29c05289af4c50fa9.png)

Apache Cassandra Logo

## 介绍

Cassandra 是一个流行的分布式键值存储，最初建立于脸书，使用商品服务器让用户搜索他们的收件箱信息。我在中提到的 TAO 针对读取进行了优化，而 Cassandra 则针对繁重的写入工作负载进行了优化，同时保持了良好的读取性能。Cassandra 的一些关键设计目标似乎是:

1.  虽然写操作是数十亿次，并且需要针对仅附加日志进行优化，但是读操作可能在地理位置上有很大差异。因此，跨数据中心复制对于良好的读取效率是必要且重要的。
2.  随着越来越多的用户加入平台，通过添加商用服务器来扩展平台。
3.  容错应该是常态。
4.  为数据库的客户端提供简单的接口和对模式类型、可用性和性能等的更多控制。

谷歌的 [bigtable](/@ameya_s/bigtable-bc9fd67238a5) 也有类似的总体目的。但是这里的关键区别是 bigtable 是建立在 GFS 之上的，它提供了数据的持久性。数据的持久性通过显式复制机制内置于 Cassandra 中。

## 数据模型

像 BigTable 这样的 Cassandra 提供了一个相当简单的数据模型。它由几十字节大小的小键和一些客户喜欢的结构化格式组成。键映射到一组称为列族的列。这样，Cassandra 数据模型可以被视为多维键值映射。

在 cassandra 中，任何行变异都是原子性的。因此，当更新键和相应的列/列族时，会写入所有数据或不写入任何数据。栏目可以按时间排序，例如最新的消息可以在顶部。

访问 Cassandra 的简单 API(相当简单)是:

insert(表，键，行突变)

get(表，键，列名)

删除(表，键，列名)

## 请求流或密钥

在 Cassandra 中，对于读取和写入，任何最终用户请求都可以到达任何节点。然后，这个节点知道“拥有”这个密钥空间的副本。那么节点将把请求路由到这些副本。

对于写入操作，复制对于数据的持久性非常重要。因此，请求最初到达的节点等待从副本的响应中建立仲裁。

对于读取，可以根据应用程序的要求放宽这一要求。对于不太担心强一致性的客户端应用程序，可以在副本的第一个响应到达时进行响应，或者可以等待建立仲裁。

# 体系结构

任何大型分布式存储系统都需要考虑数据的持久性或持久性、容错、数据分区、系统中节点的添加或删除、扩展。让我们讨论一些重要的方面。需要记住的一个关键事实是，Cassandra 中的所有节点都通过基于流言的协议相互了解。

## 分区—将键映射到节点/服务器

Cassandra 需要能够通过添加更多服务器进行扩展，还需要在不影响性能的情况下适应节点故障。因此，Cassandra 使用一致的散列法将密钥映射到服务器/节点。一致散列的优点是，如果在系统中添加或删除节点，那么所有现有的密钥-服务器映射不会像传统散列方法那样受到影响。只有邻居节点受到影响，并且密钥的重新分配发生在邻居之间。

在这个方案中，每个节点被分配到某个 keyrange。假设整个 keyrange 可以映射到一个圆的圆周上。所以当一个键到达时，它被映射到圆周上的某个点。然后算法顺时针走，直到找到映射到圆上的下一个节点。该节点现在是该键的协调者。当这个节点由于某种原因关闭时，圆周上的下一个顺时针节点将成为相关 keyrange 的协调器。由于圆圈上的不同节点会有不同的负载，Cassandra 允许负载较轻的节点向负载较重的节点移动。

## 复制—确保数据的持久性

上一节提到的给定键的协调器节点负责不同节点上的数据复制。协调器将把密钥存储在其自身以及其他 n-1 个副本上。有不同的方案来选择这些复制品。例如，出于可用性和可扩展性的考虑，用户可能希望在 coordinator 所在的数据中心之外拥有一个副本，或者可能希望在其机架之外拥有一个副本。该策略由应用决定。

卡珊德拉使用动物园管理员选举一个领导者。领导者负责将一个节点放到一个圆上。Cassandra 还通知节点，它们是哪个键空间的副本。通常，为了获得更好的可用性，最好将副本存储在通过高速链路连接的多个数据中心中。

## 集群成员资格

使用[流言蜚语协议](https://dl.acm.org/citation.cfm?id=1529983)建立集群成员关系——这是一种高效的 CPU 方式，也不会给通信通道带来沉重负担。

为了检测故障和关闭的节点，Cassandra 使用“累积故障检测”。其基本思想是，在给定某个阈值的情况下，它给出了一个节点停机的概率。积极的阈值会寻找更小的超时，而保守的阈值会寻找更长的超时。为此，每个节点通过 gossip 协议维护一个消息交换到达时间的滑动窗口。这种方案非常适合动态负载条件。

新节点如何加入集群？

一个新的节点在圆上被分配一个随机的位置。出现的任何新节点都用它可以联系的几个现有种子节点来实例化。使用这些并通过流言，新节点了解其他节点，其他节点也了解新节点。这就是为什么任何节点都能够将密钥请求路由到其合法所有者。

## 扩展集群

当新节点被添加到集群中时，在负载最重的节点附近引入它们是有意义的。这导致数据从加载的节点重新分布到新添加的节点。很明显，这是通过内核文件复制机制实现的——大概是使用 sendfile。

## 读/写性能改进

让我们看看在 Cassandra 中优化读写的一些方法。

**写优化:**通常，优化磁盘写的最佳方式是像在[日志结构化文件系统](http://pages.cs.wisc.edu/~remzi/OSTEP/file-lfs.pdf)中那样对日志进行顺序写入。因此，写操作包括写入专用磁盘上的提交日志，然后更新内存中的结构。一旦达到一定的阈值，结构化的数据就可以转储到磁盘，并生成相应的索引。

**读取优化:**第一个参考点是用于读取的内存。然后使用布隆过滤器进一步优化以避免磁盘查找。也有一些带有键和列的位置。但是在列族的情况下，某些列可能会更远—这是使用列索引优化的。

## 日志

正如我们在“写优化”一节中看到的，Cassandra 使用日志来记录操作，以提高耐用性。在这样的系统中，当机器启动时，它开始扫描日志和系统的最后保存状态，并基于日志中记录的条目重建更当前的状态。在这种情况下，显然需要经常清除日志。在 cassandra 中，这是根据大小来完成的。当日志达到 128MB 时，一个新的日志开始。只要与过去的提交日志相关的数据已经转储到磁盘，就可以删除以前的日志。

## 结论

我发现这篇论文相当值得一读。Cassandra 是使用最广泛的键值存储之一，了解更多是有用的。我还发现，使用系统方面的各种可用技术，这个系统可以很好地组合在一起。像小道消息这样的技术听起来也很有趣，我可能会在接下来的文章中涉及到它。

> [在您的收件箱中直接获得最佳软件交易](https://coincodecap.com/?utm_source=coinmonks)

[![](img/7c0b3dfdcbfea594cc0ae7d4f9bf6fcb.png)](https://coincodecap.com/?utm_source=coinmonks)