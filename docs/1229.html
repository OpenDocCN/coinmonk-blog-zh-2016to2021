<html>
<head>
<title>Celebrity Face Generation using GANs (Tensorflow Implementation)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用GANs (Tensorflow实现)的名人人脸生成</h1>
<blockquote>原文：<a href="https://medium.com/coinmonks/celebrity-face-generation-using-gans-tensorflow-implementation-eaa2001eef86?source=collection_archive---------0-----------------------#2018-08-04">https://medium.com/coinmonks/celebrity-face-generation-using-gans-tensorflow-implementation-eaa2001eef86?source=collection_archive---------0-----------------------#2018-08-04</a></blockquote><div><div class="ef hh hi hj hk hl"/><div class="hm hn ho hp hq"><div class=""/><div class=""><h2 id="6036" class="pw-subtitle-paragraph iq hs ht bd b ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ek translated"><strong class="ak"> <em class="ji">甘斯</em>简介</strong></h2></div><p id="2346" class="pw-post-body-paragraph jj jk ht jl b jm jn iu jo jp jq ix jr js jt ju jv jw jx jy jz ka kb kc kd ke hm dt translated">生成对抗网络<strong class="jl hu"> (GANs) </strong>是深度学习中最热门的话题之一。(<strong class="jl hu"> GANs) </strong>是一类用于无监督学习算法的人工算法，由两个神经网络系统实现</p><ol class=""><li id="39a0" class="kf kg ht jl b jm jn jp jq js kh jw ki ka kj ke kk kl km kn dt translated">发电机</li><li id="e54e" class="kf kg ht jl b jm ko jp kp js kq jw kr ka ks ke kk kl km kn dt translated">鉴别器</li></ol><p id="572f" class="pw-post-body-paragraph jj jk ht jl b jm jn iu jo jp jq ix jr js jt ju jv jw jx jy jz ka kb kc kd ke hm dt translated">两个网络都在零和博弈的框架下相互竞争。生成对抗网络<strong class="jl hu"> (GANs) </strong>是一组模型，它们基本上学习创建与给定的输入数据相似的合成数据。</p><figure class="ku kv kw kx fq ky fe ff paragraph-image"><div class="fe ff kt"><img src="../Images/6477cd00ca89cb32af3da8349454f444.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/format:webp/1*BqswKfX5uJeZQcRTitahQA.jpeg"/></div></figure><p id="5b3c" class="pw-post-body-paragraph jj jk ht jl b jm jn iu jo jp jq ix jr js jt ju jv jw jx jy jz ka kb kc kd ke hm dt translated">鉴别器的任务是确定给定图像看起来是自然的(即，是来自数据集的图像)还是看起来像是人工创建的。生成器的任务是创建与原始数据分布相似的看起来自然的图像，这些图像看起来足够自然以欺骗鉴别器网络。首先给发生器一个随机噪声，利用它产生假图像，然后这些假图像和原始图像一起被送到鉴别器。</p><p id="0caa" class="pw-post-body-paragraph jj jk ht jl b jm jn iu jo jp jq ix jr js jt ju jv jw jx jy jz ka kb kc kd ke hm dt translated">判别模型的任务是确定给定图像看起来是自然的(来自数据集的图像)还是看起来像是人工创建的。这基本上是一个二进制分类器，将采取正常的卷积神经网络(CNN)的形式。生成器的任务是创建与原始数据分布相似的自然图像。</p><p id="7a38" class="pw-post-body-paragraph jj jk ht jl b jm jn iu jo jp jq ix jr js jt ju jv jw jx jy jz ka kb kc kd ke hm dt translated">生成器试图愚弄鉴别器，而鉴别器试图不被生成器愚弄。随着模型通过交替优化进行训练，这两种方法都得到改进，直到“伪图像与数据集图像无法区分”为止。</p><p id="1366" class="pw-post-body-paragraph jj jk ht jl b jm jn iu jo jp jq ix jr js jt ju jv jw jx jy jz ka kb kc kd ke hm dt translated">生成对抗网络的数学方程；</p><figure class="ku kv kw kx fq ky fe ff paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="fe ff lb"><img src="../Images/06526cd46e089b08f7e8246dc38f94c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*07adQBed7pP4hnakPIQ6ZA.png"/></div></div></figure><p id="b91c" class="pw-post-body-paragraph jj jk ht jl b jm jn iu jo jp jq ix jr js jt ju jv jw jx jy jz ka kb kc kd ke hm dt translated">我们可以认为这个等式由两部分组成，第一部分是从原始数据分布中采样的数据，第二部分是从噪声的数据分布中采样的数据。</p><p id="4038" class="pw-post-body-paragraph jj jk ht jl b jm jn iu jo jp jq ix jr js jt ju jv jw jx jy jz ka kb kc kd ke hm dt translated"><strong class="jl hu"> <em class="lg">第一部分- </em> </strong></p><p id="f58c" class="pw-post-body-paragraph jj jk ht jl b jm jn iu jo jp jq ix jr js jt ju jv jw jx jy jz ka kb kc kd ke hm dt translated"><em class="lg">鉴别器</em>总是想最大化自己把一张图片正确分类为真假的概率。这里，图像是从原始数据分布中采样的，原始数据分布是真实的数据本身。我们知道<strong class="jl hu"> D(x) </strong>表示图像是真实的概率，因此<em class="lg">鉴别器</em>总是想要最大化<strong class="jl hu"> D(x) </strong>，因此<strong class="jl hu"> log(D(x)) </strong>应该最大化并且第一部分必须最大化。</p><p id="dd92" class="pw-post-body-paragraph jj jk ht jl b jm jn iu jo jp jq ix jr js jt ju jv jw jx jy jz ka kb kc kd ke hm dt translated"><strong class="jl hu"> <em class="lg">第二部分- </em> </strong></p><p id="9ad1" class="pw-post-body-paragraph jj jk ht jl b jm jn iu jo jp jq ix jr js jt ju jv jw jx jy jz ka kb kc kd ke hm dt translated">z’是随机噪声样本，G(z)是使用噪声样本生成的图像。这个术语的解释非常相似。生成器总是希望最大化鉴别器被生成的图像欺骗的概率。这意味着，生成器应该想要最大化<strong class="jl hu"> D(G(z)) </strong>，因此它应该最小化<strong class="jl hu"> 1- D(G(z)) </strong>，从而最小化<strong class="jl hu"> log(1- D(G(z))。</strong></p><h2 id="3060" class="lh li ht bd lj lk ll lm ln lo lp lq lr js ls lt lu jw lv lw lx ka ly lz ma mb dt translated">使用GANs生成名人图像</h2><figure class="ku kv kw kx fq ky fe ff paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="fe ff mc"><img src="../Images/abe75f090bbe28255644f6805c01e78f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AbMe5O-z4-Rj91-sWWA9tg.png"/></div></div></figure><h2 id="a56d" class="lh li ht bd lj lk ll lm ln lo lp lq lr js ls lt lu jw lv lw lx ka ly lz ma mb dt translated"><strong class="ak"> <em class="ji">名人图像数据集:</em> </strong></h2><p id="143e" class="pw-post-body-paragraph jj jk ht jl b jm md iu jo jp me ix jr js mf ju jv jw mg jy jz ka mh kc kd ke hm dt translated">CelebA数据集是超过200，000张带有注释的名人头像的集合。因为在这篇博客中，我只是要生成人脸，所以我没有考虑注释。</p><h2 id="2f46" class="lh li ht bd lj lk ll lm ln lo lp lq lr js ls lt lu jw lv lw lx ka ly lz ma mb dt translated">1).获取数据:-</h2><pre class="ku kv kw kx fq mi mj mk ml aw mm dt"><span id="fef4" class="lh li ht mj b fv mn mo l mp mq">import helper<br/>helper.download_extract('celeba', data_dir)</span></pre><p id="3a69" class="pw-post-body-paragraph jj jk ht jl b jm jn iu jo jp jq ix jr js jt ju jv jw jx jy jz ka kb kc kd ke hm dt translated">我已经创建了helper.py文件，您可以通过它下载CelebA数据集图像。运行这段代码时，它将下载CelebA数据集。(下面给出源代码链接)。</p><h2 id="742c" class="lh li ht bd lj lk ll lm ln lo lp lq lr js ls lt lu jw lv lw lx ka ly lz ma mb dt translated">2).预处理图像:-</h2><p id="c4f9" class="pw-post-body-paragraph jj jk ht jl b jm md iu jo jp me ix jr js mf ju jv jw mg jy jz ka mh kc kd ke hm dt translated">因为我只在人脸上工作，所以我把它调整到28*28以获得好的效果。我已经裁剪了图像中不包含图像部分的部分。</p><pre class="ku kv kw kx fq mi mj mk ml aw mm dt"><span id="2441" class="lh li ht mj b fv mn mo l mp mq">#snippet of Helper python file which preprocess the given image dataset.</span><span id="1a63" class="lh li ht mj b fv mr mo l mp mq">def get_image(image_path, width, height, mode):<br/>    """<br/>    Read image from image_path<br/>    :param image_path: Path of image<br/>    :param width: Width of image<br/>    :param height: Height of image<br/>    :param mode: Mode of image<br/>    :return: Image data<br/>    """<br/>    image = Image.open(image_path)</span><span id="2c53" class="lh li ht mj b fv mr mo l mp mq">if image.size != (width, height):  <br/>       <br/>        face_width = face_height = 108<br/>        j = (image.size[0] - face_width) // 2<br/>        i = (image.size[1] - face_height) // 2<br/>        image = image.crop([j, i, j + face_width, i + face_height])<br/>        image = image.resize([width, height], Image.BILINEAR)</span><span id="879e" class="lh li ht mj b fv mr mo l mp mq">return np.array(image.convert(mode))</span></pre><blockquote class="ms mt mu"><p id="144a" class="jj jk lg jl b jm jn iu jo jp jq ix jr mv jt ju jv mw jx jy jz mx kb kc kd ke hm dt translated">因为生成敌对网络很难训练。(你可以查看这个链接，以了解<a class="ae my" rel="noopener" href="/@jonathan_hui/gan-why-it-is-so-hard-to-train-generative-advisory-networks-819a86b3750b">为什么生成性对抗网络的训练这么难</a>？).</p></blockquote><p id="f6f9" class="pw-post-body-paragraph jj jk ht jl b jm jn iu jo jp jq ix jr js jt ju jv jw jx jy jz ka kb kc kd ke hm dt translated">为了获得准确的结果，我们应该有一个好的GPU(4GB或以上)，通过运行此代码片段，您可以发现tensorflow是否安装了GPU。</p><pre class="ku kv kw kx fq mi mj mk ml aw mm dt"><span id="39ac" class="lh li ht mj b fv mn mo l mp mq">from distutils.version import LooseVersion<br/>import warnings<br/>import tensorflow as tf</span><span id="b05b" class="lh li ht mj b fv mr mo l mp mq"># Check TensorFlow Version<br/>assert LooseVersion(tf.__version__) &gt;= LooseVersion('1.0'), 'Please use TensorFlow version 1.0 or newer.  You are using {}'.format(tf.__version__)<br/>print('TensorFlow Version: {}'.format(tf.__version__))</span><span id="204a" class="lh li ht mj b fv mr mo l mp mq"># Check for a GPU<br/>if not tf.test.gpu_device_name():<br/>    warnings.warn('No GPU found. Please use a GPU to train your neural network.')<br/>else:<br/>    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))</span></pre><h2 id="330f" class="lh li ht bd lj lk ll lm ln lo lp lq lr js ls lt lu jw lv lw lx ka ly lz ma mb dt translated">3).模型输入和网络架构-</h2><p id="2209" class="pw-post-body-paragraph jj jk ht jl b jm md iu jo jp me ix jr js mf ju jv jw mg jy jz ka mh kc kd ke hm dt translated">我将图像宽度、图像高度、图像通道和噪声参数作为模型输入，由生成器进一步用于生成假图像。</p><blockquote class="ms mt mu"><p id="3b7d" class="jj jk lg jl b jm jn iu jo jp jq ix jr mv jt ju jv mw jx jy jz mx kb kc kd ke hm dt translated">发电机的结构:-</p></blockquote><pre class="ku kv kw kx fq mi mj mk ml aw mm dt"><span id="1c5b" class="lh li ht mj b fv mn mo l mp mq">def generator(z, out_channel_dim, is_train=True, alpha=0.2, keep_prob=0.5):<br/>  <br/>    with tf.variable_scope('generator', reuse=(not is_train)):<br/>        # First fully connected layer, 4x4x1024<br/>        fc = tf.layers.dense(z, 4*4*1024, use_bias=False)<br/>        fc = tf.reshape(fc, (-1, 4, 4, 1024))<br/>        bn0 = tf.layers.batch_normalization(fc, training=is_train)<br/>        lrelu0 = tf.maximum(alpha * bn0, bn0)<br/>        drop0 = tf.layers.dropout(lrelu0, keep_prob, training=is_train)<br/>        <br/>        # Deconvolution, 7x7x512<br/>        conv1 = tf.layers.conv2d_transpose(drop0, 512, 4, 1, 'valid', use_bias=False)<br/>        bn1 = tf.layers.batch_normalization(conv1, training=is_train)<br/>        lrelu1 = tf.maximum(alpha * bn1, bn1)<br/>        drop1 = tf.layers.dropout(lrelu1, keep_prob, training=is_train)<br/>        <br/>        # Deconvolution, 14x14x256<br/>        conv2 = tf.layers.conv2d_transpose(drop1, 256, 5, 2, 'same', use_bias=False)<br/>        bn2 = tf.layers.batch_normalization(conv2, training=is_train)<br/>        lrelu2 = tf.maximum(alpha * bn2, bn2)<br/>        drop2 = tf.layers.dropout(lrelu2, keep_prob, training=is_train)<br/>        <br/>        # Output layer, 28x28xn<br/>        logits = tf.layers.conv2d_transpose(drop2, out_channel_dim, 5, 2, 'same')<br/>        <br/>        out = tf.tanh(logits)<br/>        <br/>        return out<br/>tests.test_generator(generator, tf)</span></pre><p id="38f2" class="pw-post-body-paragraph jj jk ht jl b jm jn iu jo jp jq ix jr js jt ju jv jw jx jy jz ka kb kc kd ke hm dt translated">生成器体系结构具有第一密集层和在去卷积层之后全连接层(除了输出层之外，每一层都包含batch_normalization、leaky relu和dropout层)。生成器获取一个随机噪声向量z，然后将其整形为4D形状，并将其传递给一系列上采样层。每个上采样层重复转置卷积操作，即反卷积操作。</p><p id="515f" class="pw-post-body-paragraph jj jk ht jl b jm jn iu jo jp jq ix jr js jt ju jv jw jx jy jz ka kb kc kd ke hm dt translated">所有转置卷积的深度从1024一直降低到3，这表示一幅RGB彩色图像。最后一层通过双曲正切(<a class="ae my" href="https://en.wikipedia.org/wiki/Activation_functionhttps://en.wikipedia.org/wiki/Activation_function" rel="noopener ugc nofollow" target="_blank"> tanh </a>)函数输出一个28 <em class="lg"> x28x3 </em>张量。</p><blockquote class="ms mt mu"><p id="efea" class="jj jk lg jl b jm jn iu jo jp jq ix jr mv jt ju jv mw jx jy jz mx kb kc kd ke hm dt translated">鉴别器的结构:-</p></blockquote><pre class="ku kv kw kx fq mi mj mk ml aw mm dt"><span id="5452" class="lh li ht mj b fv mn mo l mp mq">def discriminator(images, reuse=False, alpha=0.2, keep_prob=0.5):<br/>    <br/>    with tf.variable_scope('discriminator', reuse=reuse):<br/>        # Input layer is 28x28xn<br/>        # Convolutional layer, 14x14x64<br/>        conv1 = tf.layers.conv2d(images, 64, 5, 2, padding='same', kernel_initializer=tf.contrib.layers.xavier_initializer())<br/>        lrelu1 = tf.maximum(alpha * conv1, conv1)<br/>        drop1 = tf.layers.dropout(lrelu1, keep_prob)<br/>        <br/>        # Strided convolutional layer, 7x7x128<br/>        conv2 = tf.layers.conv2d(drop1, 128, 5, 2, 'same', use_bias=False)<br/>        bn2 = tf.layers.batch_normalization(conv2)<br/>        lrelu2 = tf.maximum(alpha * bn2, bn2)<br/>        drop2 = tf.layers.dropout(lrelu2, keep_prob)<br/>        <br/>        # Strided convolutional layer, 4x4x256<br/>        conv3 = tf.layers.conv2d(drop2, 256, 5, 2, 'same', use_bias=False)<br/>        bn3 = tf.layers.batch_normalization(conv3)<br/>        lrelu3 = tf.maximum(alpha * bn3, bn3)<br/>        drop3 = tf.layers.dropout(lrelu3, keep_prob)<br/>        <br/>        # fully connected<br/>        flat = tf.reshape(drop3, (-1, 4*4*256))<br/>        logits = tf.layers.dense(flat, 1)<br/>        out = tf.sigmoid(logits)<br/>        <br/>        return out, logits</span><span id="97da" class="lh li ht mj b fv mr mo l mp mq">tests.test_discriminator(discriminator, tf)</span></pre><p id="4f64" class="pw-post-body-paragraph jj jk ht jl b jm jn iu jo jp jq ix jr js jt ju jv jw jx jy jz ka kb kc kd ke hm dt translated">鉴别器的工作就是鉴别哪个图像是真的，哪个是假的。鉴别器也是4层CNN，具有批量归一化和泄漏relu层(输入层除外)。鉴别器接收输出图像(大小为28*28*3)并对其执行卷积。最后鉴别器使用<strong class="jl hu"> <em class="lg">逻辑Sigmoid函数</em> </strong> <em class="lg">显示输出概率，以显示图像是真是假。</em></p><blockquote class="ms mt mu"><p id="3350" class="jj jk lg jl b jm jn iu jo jp jq ix jr mv jt ju jv mw jx jy jz mx kb kc kd ke hm dt translated">当鉴别器看到图像中的差异时，它向发生器发送梯度信号，该信号从鉴别器流向发生器。</p></blockquote><h2 id="73b9" class="lh li ht bd lj lk ll lm ln lo lp lq lr js ls lt lu jw lv lw lx ka ly lz ma mb dt translated">4).发电机损耗和鉴别器损耗:-</h2><p id="1955" class="pw-post-body-paragraph jj jk ht jl b jm md iu jo jp me ix jr js mf ju jv jw mg jy jz ka mh kc kd ke hm dt translated">鉴别器接收来自训练图像和发生器的图像，因此在计算鉴别器的损失时，我们必须加上真实图像和虚假图像造成的损失。两个网络同时被训练，因此发生器和鉴别器都需要两个优化器。如果图像是真实的，我们希望从鉴别器输出接近1的概率，如果图像是假的，输出接近0的概率。</p><pre class="ku kv kw kx fq mi mj mk ml aw mm dt"><span id="34b7" class="lh li ht mj b fv mn mo l mp mq">def model_loss(input_real, input_z, out_channel_dim, alpha=0.2, smooth_factor=0.1):<br/>    <br/>    # TODO: Implement Function<br/>    d_model_real, d_logits_real = discriminator(input_real, alpha=alpha)<br/>    <br/>    d_loss_real = tf.reduce_mean(<br/>        tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_real,<br/>                                                labels=tf.ones_like(d_model_real) * (1 - smooth_factor)))<br/>    <br/>    input_fake = generator(input_z, out_channel_dim, alpha=alpha)<br/>    d_model_fake, d_logits_fake = discriminator(input_fake, reuse=True, alpha=alpha)<br/>    <br/>    d_loss_fake = tf.reduce_mean(<br/>        tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake, labels=tf.zeros_like(d_model_fake)))<br/>    <br/>    g_loss = tf.reduce_mean(<br/>        tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake, labels=tf.ones_like(d_model_fake)))</span><span id="8fc8" class="lh li ht mj b fv mr mo l mp mq">return d_loss_real + d_loss_fake, g_loss</span><span id="8bcf" class="lh li ht mj b fv mr mo l mp mq">tests.test_model_loss(model_loss)</span></pre><h2 id="91aa" class="lh li ht bd lj lk ll lm ln lo lp lq lr js ls lt lu jw lv lw lx ka ly lz ma mb dt translated">培训和结果:-</h2><p id="5112" class="pw-post-body-paragraph jj jk ht jl b jm md iu jo jp me ix jr js mf ju jv jw mg jy jz ka mh kc kd ke hm dt translated">当训练过程正在进行时，生成器产生图像集，并且在每个时期之后，它变得越来越好，使得鉴别器不能识别它是真实图像还是虚假图像。产生结果如下-</p><h2 id="e74b" class="lh li ht bd lj lk ll lm ln lo lp lq lr js ls lt lu jw lv lw lx ka ly lz ma mb dt translated">生成的图像:-</h2><div class="ku kv kw kx fq ab cb"><figure class="mz ky na nb nc nd ne paragraph-image"><img src="../Images/e2fa20de1b03782ee36a5f3012e66092.png" data-original-src="https://miro.medium.com/v2/resize:fit:280/format:webp/1*-WZvqhgqi1jnpp7wlqjniA.png"/></figure><figure class="mz ky na nb nc nd ne paragraph-image"><img src="../Images/de18c5b58ff9af1512471243001fbead.png" data-original-src="https://miro.medium.com/v2/resize:fit:280/format:webp/1*7ped99JzASx55f5dIvdkvg.png"/><figcaption class="nf ng fg fe ff nh ni bd b be z ek nj di nk nl">After first Epoch and After Second Epoch</figcaption></figure></div><div class="ab cb"><figure class="mz ky na nb nc nd ne paragraph-image"><img src="../Images/efce3e250e0f490ea07487184ee8700f.png" data-original-src="https://miro.medium.com/v2/resize:fit:280/format:webp/1*FNVgUtYrNZTa8mBtzj7oMw.png"/></figure><figure class="mz ky na nb nc nd ne paragraph-image"><img src="../Images/a34aec6ade6ecf446ee357edcec3cc81.png" data-original-src="https://miro.medium.com/v2/resize:fit:280/format:webp/1*MoFkyDE2_k3tPAkrIJ-tKA.png"/><figcaption class="nf ng fg fe ff nh ni bd b be z ek nj di nk nl">After third and fourth Epoch</figcaption></figure></div><div class="ab cb"><figure class="mz ky na nb nc nd ne paragraph-image"><img src="../Images/83ccb27825b8b5d39da6701309c2c75b.png" data-original-src="https://miro.medium.com/v2/resize:fit:280/format:webp/1*I7sYHVjHhi6RdP3mRzMtMA.png"/></figure><figure class="mz ky na nb nc nd ne paragraph-image"><img src="../Images/505172c9d2a321cfd282a655013dfaa2.png" data-original-src="https://miro.medium.com/v2/resize:fit:280/format:webp/1*xZEOBh8nLHVTDns6ApiASw.png"/><figcaption class="nf ng fg fe ff nh ni bd b be z ek nj di nk nl">after fifth and sixth epoch</figcaption></figure></div><p id="07a7" class="pw-post-body-paragraph jj jk ht jl b jm jn iu jo jp jq ix jr js jt ju jv jw jx jy jz ka kb kc kd ke hm dt translated">等等，新的面孔不断产生…</p><p id="550a" class="pw-post-body-paragraph jj jk ht jl b jm jn iu jo jp jq ix jr js jt ju jv jw jx jy jz ka kb kc kd ke hm dt translated">我还从<a class="ae my" href="https://drive.google.com/drive/folders/15hvzxt_XxuokSmj0uO4xxMTMWVc0cIMU" rel="noopener ugc nofollow" target="_blank">这里</a>得到了预训练的网络，如果你想使用这个预训练的网络运行GAN，那么使用我在这里<a class="ae my" href="https://drive.google.com/file/d/1xZul7DwqqJoe5OCuKHw6fQVeQZNIMSuF/view" rel="noopener ugc nofollow" target="_blank">提供的这个python文件</a>。</p><p id="1b23" class="pw-post-body-paragraph jj jk ht jl b jm jn iu jo jp jq ix jr js jt ju jv jw jx jy jz ka kb kc kd ke hm dt translated">运行后，这将生成一组10个假图像。有些是-</p><div class="ku kv kw kx fq ab cb"><figure class="mz ky nm nb nc nd ne paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><img src="../Images/1f5c9f27cc42d73668f7e0a843454693.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*7UZWo_m_i6z1r13DVa_d_w.png"/></div></figure><figure class="mz ky nm nb nc nd ne paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><img src="../Images/3656586558e7275e2184b3fb0ffacf36.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*L3GyCKxLGy_Vuh3QpAKRgA.png"/></div></figure><figure class="mz ky nm nb nc nd ne paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><img src="../Images/cbfb995a79d18946e565f9da0839bbfe.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*GoJgyqkc0aMR2XGH4gRTCA.png"/></div></figure></div><div class="ab cb"><figure class="mz ky nm nb nc nd ne paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><img src="../Images/4818163cc7f7848c983a044615f17e7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*N6JeDTSziIhnmdW3cinSoA.png"/></div></figure><figure class="mz ky nm nb nc nd ne paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><img src="../Images/b486b16d2ae8554f81c52e995c3760c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*1fDnRh0uMyowX12PeXOKfQ.png"/></div></figure><figure class="mz ky nm nb nc nd ne paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><img src="../Images/f16336e4388b96f4a1db39c2e0d44c43.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*nRdyAcRYTe8221vyHhMsCQ.png"/></div></figure></div><p id="7edf" class="pw-post-body-paragraph jj jk ht jl b jm jn iu jo jp jq ix jr js jt ju jv jw jx jy jz ka kb kc kd ke hm dt translated">这些是从给定的预训练网络生成的假图像。</p><p id="b6b3" class="pw-post-body-paragraph jj jk ht jl b jm jn iu jo jp jq ix jr js jt ju jv jw jx jy jz ka kb kc kd ke hm dt translated">这就完成了与生成性对抗网络相关的所有惊人的东西。</p><h1 id="0cfa" class="nn li ht bd lj no np nq ln nr ns nt lr iz nu ja lu jc nv jd lx jf nw jg ma nx dt translated">参考资料:-</h1><ol class=""><li id="ce42" class="kf kg ht jl b jm md jp me js ny jw nz ka oa ke kk kl km kn dt translated"><a class="ae my" rel="noopener" href="/deep-dimension/gans-a-modern-perspective-83ed64b42f5c">生成对抗网络教程</a></li><li id="49c5" class="kf kg ht jl b jm ko jp kp js kq jw kr ka ks ke kk kl km kn dt translated"><a class="ae my" rel="noopener" href="/deep-dimension/gans-a-modern-perspective-83ed64b42f5c"> Shravan关于甘的博客</a></li><li id="139e" class="kf kg ht jl b jm ko jp kp js kq jw kr ka ks ke kk kl km kn dt translated"><a class="ae my" href="https://www.oreilly.com/learning/generative-adversarial-networks-for-beginners" rel="noopener ugc nofollow" target="_blank">一个关于生成性对抗网络的很好的教程</a></li><li id="d8eb" class="kf kg ht jl b jm ko jp kp js kq jw kr ka ks ke kk kl km kn dt translated"><a class="ae my" href="https://towardsdatascience.com/understanding-generative-adversarial-networks-4dafc963f2ef" rel="noopener" target="_blank">了解创成式数字网络</a> k</li></ol><p id="f12d" class="pw-post-body-paragraph jj jk ht jl b jm jn iu jo jp jq ix jr js jt ju jv jw jx jy jz ka kb kc kd ke hm dt translated">这个项目的代码可以在我的Github-:<a class="ae my" href="https://github.com/HACKERSHUBH/Face-Genaration-using-Generative-Adversarial-Network" rel="noopener ugc nofollow" target="_blank">https://Github . com/hacker shubh/Face-gen aration-using-Generative-Adversarial-Network</a>中找到。</p><blockquote class="ob"><p id="6ed7" class="oc od ht bd oe of og oh oi oj ok ke ek translated">加入Coinmonks <a class="ae my" href="https://t.me/coincodecap" rel="noopener ugc nofollow" target="_blank">电报频道</a>和<a class="ae my" href="https://www.youtube.com/c/coinmonks/videos" rel="noopener ugc nofollow" target="_blank"> Youtube频道</a>获取每日<a class="ae my" href="http://coincodecap.com/" rel="noopener ugc nofollow" target="_blank">加密新闻</a></p></blockquote><h2 id="15d6" class="lh li ht bd lj lk ol lm ln lo om lq lr js on lt lu jw oo lw lx ka op lz ma mb dt translated">另外，阅读</h2><ul class=""><li id="20fb" class="kf kg ht jl b jm md jp me js ny jw nz ka oa ke oq kl km kn dt translated"><a class="ae my" rel="noopener" href="/coinmonks/top-10-crypto-copy-trading-platforms-for-beginners-d0c37c7d698c">复制交易</a> | <a class="ae my" rel="noopener" href="/coinmonks/crypto-tax-software-ed4b4810e338">加密税务软件</a></li><li id="723e" class="kf kg ht jl b jm ko jp kp js kq jw kr ka ks ke oq kl km kn dt translated"><a class="ae my" href="https://coincodecap.com/grid-trading" rel="noopener ugc nofollow" target="_blank">网格交易</a> | <a class="ae my" rel="noopener" href="/coinmonks/the-best-cryptocurrency-hardware-wallets-of-2020-e28b1c124069">加密硬件钱包</a></li><li id="874f" class="kf kg ht jl b jm ko jp kp js kq jw kr ka ks ke oq kl km kn dt translated"><a class="ae my" href="http://Top 4 Telegram Channels for Crypto Traders" rel="noopener ugc nofollow" target="_blank">密码电报信号</a> | <a class="ae my" rel="noopener" href="/coinmonks/crypto-trading-bot-c2ffce8acb2a">密码交易机器人</a></li><li id="f33b" class="kf kg ht jl b jm ko jp kp js kq jw kr ka ks ke oq kl km kn dt translated"><a class="ae my" rel="noopener" href="/coinmonks/crypto-exchange-dd2f9d6f3769">最佳加密交易所</a> | <a class="ae my" rel="noopener" href="/coinmonks/bitcoin-exchange-in-india-7f1fe79715c9">最佳加密交易所</a></li><li id="47a8" class="kf kg ht jl b jm ko jp kp js kq jw kr ka ks ke oq kl km kn dt translated">开发人员的最佳加密API</li><li id="b359" class="kf kg ht jl b jm ko jp kp js kq jw kr ka ks ke oq kl km kn dt translated">最佳<a class="ae my" rel="noopener" href="/coinmonks/top-5-crypto-lending-platforms-in-2020-that-you-need-to-know-a1b675cec3fa">密码借贷平台</a></li><li id="9487" class="kf kg ht jl b jm ko jp kp js kq jw kr ka ks ke oq kl km kn dt translated">杠杆代币的终极指南</li><li id="f1ee" class="kf kg ht jl b jm ko jp kp js kq jw kr ka ks ke oq kl km kn dt translated"><a class="ae my" href="https://coincodecap.com/zero-fee-crypto-exchanges" rel="noopener ugc nofollow" target="_blank"> 7个最佳零费用加密交易平台</a></li><li id="5aa5" class="kf kg ht jl b jm ko jp kp js kq jw kr ka ks ke oq kl km kn dt translated"><a class="ae my" href="https://coincodecap.com/best-online-casinos" rel="noopener ugc nofollow" target="_blank">最佳网上赌场</a> | <a class="ae my" rel="noopener" href="/coinmonks/futures-trading-bots-5a282ccee3f5">期货交易机器人</a></li><li id="3d0e" class="kf kg ht jl b jm ko jp kp js kq jw kr ka ks ke oq kl km kn dt translated"><a class="ae my" href="https://coincodecap.com/what-are-decentralized-exchanges" rel="noopener ugc nofollow" target="_blank">分散交易所</a> | <a class="ae my" href="https://coincodecap.com/bitbns-fip" rel="noopener ugc nofollow" target="_blank">比特FIP </a></li><li id="5cf9" class="kf kg ht jl b jm ko jp kp js kq jw kr ka ks ke oq kl km kn dt translated"><a class="ae my" href="https://coincodecap.com/buy-crypto-with-credit-card" rel="noopener ugc nofollow" target="_blank">用信用卡购买密码的10个最佳地点</a></li><li id="3d13" class="kf kg ht jl b jm ko jp kp js kq jw kr ka ks ke oq kl km kn dt translated"><a class="ae my" href="https://coincodecap.com/5-best-crypto-trading-bots-in-canada" rel="noopener ugc nofollow" target="_blank">加拿大最佳加密交易机器人</a> | <a class="ae my" href="https://coincodecap.com/bybit-binance-moonxbt" rel="noopener ugc nofollow" target="_blank"> Bybit vs币安</a></li></ul></div></div>    
</body>
</html>