<html>
<head>
<title>Rethinking the Inception Architecture for Computer Vision — Part 1</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">重新思考计算机视觉的初始架构——第1部分</h1>
<blockquote>原文：<a href="https://medium.com/coinmonks/rethinking-the-inception-architecture-for-computer-vision-part-1-2938cc7c7872?source=collection_archive---------1-----------------------#2018-07-16">https://medium.com/coinmonks/rethinking-the-inception-architecture-for-computer-vision-part-1-2938cc7c7872?source=collection_archive---------1-----------------------#2018-07-16</a></blockquote><div><div class="ef hh hi hj hk hl"/><div class="hm hn ho hp hq"><div class=""/><p id="0fd4" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">我最近读了这篇关于初始架构的论文。我也在这里整理笔记。这个记录研究论文以备将来参考的酷主意是受Jae Duk Seo的启发。</p><figure class="jp jq jr js fq jt"><div class="bz el l di"><div class="ju jv l"/></div><figcaption class="jw jx fg fe ff jy jz bd b be z ek">Rethinking the Inception Architecture for Computer Vision</figcaption></figure><h1 id="2754" class="ka kb ht bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dt translated">Conv篮网开赛前的小历史</h1><p id="d0b7" class="pw-post-body-paragraph iq ir ht is b it ky iv iw ix kz iz ja jb la jd je jf lb jh ji jj lc jl jm jn hm dt translated">在卷积神经网络用于图像分类之前，特征提取和分类用于计算机视觉中对图像进行分类。特征提取是一个耗时的过程，必须根据数据仔细选择特征。因此，每次根据图像来定制特征就变成了一项麻烦的任务。</p><p id="855b" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">深度学习兴起后，卷积神经网络开始用于图像分类、图像分割和其他计算机视觉任务。</p><h2 id="7fb5" class="ld kb ht bd kc le lf lg kg lh li lj kk jb lk ll ko jf lm ln ks jj lo lp kw lq dt translated">什么是ImageNet？</h2><p id="d362" class="pw-post-body-paragraph iq ir ht is b it ky iv iw ix kz iz ja jb la jd je jf lb jh ji jj lc jl jm jn hm dt translated"><a class="ae jo" href="http://image-net.org/" rel="noopener ugc nofollow" target="_blank"> ImageNet </a>是一个正式的项目，旨在(手动)将图像标记和分类为近22，000个独立的对象类别，用于计算机视觉研究。</p><p id="e282" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">然而，当我们在深度学习和卷积神经网络的背景下听到术语<em class="lr">【ImageNet】</em>时，我们很可能指的是<a class="ae jo" href="http://www.image-net.org/challenges/LSVRC/" rel="noopener ugc nofollow" target="_blank"> <em class="lr"> ImageNet大规模视觉识别挑战</em> </a>，简称ILSVRC。</p><p id="4d2c" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">这个图像分类挑战的目标是训练一个模型，该模型可以将输入图像正确地分类成1，000个单独的对象类别。</p><p id="6f7c" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">模型在大约120万张训练图像上进行训练，另外50，000张图像用于验证，100，000张图像用于测试。</p><p id="01df" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">这1，000个图像类别代表了我们在日常生活中遇到的对象类别，如狗、猫、各种家用物品、车辆类型等。你可以在这里找到ILSVRC挑战赛<a class="ae jo" href="http://image-net.org/challenges/LSVRC/2014/browse-synsets" rel="noopener ugc nofollow" target="_blank">中物体类别的完整列表</a>。</p><p id="4d55" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">说到图像分类，ImageNet挑战是计算机视觉分类算法的事实上的基准。</p><p id="ca43" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">Alex net——这是最早使用的CNN架构之一。它由5个卷积层和3个全连接层组成。首次使用了ReLu激活函数，解决了渐变爆炸和渐变消失的问题。此外，它使用辍学作为一种正规化技术。它包括11x11、5x5、3x3、卷积、最大池、数据扩充、带动量的SGD。它在每个卷积和全连接层之后附加ReLU激活。</p><figure class="jp jq jr js fq jt fe ff paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="fe ff ls"><img src="../Images/5816c26891e49a0ba35f989e0daa9ee2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*L1dP8rQflJNhf3Irg1UXPQ.png"/></div></div></figure><p id="d8aa" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">VGG16 — VGGNet在<a class="ae jo" href="https://arxiv.org/abs/1409.1556" rel="noopener ugc nofollow" target="_blank">论文</a> <em class="lr">中介绍了用于大规模图像识别的极深卷积网络。</em>它确实是一个非常深的架构，由16个卷积层组成。</p><p id="1213" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">它只使用3x3过滤器，最大池，并有一个非常统一的架构。</p><figure class="jp jq jr js fq jt fe ff paragraph-image"><div class="fe ff lz"><img src="../Images/e55cd32002cf3139ecf1509a2bba663a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*g8fe6eiwOcPKJ8jdkcrLtA.png"/></div></figure><p id="a2e3" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">这意味着深度卷积架构中的架构改进可以用于提高大多数其他计算机视觉任务的性能，这些任务越来越依赖于高质量的学习视觉特征。</p><h2 id="e620" class="ld kb ht bd kc le lf lg kg lh li lj kk jb lk ll ko jf lm ln ks jj lo lp kw lq dt translated">介绍</h2><figure class="jp jq jr js fq jt fe ff paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="fe ff ma"><img src="../Images/480466d665f8437cbda91d098fbdecdc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Nfn5lOpTyNt84Z70mpEreQ.png"/></div></div></figure><p id="722d" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">基本上，如果我们采用旧的方法，AlexNet即使对于通常需要制定特殊功能的任务也能给出很好的准确性。但是AlexNet有大量的参数，这使得它的计算非常昂贵。虽然VGGNet的架构更加统一和简单，但它的参数比AlexNet多3倍。</p><p id="9739" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">GoogLeNet(初始架构)的计算成本很低。因此，它可以用在内存或计算能力有限的地方(大数据场景)。但是由于这个架构比较复杂，所以很难对其进行改动，使其变得更好。我们将在本文中看到一些技术。</p><h2 id="2576" class="ld kb ht bd kc le lf lg kg lh li lj kk jb lk ll ko jf lm ln ks jj lo lp kw lq dt translated">一般设计原则</h2><figure class="jp jq jr js fq jt fe ff paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="fe ff mb"><img src="../Images/f4879e1680f9dc6612b8e290ec8227bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hRlo_G6keXyVlhsIUdWJ8A.png"/></div></div></figure><p id="2ed0" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">基于实验证据的CNN架构的一些一般原则是:</p><ol class=""><li id="3b35" class="mc md ht is b it iu ix iy jb me jf mf jj mg jn mh mi mj mk dt translated">通过极度压缩避免瓶颈。尺寸应该逐渐减小。</li><li id="89f7" class="mc md ht is b it ml ix mm jb mn jf mo jj mp jn mh mi mj mk dt translated"><strong class="is hu">增加每张牌的激活次数将导致</strong> <a class="ae jo" href="https://www.tik.ee.ethz.ch/file/11601d4777e61d25ee085e4419bc4308/LearningDisentRepresentations.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="is hu"> <em class="lr">解除特征</em> </strong> </a> <strong class="is hu">并导致更快的训练。</strong></li><li id="0a16" class="mc md ht is b it ml ix mm jb mn jf mo jj mp jn mh mi mj mk dt translated">在进行空间聚合之前降低输入的维度，而不会损失太多的表示。</li><li id="05f5" class="mc md ht is b it ml ix mm jb mn jf mo jj mp jn mh mi mj mk dt translated">在网络的高度和宽度之间分配计算预算。</li></ol><h2 id="0fad" class="ld kb ht bd kc le lf lg kg lh li lj kk jb lk ll ko jf lm ln ks jj lo lp kw lq dt translated">分解具有大滤波器尺寸的卷积</h2><p id="f051" class="pw-post-body-paragraph iq ir ht is b it ky iv iw ix kz iz ja jb la jd je jf lb jh ji jj lc jl jm jn hm dt translated">基本上，在论文<a class="ae jo" href="https://arxiv.org/abs/1409.4842" rel="noopener ugc nofollow" target="_blank">深入探讨卷积</a>中，介绍了初始架构，它将不同滤波器大小的滤波器输出连接在一起。除了连接之外，它还引入了降维技术。(将进一步讨论)</p><figure class="jp jq jr js fq jt fe ff paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="fe ff mq"><img src="../Images/f829cb9c7fe07d1abde575d47bdc6d25.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*F6Jg41d5jM28Zq3lHG0cew.png"/></div></div></figure><p id="03b0" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">但是，像5x5、7x7这样的大滤波器尺寸的卷积计算量非常大。如果我们用两个3×3的过滤层代替5×5的过滤层，会怎么样</p><figure class="jp jq jr js fq jt fe ff paragraph-image"><div class="fe ff mr"><img src="../Images/b7e43391ca92c4175c37cbe5fed6757b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1364/format:webp/1*XYOid2ddcI7AAyeyETRADQ.png"/></div></figure><p id="83b2" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">可以想象，这个两层网络与5x5卷积做同样的工作，但是参数更少，因此计算量更少。因此，我们的计算时间减少了(9+9/25)。</p><figure class="jp jq jr js fq jt fe ff paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="fe ff ms"><img src="../Images/33e023f24f94f2acd3f678d12f033982.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7wtV2a-QapWBAFMN-QNAKw.png"/></div></div></figure><h2 id="540a" class="ld kb ht bd kc le lf lg kg lh li lj kk jb lk ll ko jf lm ln ks jj lo lp kw lq dt translated">额外阅读——初始架构中的维度缩减</h2><h2 id="f06a" class="ld kb ht bd kc le lf lg kg lh li lj kk jb lk ll ko jf lm ln ks jj lo lp kw lq dt translated">卷积解释:</h2><p id="70a2" class="pw-post-body-paragraph iq ir ht is b it ky iv iw ix kz iz ja jb la jd je jf lb jh ji jj lc jl jm jn hm dt translated">使用3×3滤波器的卷积运算:</p><figure class="jp jq jr js fq jt fe ff paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="fe ff mt"><img src="../Images/d2e0f2b039b660a61a6d8e9e011a9528.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*drwxQWrICM4q-uwfBwt18g.png"/></div></div></figure><p id="2d35" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">卷积运算1x1滤波器，深度3，滤波器数量-1:</p><figure class="jp jq jr js fq jt fe ff paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="fe ff mu"><img src="../Images/0b653df54298750706853c0d70d1351b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DMhe62jmSti6Y51ODpI6eg.png"/></div></div></figure><p id="2114" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">卷积运算1x1滤波器，深度-3，滤波器数量- 2:</p><figure class="jp jq jr js fq jt fe ff paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="fe ff mv"><img src="../Images/e765c125a06da90cd65e5734c0c8ae0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cuKlYQNZBsInEhMTshOcmg.png"/></div></div></figure><p id="f8ac" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">卷积运算1x1滤波器，深度- 3，滤波器数量-3:</p><figure class="jp jq jr js fq jt fe ff paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="fe ff mw"><img src="../Images/e223ad6555bfb663c47ce13985533bc6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EmiX8Cr2IRs_VHwvIMHBxg.png"/></div></div></figure><h2 id="467b" class="ld kb ht bd kc le lf lg kg lh li lj kk jb lk ll ko jf lm ln ks jj lo lp kw lq dt translated">1x1卷积如何减少运算次数？</h2><figure class="jp jq jr js fq jt fe ff paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="fe ff mx"><img src="../Images/4d8f3a3757d7f2d1ce2cc24dbdaf74e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yRL1DwfFBlnfB7U-9GB1lA.png"/></div></div></figure><p id="0d8b" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">在上面的卷积中，</p><p id="c463" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">28x28(输入图像的大小)x5x5(滤镜的大小)x192(通道)x32(滤镜的数量)= 120，422，400次操作</p><figure class="jp jq jr js fq jt fe ff paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="fe ff my"><img src="../Images/b1f7ebd2de896072847c210b9412768e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Gtl0KhtrtM7ZJB1UtMeACA.png"/></div></div></figure><p id="cdad" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">中间有1x1卷积，运算次数变为:</p><p id="383e" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">28 x 28 x 1 x 1 x 192 x 16+28 x 28 x 5 x 5 x 16 x 32 = 12，443，648--&gt;<strong class="is hu">运算次数减少10倍</strong></p><h2 id="fae9" class="ld kb ht bd kc le lf lg kg lh li lj kk jb lk ll ko jf lm ln ks jj lo lp kw lq dt translated">资源</h2><div class="mz na fm fo nb nc"><a href="https://www.pyimagesearch.com/2017/03/20/imagenet-vggnet-resnet-inception-xception-keras/" rel="noopener  ugc nofollow" target="_blank"><div class="nd ab ej"><div class="ne ab nf cl cj ng"><h2 class="bd hu fv z el nh eo ep ni er et hs dt translated">ImageNet: VGGNet、ResNet、Inception和exception with Keras-PyImageSearch</h2><div class="nj l"><h3 class="bd b fv z el nh eo ep ni er et ek translated">几个月前，我写了一篇关于如何使用卷积神经网络(特别是VGG16)对图像进行分类的教程…</h3></div><div class="nk l"><p class="bd b gc z el nh eo ep ni er et ek translated">www.pyimagesearch.com</p></div></div><div class="nl l"><div class="nm l nn no np nl nq lx nc"/></div></div></a></div><div class="mz na fm fo nb nc"><a href="http://cv-tricks.com/cnn/understand-resnet-alexnet-vgg-inception/" rel="noopener  ugc nofollow" target="_blank"><div class="nd ab ej"><div class="ne ab nf cl cj ng"><h2 class="bd hu fv z el nh eo ep ni er et hs dt translated">ResNet，AlexNet，VGGNet，Inception:理解卷积网络的各种架构</h2><div class="nj l"><h3 class="bd b fv z el nh eo ep ni er et ek translated">好的ConvNets是有数百万个参数和许多隐藏层的野兽。事实上，一个糟糕的经验法则是:‘更高…</h3></div><div class="nk l"><p class="bd b gc z el nh eo ep ni er et ek translated">cv-tricks.com</p></div></div><div class="nl l"><div class="nr l nn no np nl nq lx nc"/></div></div></a></div><div class="mz na fm fo nb nc"><a href="https://www.quora.com/How-are-1x1-convolutions-used-for-dimensionality-reduction" rel="noopener  ugc nofollow" target="_blank"><div class="nd ab ej"><div class="ne ab nf cl cj ng"><h2 class="bd hu fv z el nh eo ep ni er et hs dt translated">1x1卷积是如何用于降维的？</h2><div class="nj l"><h3 class="bd b fv z el nh eo ep ni er et ek translated">回答(第1题，共5题):我明白为什么这很令人困惑。从表面上看，如果你用一个1x1内核卷积…</h3></div><div class="nk l"><p class="bd b gc z el nh eo ep ni er et ek translated">www.quora.com</p></div></div><div class="nl l"><div class="ns l nn no np nl nq lx nc"/></div></div></a></div></div></div>    
</body>
</html>