<html>
<head>
<title>Review: Fast R-CNN (Object Detection)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">回顾:快速R-CNN(目标检测)</h1>
<blockquote>原文：<a href="https://medium.com/coinmonks/review-fast-r-cnn-object-detection-a82e172e87ba?source=collection_archive---------0-----------------------#2018-09-04">https://medium.com/coinmonks/review-fast-r-cnn-object-detection-a82e172e87ba?source=collection_archive---------0-----------------------#2018-09-04</a></blockquote><div><div class="ef hh hi hj hk hl"/><div class="hm hn ho hp hq"><div class=""/><p id="c254" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt jo translated"><span class="l jp jq jr bm js jt ju jv jw di">在</span> <strong class="is hu">这个故事中，快速基于区域的卷积网络方法(Fast R-CNN) [1]被回顾。它提高了训练和测试速度，也提高了检测精度。</strong></p><ol class=""><li id="1431" class="jx jy ht is b it iu ix iy jb jz jf ka jj kb jn kc kd ke kf dt translated"><strong class="is hu">快速R-CNN训练非常深的VGG-16 [2]比R-CNN [3]快9倍，在测试时间快213倍</strong></li><li id="8ff7" class="jx jy ht is b it kg ix kh jb ki jf kj jj kk jn kc kd ke kf dt translated"><strong class="is hu">PASCAL VOC 2012上的高等地图</strong></li><li id="0352" class="jx jy ht is b it kg ix kh jb ki jf kj jj kk jn kc kd ke kf dt translated"><strong class="is hu">与SPPNet [4]相比，它训练VGG-16的速度快3倍，测试速度快10倍，而且更准确。</strong></li></ol><p id="6504" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">这是一篇<strong class="is hu"> 2015 </strong> <strong class="is hu"> ICCV论文</strong>有<strong class="is hu">3000多篇引用</strong>当我在写这个故事的时候。(<a class="kl km gr" href="https://medium.com/u/aff72a0c1243?source=post_page-----a82e172e87ba--------------------------------" rel="noopener" target="_blank"> Sik-Ho Tsang </a> @中)</p></div><div class="ab cl kn ko hb kp" role="separator"><span class="kq bw bk kr ks kt"/><span class="kq bw bk kr ks kt"/><span class="kq bw bk kr ks"/></div><div class="hm hn ho hp hq"><h1 id="f7fe" class="ku kv ht bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr dt translated">涵盖哪些内容</h1><ol class=""><li id="9dfe" class="jx jy ht is b it ls ix lt jb lu jf lv jj lw jn kc kd ke kf dt translated"><strong class="is hu">现有技术的问题</strong></li><li id="087c" class="jx jy ht is b it kg ix kh jb ki jf kj jj kk jn kc kd ke kf dt translated"><strong class="is hu"> ROI汇集层</strong></li><li id="4c42" class="jx jy ht is b it kg ix kh jb ki jf kj jj kk jn kc kd ke kf dt translated"><strong class="is hu">多任务损失</strong></li><li id="7a55" class="jx jy ht is b it kg ix kh jb ki jf kj jj kk jn kc kd ke kf dt translated"><strong class="is hu">其他一些消融研究</strong></li><li id="eb96" class="jx jy ht is b it kg ix kh jb ki jf kj jj kk jn kc kd ke kf dt translated"><strong class="is hu">与最先进结果的比较</strong></li></ol></div><div class="ab cl kn ko hb kp" role="separator"><span class="kq bw bk kr ks kt"/><span class="kq bw bk kr ks kt"/><span class="kq bw bk kr ks"/></div><div class="hm hn ho hp hq"><h1 id="0434" class="ku kv ht bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr dt translated"><strong class="ak"> 1。现有技术的问题</strong></h1><h2 id="8325" class="lx kv ht bd kw ly lz ma la mb mc md le jb me mf li jf mg mh lm jj mi mj lq mk dt translated">1.1.多级流水线</h2><p id="f481" class="pw-post-body-paragraph iq ir ht is b it ls iv iw ix lt iz ja jb ml jd je jf mm jh ji jj mn jl jm jn hm dt translated">R-CNN和SPPNet首先为softmax分类器训练CNN，然后使用特征向量训练包围盒回归器。因此，<strong class="is hu"> R-CNN和SPPNet不是端到端的训练。</strong></p><h2 id="f4cf" class="lx kv ht bd kw ly lz ma la mb mc md le jb me mf li jf mg mh lm jj mi mj lq mk dt translated">1.2.在空间和时间上都很昂贵</h2><p id="e430" class="pw-post-body-paragraph iq ir ht is b it ls iv iw ix lt iz ja jb ml jd je jf mm jh ji jj mn jl jm jn hm dt translated">由于<strong class="is hu">特征向量存储在硬盘中，占用了几百千兆字节</strong>，用于训练包围盒回归器。</p><h2 id="8d6e" class="lx kv ht bd kw ly lz ma la mb mc md le jb me mf li jf mg mh lm jj mi mj lq mk dt translated">1.3.慢速物体检测</h2><p id="91c5" class="pw-post-body-paragraph iq ir ht is b it ls iv iw ix lt iz ja jb ml jd je jf mm jh ji jj mn jl jm jn hm dt translated"><strong class="is hu">在测试时间，使用VGG-16的R-CNN需要使用GPU的每个图像47秒，这很慢。</strong></p><p id="3097" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">快速R-CNN解决了以上问题！</p></div><div class="ab cl kn ko hb kp" role="separator"><span class="kq bw bk kr ks kt"/><span class="kq bw bk kr ks kt"/><span class="kq bw bk kr ks"/></div><div class="hm hn ho hp hq"><h1 id="b180" class="ku kv ht bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr dt translated">2.<strong class="ak"> ROI汇集层</strong></h1><p id="1e7e" class="pw-post-body-paragraph iq ir ht is b it ls iv iw ix lt iz ja jb ml jd je jf mm jh ji jj mn jl jm jn hm dt translated">这其实是SPPNet中SPP层的一个特例<strong class="is hu">，只使用了一个金字塔</strong>。下面举例说明:</p><figure class="mp mq mr ms fq mt fe ff paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="fe ff mo"><img src="../Images/02f2f0c7ed42c12e557875b037a5417c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aB4gy6i8Zc3BasYaQGDVtg.png"/></div></div><figcaption class="na nb fg fe ff nc nd bd b be z ek"><strong class="bd ne">ROI Pooling</strong></figcaption></figure><p id="210a" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">首先，输入图像通过CNN进行特征提取。</p><p id="2c9d" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">区域建议通过基于非深度学习的选择性搜索(SS)方法获得，这与先前的R-CNN相同。</p><p id="e96b" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">每个区域方案产生自适应组合的RoI，即RoI组合。</p><p id="2679" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">假设我们得到了带有<em class="nf"> h </em> × <em class="nf"> w </em> 的<strong class="is hu">区域方案(左)，我们希望在合并后有一个H×W </strong>大小的<strong class="is hu">输出层输出(右)。然后，每个公摊区的<strong class="is hu">面积(中间)=<em class="nf">H</em>/<em class="nf">H</em>×<em class="nf">W</em>/<em class="nf">W</em></strong>。</strong></p><p id="a441" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">在上面的例子中，当<strong class="is hu">输入ROI为5×7 </strong>，而<strong class="is hu">输出为2×2 </strong>时，舍入后每个汇集区域的<strong class="is hu">面积为2×3或3×3 </strong>。</p><p id="ccab" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">并且池窗口内的最大值被作为每个网格的输出值，这与传统的最大池层的思想相同。</p></div><div class="ab cl kn ko hb kp" role="separator"><span class="kq bw bk kr ks kt"/><span class="kq bw bk kr ks kt"/><span class="kq bw bk kr ks"/></div><div class="hm hn ho hp hq"><h1 id="11e0" class="ku kv ht bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr dt translated"><strong class="ak"> 3。多任务损失</strong></h1><p id="c21d" class="pw-post-body-paragraph iq ir ht is b it ls iv iw ix lt iz ja jb ml jd je jf mm jh ji jj mn jl jm jn hm dt translated">由于快速R-CNN是端到端学习架构(除了区域提议生成部分)来学习对象的类别以及相关联的包围盒位置和大小，因此损失是多任务损失。</p><figure class="mp mq mr ms fq mt fe ff paragraph-image"><div class="fe ff ng"><img src="../Images/2d4a3046a88898cb6b8f35d35502029f.png" data-original-src="https://miro.medium.com/v2/resize:fit:880/format:webp/1*YzFseoGKhmDrqagVRJ5_qw.png"/></div><figcaption class="na nb fg fe ff nc nd bd b be z ek"><strong class="bd ne">Multi-task Loss</strong></figcaption></figure><p id="0032" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu"> <em class="nf"> L_cls </em>为真实类<em class="nf"> u </em>的对数损失。<br/> L_los是边界框的损失。<br/></strong>【u≥1】表示当u≥1时等于1。(u=0是背景类)</p><p id="7295" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu">与OverFeat、R-CNN、SPPNet相比，Fast R-CNN采用多任务丢失实现端到端学习。</strong></p><figure class="mp mq mr ms fq mt fe ff paragraph-image"><div class="fe ff nh"><img src="../Images/29d20b0c3f97745e41159fa004c5f14e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1096/format:webp/1*67iVyCzqapfB5Nyci_zynw.png"/></div><figcaption class="na nb fg fe ff nc nd bd b be z ek"><strong class="bd ne">Fast R-CNN</strong></figcaption></figure><p id="3279" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">对于多任务丢失，在输出端，我们有softmax和边界框回归量，如图右上方所示。</p><p id="7646" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">3款评测:<br/> <strong class="is hu"> S = AlexNet或CaffeNet <br/> M = VGG式的更宽版S <br/> L = VGG-16 </strong></p><figure class="mp mq mr ms fq mt fe ff paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="fe ff ni"><img src="../Images/e0bd681dbb7284bf877bdccaa5749e82.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*i0Fq3zitbotf8mZBURqe7w.png"/></div></div><figcaption class="na nb fg fe ff nc nd bd b be z ek"><strong class="bd ne">Multi-task Loss Results</strong></figcaption></figure><p id="a606" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu">在多任务丢失的情况下，与阶段式训练(即softmax和边界框回归器的单独训练)相比，获得了更高的mAP</strong>。</p></div><div class="ab cl kn ko hb kp" role="separator"><span class="kq bw bk kr ks kt"/><span class="kq bw bk kr ks kt"/><span class="kq bw bk kr ks"/></div><div class="hm hn ho hp hq"><h1 id="d23b" class="ku kv ht bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr dt translated">4.一些其他消融研究</h1><h2 id="f2b1" class="lx kv ht bd kw ly lz ma la mb mc md le jb me mf li jf mg mh lm jj mi mj lq mk dt translated">4.1多规模培训和测试</h2><p id="bd5b" class="pw-post-body-paragraph iq ir ht is b it ls iv iw ix lt iz ja jb ml jd je jf mm jh ji jj mn jl jm jn hm dt translated">使用5个标度测试输入图像。</p><figure class="mp mq mr ms fq mt fe ff paragraph-image"><div class="fe ff nj"><img src="../Images/06010031ef799daade12b62fb7fa79e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1110/format:webp/1*awn21lCgHv2hKImdlfXSpg.png"/></div><figcaption class="na nb fg fe ff nc nd bd b be z ek"><strong class="bd ne">1-Scale vs 5-Scale</strong></figcaption></figure><p id="39db" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu">使用5-scale，以较大的测试速率(秒/图像)为代价，为每个模型获得较高的mAP。</strong></p><h2 id="ba04" class="lx kv ht bd kw ly lz ma la mb mc md le jb me mf li jf mg mh lm jj mi mj lq mk dt translated">4.2 SVM vs Softmax</h2><figure class="mp mq mr ms fq mt fe ff paragraph-image"><div class="fe ff nk"><img src="../Images/4daa554976628af09ce127c13944e716.png" data-original-src="https://miro.medium.com/v2/resize:fit:1144/format:webp/1*5VLipfjGezKosdjTADi_wg.png"/></div><figcaption class="na nb fg fe ff nc nd bd b be z ek"><strong class="bd ne">SVM vs Softmax</strong></figcaption></figure><p id="1e7a" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">在快速R-CNN (FRCN)，<strong class="is hu"> softmax比SVM好。</strong></p><p id="fd51" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">此外，对于SVM，特征向量需要在硬盘中存储数百千兆字节，并成为阶段式训练，而softmax可以实现端到端的学习，而无需将特征向量存储到硬盘中。</p><h2 id="d4ee" class="lx kv ht bd kw ly lz ma la mb mc md le jb me mf li jf mg mh lm jj mi mj lq mk dt translated">4.3区域提案</h2><figure class="mp mq mr ms fq mt fe ff paragraph-image"><div class="fe ff nl"><img src="../Images/d38f5eb9ecb1b7b56994601f7b6a16fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1116/format:webp/1*66N_gcm4o7xAgeTb51HK0g.png"/></div><figcaption class="na nb fg fe ff nc nd bd b be z ek"><strong class="bd ne">Different Proposal Approaches</strong></figcaption></figure><p id="0531" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">发现<strong class="is hu">增加区域提案数量并不一定会增加mAP。</strong></p><p id="378d" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu">使用选择性搜索(SS) [5]的备用集已经足够好了如上图所示(蓝色实线)(</strong> SS [5]正在R-CNN中使用。)</p><p id="fa91" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">快速R-CNN需要来自外部源的区域提议仍然是个问题。</p><h2 id="9494" class="lx kv ht bd kw ly lz ma la mb mc md le jb me mf li jf mg mh lm jj mi mj lq mk dt translated">4.4截断奇异值分解，检测速度更快</h2><p id="b9b3" class="pw-post-body-paragraph iq ir ht is b it ls iv iw ix lt iz ja jb ml jd je jf mm jh ji jj mn jl jm jn hm dt translated">测试时间的瓶颈之一在FC层。</p><p id="71df" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu">作者使用奇异向量分解(SVD)来减少连接数目，以减少测试时间。</strong></p><p id="908c" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu">FC6层25088×4096矩阵的前1024个奇异值，</strong>和<strong class="is hu">FC7层4096×4096矩阵的前256个奇异值。</strong></p><figure class="mp mq mr ms fq mt fe ff paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="fe ff nm"><img src="../Images/3ce5cb867fcd22a4bc28cdec5a7279f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Pcx4x1nUkmF8jiszfO8_nA.png"/></div></div><figcaption class="na nb fg fe ff nc nd bd b be z ek"><strong class="bd ne">Large Reduction of Test Time for FC6 and FC7 Layers</strong></figcaption></figure></div><div class="ab cl kn ko hb kp" role="separator"><span class="kq bw bk kr ks kt"/><span class="kq bw bk kr ks kt"/><span class="kq bw bk kr ks"/></div><div class="hm hn ho hp hq"><h1 id="354a" class="ku kv ht bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr dt translated"><strong class="ak"> 5。与最先进结果的比较</strong></h1><h2 id="6f82" class="lx kv ht bd kw ly lz ma la mb mc md le jb me mf li jf mg mh lm jj mi mj lq mk dt translated">5.1 VOC 2007</h2><figure class="mp mq mr ms fq mt fe ff paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="fe ff nn"><img src="../Images/ff5b937bf778a07e49c1214e61386147.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t4kHGY-VPUKexDiLC5ObzA.png"/></div></div><figcaption class="na nb fg fe ff nc nd bd b be z ek"><strong class="bd ne">VOC 2007 Results</strong></figcaption></figure><p id="9d2b" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated"><strong class="is hu">快速R-CNN: 66.9% mAP <br/>快速R-CNN在训练过程中移除了困难示例(这是SPPNet的设置):68.1% mAP <br/>快速R-CNN带外部VOC 2012训练:70.0% mAP </strong></p><h2 id="c9fb" class="lx kv ht bd kw ly lz ma la mb mc md le jb me mf li jf mg mh lm jj mi mj lq mk dt translated">5.2 VOC 2010</h2><figure class="mp mq mr ms fq mt fe ff paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="fe ff no"><img src="../Images/c7013a7ec014f3b1f4421b901b52ef7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uH3kNBlBlLddtxB7zaVerQ.png"/></div></div><figcaption class="na nb fg fe ff nc nd bd b be z ek"><strong class="bd ne">VOC 2010 Results</strong></figcaption></figure><p id="d1e2" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">与VOC 2007相似，<strong class="is hu">用外部VOC 2007和2012训练的快速R-CNN最好，有68.8%的mAP。</strong></p><h2 id="5bab" class="lx kv ht bd kw ly lz ma la mb mc md le jb me mf li jf mg mh lm jj mi mj lq mk dt translated">5.3 VOC 2012</h2><figure class="mp mq mr ms fq mt fe ff paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="fe ff np"><img src="../Images/ce061367eac8b881158853a72798a17b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nEiW6axqzWZiXaVmokJF4w.png"/></div></div><figcaption class="na nb fg fe ff nc nd bd b be z ek"><strong class="bd ne">VOC 2012 Results</strong></figcaption></figure><p id="0033" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">与VOC 2007相似，<strong class="is hu">用外部VOC 2007训练的快速R-CNN最好，有68.4%的mAP。</strong></p><h2 id="0e20" class="lx kv ht bd kw ly lz ma la mb mc md le jb me mf li jf mg mh lm jj mi mj lq mk dt translated">5.4培训和测试时间</h2><figure class="mp mq mr ms fq mt fe ff paragraph-image"><div class="fe ff nq"><img src="../Images/201eaab77785e2c57bae94aed06ecd87.png" data-original-src="https://miro.medium.com/v2/resize:fit:1102/format:webp/1*boqOFsYjqYP2QJvLs2hA3w.png"/></div><figcaption class="na nb fg fe ff nc nd bd b be z ek"><strong class="bd ne">Training and Testing Time</strong></figcaption></figure><p id="9c6e" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">如前所述，<strong class="is hu">快速R-CNN训练非常深的VGG-16 [2]比R-CNN [3]快9倍，测试时快213倍。</strong></p><p id="3694" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hm dt translated">与SPPNet [4]相比，它训练VGG-16的速度快3倍，测试速度快10倍。</p></div><div class="ab cl kn ko hb kp" role="separator"><span class="kq bw bk kr ks kt"/><span class="kq bw bk kr ks kt"/><span class="kq bw bk kr ks"/></div><div class="hm hn ho hp hq"><h1 id="8194" class="ku kv ht bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr dt translated">参考</h1><ol class=""><li id="068c" class="jx jy ht is b it ls ix lt jb lu jf lv jj lw jn kc kd ke kf dt translated">【2015 ICCV】【快速R-CNN】<br/><a class="ae nr" href="https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Girshick_Fast_R-CNN_ICCV_2015_paper.pdf" rel="noopener ugc nofollow" target="_blank">快速R-CNN </a></li><li id="c8cf" class="jx jy ht is b it kg ix kh jb ki jf kj jj kk jn kc kd ke kf dt translated">【2015 ICLR】【VGGNet】<br/><a class="ae nr" href="https://arxiv.org/pdf/1409.1556" rel="noopener ugc nofollow" target="_blank">用于大规模图像识别的极深度卷积网络</a></li><li id="d9c3" class="jx jy ht is b it kg ix kh jb ki jf kj jj kk jn kc kd ke kf dt translated">【2014 CVPR】【R-CNN】<br/><a class="ae nr" href="https://arxiv.org/pdf/1311.2524" rel="noopener ugc nofollow" target="_blank">丰富的特征层次，用于精确的对象检测和语义分割</a></li><li id="fb29" class="jx jy ht is b it kg ix kh jb ki jf kj jj kk jn kc kd ke kf dt translated">【2014 ECCV】【SPPNet】<br/><a class="ae nr" href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.699.8052&amp;rep=rep1&amp;type=pdf" rel="noopener ugc nofollow" target="_blank">用于视觉识别的深度卷积网络中的空间金字塔池</a></li><li id="3628" class="jx jy ht is b it kg ix kh jb ki jf kj jj kk jn kc kd ke kf dt translated">【2013 IJCV】【选择性搜索】<br/> <a class="ae nr" href="http://www.huppelen.nl/publications/selectiveSearchDraft.pdf" rel="noopener ugc nofollow" target="_blank">选择性搜索对象识别</a></li></ol><h1 id="74fe" class="ku kv ht bd kw kx ns kz la lb nt ld le lf nu lh li lj nv ll lm ln nw lp lq lr dt translated">我的评论</h1><ol class=""><li id="2f59" class="jx jy ht is b it ls ix lt jb lu jf lv jj lw jn kc kd ke kf dt translated"><a class="ae nr" rel="noopener" href="/coinmonks/review-r-cnn-object-detection-b476aba290d1">回顾:R-CNN(物体检测)</a></li><li id="f69d" class="jx jy ht is b it kg ix kh jb ki jf kj jj kk jn kc kd ke kf dt translated"><a class="ae nr" rel="noopener" href="/coinmonks/paper-review-of-alexnet-caffenet-winner-in-ilsvrc-2012-image-classification-b93598314160">回顾AlexNet，CaffeNet——2012年ILSVRC(图像分类)获奖者</a></li><li id="5813" class="jx jy ht is b it kg ix kh jb ki jf kj jj kk jn kc kd ke kf dt translated"><a class="ae nr" rel="noopener" href="/coinmonks/review-sppnet-1st-runner-up-object-detection-2nd-runner-up-image-classification-in-ilsvrc-906da3753679">回顾:spp net—ils vrc 2014亚军(目标检测)、季军(图像分类)</a></li><li id="3f1d" class="jx jy ht is b it kg ix kh jb ki jf kj jj kk jn kc kd ke kf dt translated"><a class="ae nr" rel="noopener" href="/coinmonks/paper-review-of-vggnet-1st-runner-up-of-ilsvlc-2014-image-classification-d02355543a11">点评:VGGNet—ils vrc 2014亚军(图像分类)、冠军(本地化)</a></li><li id="a82c" class="jx jy ht is b it kg ix kh jb ki jf kj jj kk jn kc kd ke kf dt translated"><a class="ae nr" rel="noopener" href="/coinmonks/review-of-overfeat-winner-of-ilsvrc-2013-localization-task-object-detection-a6f8b9044754">回顾:over feat——ils vrc 2013定位任务(目标检测)冠军</a></li></ol><blockquote class="nx"><p id="11ae" class="ny nz ht bd oa ob oc od oe of og jn ek translated">加入Coinmonks <a class="ae nr" href="https://t.me/coincodecap" rel="noopener ugc nofollow" target="_blank">电报频道</a>和<a class="ae nr" href="https://www.youtube.com/c/coinmonks/videos" rel="noopener ugc nofollow" target="_blank"> Youtube频道</a>获取每日<a class="ae nr" href="http://coincodecap.com/" rel="noopener ugc nofollow" target="_blank">加密新闻</a></p></blockquote><h2 id="15d6" class="lx kv ht bd kw ly oh ma la mb oi md le jb oj mf li jf ok mh lm jj ol mj lq mk dt translated">另外，阅读</h2><ul class=""><li id="20fb" class="jx jy ht is b it ls ix lt jb lu jf lv jj lw jn om kd ke kf dt translated"><a class="ae nr" rel="noopener" href="/coinmonks/top-10-crypto-copy-trading-platforms-for-beginners-d0c37c7d698c">复制交易</a> | <a class="ae nr" rel="noopener" href="/coinmonks/crypto-tax-software-ed4b4810e338">加密税务软件</a></li><li id="723e" class="jx jy ht is b it kg ix kh jb ki jf kj jj kk jn om kd ke kf dt translated"><a class="ae nr" href="https://coincodecap.com/grid-trading" rel="noopener ugc nofollow" target="_blank">网格交易</a> | <a class="ae nr" rel="noopener" href="/coinmonks/the-best-cryptocurrency-hardware-wallets-of-2020-e28b1c124069">加密硬件钱包</a></li><li id="874f" class="jx jy ht is b it kg ix kh jb ki jf kj jj kk jn om kd ke kf dt translated"><a class="ae nr" href="http://Top 4 Telegram Channels for Crypto Traders" rel="noopener ugc nofollow" target="_blank">密码电报信号</a> | <a class="ae nr" rel="noopener" href="/coinmonks/crypto-trading-bot-c2ffce8acb2a">密码交易机器人</a></li><li id="f33b" class="jx jy ht is b it kg ix kh jb ki jf kj jj kk jn om kd ke kf dt translated"><a class="ae nr" rel="noopener" href="/coinmonks/crypto-exchange-dd2f9d6f3769">最佳加密交易所</a> | <a class="ae nr" rel="noopener" href="/coinmonks/bitcoin-exchange-in-india-7f1fe79715c9">印度最佳加密交易所</a></li><li id="47a8" class="jx jy ht is b it kg ix kh jb ki jf kj jj kk jn om kd ke kf dt translated">开发人员的最佳加密API</li><li id="b359" class="jx jy ht is b it kg ix kh jb ki jf kj jj kk jn om kd ke kf dt translated">最佳<a class="ae nr" rel="noopener" href="/coinmonks/top-5-crypto-lending-platforms-in-2020-that-you-need-to-know-a1b675cec3fa">密码借贷平台</a></li><li id="3c98" class="jx jy ht is b it kg ix kh jb ki jf kj jj kk jn om kd ke kf dt translated"><a class="ae nr" rel="noopener" href="/coinmonks/free-crypto-signals-48b25e61a8da">免费加密信号</a> | <a class="ae nr" rel="noopener" href="/coinmonks/crypto-trading-bot-c2ffce8acb2a">加密交易机器人</a></li><li id="9487" class="jx jy ht is b it kg ix kh jb ki jf kj jj kk jn om kd ke kf dt translated"><a class="ae nr" rel="noopener" href="/coinmonks/leveraged-token-3f5257808b22">杠杆代币</a>终极指南</li></ul></div></div>    
</body>
</html>