<html>
<head>
<title>Identity Verification with Deep Learning: ID-Selfie Matching Method</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于深度学习的身份验证:ID-自拍匹配方法</h1>
<blockquote>原文：<a href="https://medium.com/coinmonks/identity-verification-with-deep-learning-id-selfie-matching-method-be56d72be632?source=collection_archive---------2-----------------------#2018-09-24">https://medium.com/coinmonks/identity-verification-with-deep-learning-id-selfie-matching-method-be56d72be632?source=collection_archive---------2-----------------------#2018-09-24</a></blockquote><div><div class="ef hh hi hj hk hl"/><div class="hm hn ho hp hq"><div class=""/><figure class="fi fk ir is it iu fe ff paragraph-image"><div role="button" tabindex="0" class="iv iw di ix bf iy"><div class="fe ff iq"><img src="../Images/a0f9c914f8488bc3ae91e66105d0e44e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3YU0QHDcHnNa7deSH3N5hQ.png"/></div></div></figure><p id="182b" class="pw-post-body-paragraph jb jc ht jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">我们生活中大量的日常活动都需要<strong class="jd hu">身份验证</strong>。身份验证提供了一种安全机制，从系统的访问控制一直到过境和银行交易。然而，在许多需要身份验证的活动中，该过程是手动完成的，并且通常很慢，需要人工操作。</p><p id="1794" class="pw-post-body-paragraph jb jc ht jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">身份验证的自动化系统将大大加快这一过程，并在我们需要验证身份的所有活动中提供无缝的安全检查。最简单的方法之一是设计一个系统，将身份证照片与自拍照片进行匹配。</p><figure class="ka kb kc kd fq iu fe ff paragraph-image"><div role="button" tabindex="0" class="iv iw di ix bf iy"><div class="fe ff jz"><img src="../Images/0bbae60ab1e068bd33e50fa4c8eab77d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kEkO23rL1ItgeWpwEE8pug.png"/></div></div><figcaption class="ke kf fg fe ff kg kh bd b be z ek">Examples of automatic ID document photo matching systems at international borders</figcaption></figure><h1 id="ad69" class="ki kj ht bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf dt translated">以前的作品</h1><p id="f8cf" class="pw-post-body-paragraph jb jc ht jd b je lg jg jh ji lh jk jl jm li jo jp jq lj js jt ju lk jw jx jy hm dt translated">在过去，使用自动系统进行身份验证的尝试既有成功的，也有不成功的。一个成功的例子是澳大利亚的SmartGate。这是一个自动化的自助边境管制系统，由澳大利亚边防部队运作，位于澳大利亚八个国际机场入境大厅的移民检查站。它使用摄像头捕捉验证图片，并尝试将其与个人ID进行匹配。此外，中国已经在火车站和机场引入了这种系统。</p><p id="510a" class="pw-post-body-paragraph jb jc ht jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">虽然也有人试图使用传统的计算机视觉技术来匹配身份证件和自拍，但性能更好的方法依赖于深度学习。Zhu等人提出了第一个使用卷积神经网络进行文档自拍匹配的深度学习方法。</p><h1 id="7f0d" class="ki kj ht bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf dt translated">最先进的想法</h1><p id="6556" class="pw-post-body-paragraph jb jc ht jd b je lg jg jh ji lh jk jl jm li jo jp jq lj js jt ju lk jw jx jy hm dt translated"><strong class="jd hu">在他们的新论文中，来自密歇根州立大学</strong> <a class="ae ll" href="https://arxiv.org/pdf/1809.05620.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="jd hu">的研究人员提出了他们DocFace的改进版本——一种用于文档-自拍匹配的深度学习方法。</strong> </a></p><p id="7370" class="pw-post-body-paragraph jb jc ht jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">他们表明，当许多类只有非常少的样本时，基于梯度的优化方法收敛缓慢——就像现有的ID-selfie数据集的情况一样。为了克服这个缺点，他们提出了一种方法，叫做<strong class="jd hu">动态权重印迹(DWI) </strong>。此外，他们引入了一种新的识别系统，用于从ID-selfie对中学习统一的表示，以及一种名为<strong class="jd hu"> DocFace+ </strong>的开源人脸匹配器，用于ID-selfie匹配。</p><h1 id="9686" class="ki kj ht bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf dt translated">方法</h1><p id="6937" class="pw-post-body-paragraph jb jc ht jd b je lg jg jh ji lh jk jl jm li jo jp jq lj js jt ju lk jw jx jy hm dt translated">在构建用于ID-自拍匹配的自动化系统中存在大量的问题和限制。说起ID-自拍匹配，众多挑战不同于一般的人脸识别。</p><p id="49fe" class="pw-post-body-paragraph jb jc ht jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">两个主要挑战是由于压缩造成的文件(以及自拍)照片的低质量，以及文件发布时间和验证时间之间的巨大时间差。</p><p id="e716" class="pw-post-body-paragraph jb jc ht jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">整个方法基于迁移学习。在大规模人脸数据集<strong class="jd hu">(MS-celebe 1M)</strong>上训练基本神经网络模型，并将特征转移到身份自拍对的目标域。</p><figure class="ka kb kc kd fq iu fe ff paragraph-image"><div role="button" tabindex="0" class="iv iw di ix bf iy"><div class="fe ff lm"><img src="../Images/1d7c0a08ba01222def1f1ece826b5e78.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ysj9FxMiPfpWgpfY.png"/></div></div></figure><p id="83c8" class="pw-post-body-paragraph jb jc ht jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">研究人员认为，当处理样本很少的许多类时，收敛非常缓慢，训练经常会陷入局部极小值，因此他们建议使用<strong class="jd hu">加性边际Softmax (AM-Softmax) </strong>损失函数以及一种新的优化方法，他们称之为动态权重印迹(DWI)。</p><figure class="ka kb kc kd fq iu fe ff paragraph-image"><div class="fe ff ln"><img src="../Images/632211843f85f7bd5c2e6e7dfc8536aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1058/format:webp/0*mRYdxx-MjGPCd6bo.png"/></div><figcaption class="ke kf fg fe ff kg kh bd b be z ek">Generalization performance of different loss functions.</figcaption></figure><h1 id="4a11" class="ki kj ht bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf dt translated">动态重量压印</h1><p id="4864" class="pw-post-body-paragraph jb jc ht jd b je lg jg jh ji lh jk jl jm li jo jp jq lj js jt ju lk jw jx jy hm dt translated">由于随机梯度下降以小批量更新网络，在两次触发的情况下(像身份自拍匹配的情况)，每个权重向量在每个历元仅接收两次信号。这些稀疏的吸引信号对分类器权重几乎没有影响。为了克服这个问题，他们提出了一种新的优化方法，其思想是根据样本特征更新权重，从而避免分类器权重的不匹配，加快收敛速度。</p><p id="5b03" class="pw-post-body-paragraph jb jc ht jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">与随机梯度下降和其他基于梯度的优化方法相比，所提出的DWI算法仅基于真实样本更新权重。它只更新小批量中存在的类的权重，并且它在广泛的数据集上工作得很好，在这些数据集上，所有类的权重矩阵都太大而无法加载，并且只有权重的子集可以被采样用于训练。</p><figure class="ka kb kc kd fq iu fe ff paragraph-image"><div class="fe ff lo"><img src="../Images/07ba1ca3699e794484cc7cccea29c1fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:992/format:webp/0*Beme9a7RzJxDyyMi.png"/></div><figcaption class="ke kf fg fe ff kg kh bd b be z ek">Comparison of AM-Softmax loss and the proposed DIAM loss.</figcaption></figure><p id="f43a" class="pw-post-body-paragraph jb jc ht jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">研究人员使用随机梯度下降和AM-Softmax损失来训练流行的Face-ResNet架构。然后，他们通过将提出的动态重量印迹优化方法与附加边际Softmax相结合，在ID-自拍数据集上对模型进行微调。最后，训练一对兄弟网络学习共享高级参数的身份识别和自拍的特定领域特征。</p><figure class="ka kb kc kd fq iu fe ff paragraph-image"><div class="fe ff lp"><img src="../Images/524aa02b470cf61d76d89fb9f08848d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1046/format:webp/0*r87wh3BsbV8df8Wx.png"/></div><figcaption class="ke kf fg fe ff kg kh bd b be z ek">Workflow of the proposed method. A base model is trained on a large scale unconstrained face dataset. Then, the parameters are transferred to a pair of sibling networks, who have shared high-level modules.</figcaption></figure><h1 id="36fa" class="ki kj ht bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf dt translated">结果</h1><p id="7b83" class="pw-post-body-paragraph jb jc ht jd b je lg jg jh ji lh jk jl jm li jo jp jq lj js jt ju lk jw jx jy hm dt translated">提出的身份-自拍匹配方法取得了良好的效果，真实接受率达到97.51±0.40%。作者报告称，他们使用MS-celebe-1M数据集和AM-Softmax损失函数的方法在LFW标准验证方案下达到99.67%的准确度，在BLUFR方案下达到99.60%的验证率(VR)和0.1%的错误接受率(FAR)。</p><figure class="ka kb kc kd fq iu fe ff paragraph-image"><div role="button" tabindex="0" class="iv iw di ix bf iy"><div class="fe ff lq"><img src="../Images/fd167f8502858454e0fe0663c8966260.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*hza9mNyd7DLkjW5S.png"/></div></div></figure><figure class="ka kb kc kd fq iu fe ff paragraph-image"><div role="button" tabindex="0" class="iv iw di ix bf iy"><div class="fe ff lq"><img src="../Images/0d45211ea64f0acec4477730ff487a3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*pE9bTZU-eMbIOAHm.png"/></div></div><figcaption class="ke kf fg fe ff kg kh bd b be z ek">Examples of falsely classified images by our model on the Private ID-selfie dataset.</figcaption></figure><figure class="ka kb kc kd fq iu fe ff paragraph-image"><div class="fe ff lr"><img src="../Images/71dbc8e544d0b5bb2246dd48d3f33d27.png" data-original-src="https://miro.medium.com/v2/resize:fit:1140/format:webp/0*pDob8UK9jH3ZZQIg.png"/></div><figcaption class="ke kf fg fe ff kg kh bd b be z ek">The mean performance of constraining different modules of the sibling networks to be shared</figcaption></figure><figure class="ka kb kc kd fq iu fe ff paragraph-image"><div class="fe ff lr"><img src="../Images/7c2fd1af20fa3d633144986c77537969.png" data-original-src="https://miro.medium.com/v2/resize:fit:1140/format:webp/0*25wSLpoxkEnYFQ-c.png"/></div><figcaption class="ke kf fg fe ff kg kh bd b be z ek">Comparing Static and Dynamic Weight Imprinting regarding TAR</figcaption></figure><h1 id="d0b7" class="ki kj ht bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf dt translated">与其他最先进技术的比较</h1><p id="d021" class="pw-post-body-paragraph jb jc ht jd b je lg jg jh ji lh jk jl jm li jo jp jq lj js jt ju lk jw jx jy hm dt translated">该方法与其他最先进的普通人脸匹配方法进行了比较，因为没有现有的公共身份自拍匹配方法。给出了与这些方法在TAR(真实接受率)和FAR(错误接受率)方面的比较，如下表所示。</p><figure class="ka kb kc kd fq iu fe ff paragraph-image"><div class="fe ff lr"><img src="../Images/79baf825361db4d77a34a145c563b0e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1140/format:webp/0*W5q6oQcX_ik-vdzT.png"/></div><figcaption class="ke kf fg fe ff kg kh bd b be z ek">The mean (and s.d. of) performance of different matches on the private ID-selfie dataset</figcaption></figure><figure class="ka kb kc kd fq iu fe ff paragraph-image"><div class="fe ff lr"><img src="../Images/8f3b4d60ebaf3cf63ef98e80fb2406e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1140/format:webp/0*38F35rdbPC2nEFoq.png"/></div><figcaption class="ke kf fg fe ff kg kh bd b be z ek">Evaluation results were compared with other methods on Public-IvS dataset</figcaption></figure><h1 id="1fec" class="ki kj ht bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf dt translated">结论</h1><p id="abbc" class="pw-post-body-paragraph jb jc ht jd b je lg jg jh ji lh jk jl jm li jo jp jq lj js jt ju lk jw jx jy hm dt translated">提出的用于ID-selfie匹配的DocFace+方法显示了迁移学习的潜力，特别是在没有足够数据可用的任务中。所提出的方法在自拍与身份匹配中实现了高准确度，并且具有在身份验证系统中使用的潜力。此外，提出的新的优化方法——动态权重印记法显示了改进的收敛性和更好的泛化性能，代表了对机器学习领域的重大贡献。</p><blockquote class="ls"><p id="8c3d" class="lt lu ht bd lv lw lx ly lz ma mb jy ek translated"><a class="ae ll" href="https://coincodecap.com/?utm_source=coinmonks" rel="noopener ugc nofollow" target="_blank">在您的收件箱中直接获得最佳软件交易</a></p></blockquote><figure class="md me mf mg mh iu fe ff paragraph-image"><a href="https://coincodecap.com/?utm_source=coinmonks"><div class="fe ff mc"><img src="../Images/7c0b3dfdcbfea594cc0ae7d4f9bf6fcb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1168/format:webp/0*OJ-qb5G6i863msBB.png"/></div></a></figure></div><div class="ab cl mi mj hb mk" role="separator"><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn"/></div><div class="hm hn ho hp hq"><p id="ea15" class="pw-post-body-paragraph jb jc ht jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated"><em class="mp">原载于2018年9月24日</em><a class="ae ll" href="https://neurohive.io/en/state-of-the-art/identity-verification-with-deep-learning-id-selfie-matching-method/" rel="noopener ugc nofollow" target="_blank"><em class="mp">neuro hive . io</em></a><em class="mp">。</em></p></div></div>    
</body>
</html>