<html>
<head>
<title>Loss Optimization in Scientific Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">科学Python中的损失优化</h1>
<blockquote>原文：<a href="https://medium.com/coinmonks/loss-optimization-in-scientific-python-d1efbbe87171?source=collection_archive---------3-----------------------#2018-07-08">https://medium.com/coinmonks/loss-optimization-in-scientific-python-d1efbbe87171?source=collection_archive---------3-----------------------#2018-07-08</a></blockquote><div><div class="ef hh hi hj hk hl"/><div class="hm hn ho hp hq"><div class=""/><figure class="fi fk ir is it iu fe ff paragraph-image"><div role="button" tabindex="0" class="iv iw di ix bf iy"><div class="fe ff iq"><img src="../Images/acfdca122622f108c6f56a07e1ced431.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t4aYsxpCqz2eymJ4zkUS9Q.png"/></div></div><figcaption class="jb jc fg fe ff jd je bd b be z ek">Visualizing loss defined by two parameters</figcaption></figure><p id="3e9d" class="pw-post-body-paragraph jf jg ht jh b ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc hm dt translated">为了找到优化的参数而对数据进行训练的过程在机器学习中是经常发生的。当你使用像MRSE这样的标准损失函数时，很容易找到标准包来训练你的模型。然而，当实现(或编写)新算法时，您可能必须自己处理自己的损失函数。</p><p id="f962" class="pw-post-body-paragraph jf jg ht jh b ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc hm dt translated">Scientific Python在<em class="kd"> scipy.optimize </em>包中提供了许多优化例程。在本文中，我们将实现其中的两个例程。我们将利用Kaggle提供的波士顿住房预测数据。你可以在这里买到<a class="ae ke" href="https://www.kaggle.com/c/boston-housing" rel="noopener ugc nofollow" target="_blank">。让我们从导入所需的包开始。</a></p><pre class="kf kg kh ki fq kj kk kl km aw kn dt"><span id="ada9" class="ko kp ht kk b fv kq kr l ks kt">import pandas as pd<br/>import numpy as np<br/>from scipy.optimize import fmin, minimize</span></pre><p id="eb8a" class="pw-post-body-paragraph jf jg ht jh b ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc hm dt translated">让我们获取、加载和提取我们的numpy数组。</p><pre class="kf kg kh ki fq kj kk kl km aw kn dt"><span id="4863" class="ko kp ht kk b fv kq kr l ks kt">train_df = pd.read_csv('./train.csv', index_col='ID')</span><span id="29ef" class="ko kp ht kk b fv ku kr l ks kt">y = train_df['medv'].values<br/>y = y.reshape(-1, 1)</span><span id="6c5e" class="ko kp ht kk b fv ku kr l ks kt">train_df['constant'] = 1<br/>columns = ['constant', 'crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax', 'ptratio', 'black', 'lstat']<br/>x = train_df[columns].values</span></pre><p id="4066" class="pw-post-body-paragraph jf jg ht jh b ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc hm dt translated">我们将实现简单的线性回归<em class="kd"> y = w.x </em>，所以让我们实例化一个初始值为0的数组<em class="kd"> w </em>。我们需要关注我们的维度，所以我们的维度没有静态值。</p><pre class="kf kg kh ki fq kj kk kl km aw kn dt"><span id="3b00" class="ko kp ht kk b fv kq kr l ks kt">w = np.zeros([x.shape[1], 1])</span></pre><p id="c2a1" class="pw-post-body-paragraph jf jg ht jh b ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc hm dt translated">接下来，让我们创建我们的线性回归函数。</p><pre class="kf kg kh ki fq kj kk kl km aw kn dt"><span id="3ed6" class="ko kp ht kk b fv kq kr l ks kt">def pred(x, w):<br/>    return np.dot(x, w)</span></pre><p id="140f" class="pw-post-body-paragraph jf jg ht jh b ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc hm dt translated">然后我们可以通过调用这个函数进行预测。</p><pre class="kf kg kh ki fq kj kk kl km aw kn dt"><span id="9653" class="ko kp ht kk b fv kq kr l ks kt">y_pred = pred(x, w)</span></pre><p id="2087" class="pw-post-body-paragraph jf jg ht jh b ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc hm dt translated">为了训练我们的模型并优化w，我们需要一个损失函数。接下来我们来定义一下。</p><pre class="kf kg kh ki fq kj kk kl km aw kn dt"><span id="8466" class="ko kp ht kk b fv kq kr l ks kt">def loss(_w):<br/>    p = pred(x, _w)<br/>    e = y - p<br/>    se = np.power(e, 2)<br/>    rse = np.sqrt(np.sum(se))<br/>    rmse = rse / y.shape[0]<br/>    return rmse</span></pre><h1 id="932b" class="kv kp ht bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr dt translated">fmin</h1><p id="0c46" class="pw-post-body-paragraph jf jg ht jh b ji ls jk jl jm lt jo jp jq lu js jt ju lv jw jx jy lw ka kb kc hm dt translated">我们将使用的第一个优化例程是fmin。这使用了Nelder-Mead单纯形算法来寻找我们的函数的最小值。它不要求我们的函数是可微的。然而，它不能很好地推广到高维数据。让我们使用这个。我们需要指定迭代的次数，这样这个算法才能找到好的值。如果没有它，数据的默认步骤数可能会提供</p><pre class="kf kg kh ki fq kj kk kl km aw kn dt"><span id="e297" class="ko kp ht kk b fv kq kr l ks kt">min = fmin(loss, w, maxiter=1000)</span></pre><p id="729f" class="pw-post-body-paragraph jf jg ht jh b ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc hm dt translated">函数调用返回<em class="kd"> w </em>的优化值。然后，当<em class="kd"> w </em>全为0时，我们可以继续比较我们的新预测值与我们的初始预测值，以及我们的基本事实。</p><pre class="kf kg kh ki fq kj kk kl km aw kn dt"><span id="abd3" class="ko kp ht kk b fv kq kr l ks kt">y_min = pred(x, min)<br/>out = pd.DataFrame({'y': y[:,0], 'y_pred': y_pred[:,0], 'y_min': pred(x, min)})<br/>out.head(n=15)</span></pre><h1 id="8090" class="kv kp ht bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr dt translated">最小化</h1><p id="fc71" class="pw-post-body-paragraph jf jg ht jh b ji ls jk jl jm lt jo jp jq lu js jt ju lv jw jx jy lw ka kb kc hm dt translated">当处理高维数据，或者一阶或二阶导数的损失函数时，我们可以利用<em class="kd"> minimize() </em>。它是很多东西，所以最好是小心翼翼，循序渐进地接近它。</p><p id="0d60" class="pw-post-body-paragraph jf jg ht jh b ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc hm dt translated">让我们从实现与<em class="kd"> fmin() </em>相同的解决方案开始。</p><pre class="kf kg kh ki fq kj kk kl km aw kn dt"><span id="868e" class="ko kp ht kk b fv kq kr l ks kt">nms = minimize(loss, w, method='nelder-mead')</span></pre><p id="62ac" class="pw-post-body-paragraph jf jg ht jh b ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc hm dt translated">你可能注意到的第一件事是我们现在有了一个<em class="kd">方法</em>参数。为了复制<em class="kd"> fmin() </em>，我们指定<em class="kd">‘内尔德-米德’</em>。其次，我们现在在调用<em class="kd"> minimize() </em>的结果中有了更多的数据。在这种情况下，我们对参数<em class="kd"> x </em>感兴趣。让我们来做一个预测。</p><pre class="kf kg kh ki fq kj kk kl km aw kn dt"><span id="70b4" class="ko kp ht kk b fv kq kr l ks kt">out_2 = pd.DataFrame({'y': y[:,0], 'y_pred': y_pred[:,0], 'y_min': pred(x, nms.x)})<br/>out_2.head()</span></pre><p id="bfb0" class="pw-post-body-paragraph jf jg ht jh b ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc hm dt translated">可以定义另一个函数，它是我们损失的导数，然后在调用中使用它来最小化()。我们将把它留给另一篇文章。</p><p id="4328" class="pw-post-body-paragraph jf jg ht jh b ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc hm dt translated">现在，我们在下面的要点中有上述所有代码。</p><figure class="kf kg kh ki fq iu"><div class="bz el l di"><div class="lx ly l"/></div></figure><p id="9472" class="pw-post-body-paragraph jf jg ht jh b ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc hm dt translated">下次见。</p></div></div>    
</body>
</html>