<html>
<head>
<title>Diving into TensorBoard</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">潜入冲浪板</h1>
<blockquote>原文：<a href="https://medium.com/coinmonks/diving-into-tensorboard-c68523418738?source=collection_archive---------0-----------------------#2020-10-12">https://medium.com/coinmonks/diving-into-tensorboard-c68523418738?source=collection_archive---------0-----------------------#2020-10-12</a></blockquote><div><div class="ef hh hi hj hk hl"/><div class="hm hn ho hp hq"><div class=""/><figure class="fi fk ir is it iu fe ff paragraph-image"><div role="button" tabindex="0" class="iv iw di ix bf iy"><div class="fe ff iq"><img src="../Images/defebde7318e73b91f9bf9251115f6bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Fa0-xrkmsQ89QvFI.png"/></div></div></figure><p id="c15b" class="pw-post-body-paragraph jb jc ht jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">TensorFlow是最受欢迎的深度学习框架，随着Tensorflow 2.0的发布，Keras已被集成到Tensorflow生态系统中。这大大提高了Tensorflow的易用性。Tensorflow为深度学习提供了许多令人惊叹的功能和库。Tensorboard是Tensorflow提供的惊人功能之一。根据tensorflow.org:</p><p id="d79a" class="pw-post-body-paragraph jb jc ht jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">Tensorboard是一个分析、可视化、调试训练的神奇工具。Tensorboard是Tensorflow的一部分，但也可以单独安装。</p><p id="f412" class="pw-post-body-paragraph jb jc ht jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">我们的Tensorflow之旅概述如下:</p><ol class=""><li id="2239" class="jz ka ht jd b je jf ji jj jm kb jq kc ju kd jy ke kf kg kh dt translated">Tensorboard入门</li><li id="d77a" class="jz ka ht jd b je ki ji kj jm kk jq kl ju km jy ke kf kg kh dt translated">分析标量和度量</li><li id="01a8" class="jz ka ht jd b je ki ji kj jm kk jq kl ju km jy ke kf kg kh dt translated">绘制图像数据</li><li id="7d05" class="jz ka ht jd b je ki ji kj jm kk jq kl ju km jy ke kf kg kh dt translated">分析图形模型</li><li id="f3dd" class="jz ka ht jd b je ki ji kj jm kk jq kl ju km jy ke kf kg kh dt translated">超参数调谐</li></ol><p id="b113" class="pw-post-body-paragraph jb jc ht jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated"><strong class="jd hu"> 1。</strong><strong class="jd hu">Tensorboard入门</strong> TensorBoad在模型训练时使用回调。要在训练中使用Tensorboard，您需要在model.fit函数中包含Tensorboard回调。</p><pre class="kn ko kp kq fq kr ks kt ku aw kv dt"><span id="c780" class="kw kx ht ks b fv ky kz l la lb">log_dir = "logs"<br/>tensorboard_callback = tf.keras.callbacks.Tensorboard(logdir)<br/>model = tf.keras.Sequential([###YOUR MODEL###])<br/>model.compile()<br/>model.fit(x,y, callbacks=[tensorboard_callback])</span></pre><p id="7461" class="pw-post-body-paragraph jb jc ht jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">此后，将为<code class="eh lc ld le ks b">log_dir</code>中的培训生成日志。您可以从Jupyter笔记本或命令行启动Tensorbaord。要在Jupyter笔记本中使用它，请在新的单元格中使用下面的代码，您将在单元格输出中看到Tensorboard。</p><pre class="kn ko kp kq fq kr ks kt ku aw kv dt"><span id="34ae" class="kw kx ht ks b fv ky kz l la lb">%load_ext tensorboard<br/>%tensorboard –logdir log_dir</span></pre><p id="71d1" class="pw-post-body-paragraph jb jc ht jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">使用下面的命令在命令行中运行Tensorboard，然后打开<a class="ae lf" href="http://localhost:6006/" rel="noopener ugc nofollow" target="_blank"> http://localhost:6006/ </a>查看Tensorboard。</p><pre class="kn ko kp kq fq kr ks kt ku aw kv dt"><span id="e17c" class="kw kx ht ks b fv ky kz l la lb">tensorboard –logdir logs/</span></pre><p id="db9b" class="pw-post-body-paragraph jb jc ht jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">运行以上命令后，您将能够看到如下的张量板:</p><figure class="kn ko kp kq fq iu fe ff paragraph-image"><div role="button" tabindex="0" class="iv iw di ix bf iy"><div class="fe ff lg"><img src="../Images/1d9dd0f47fff74eea3a052971e424da0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*gpo8_t3PVvr28kto.png"/></div></div></figure><p id="cf41" class="pw-post-body-paragraph jb jc ht jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">您可以看到训练和验证数据集的准确性和损失。接下来，假设你想比较两个型号的性能。然后，您可以在不同的目录中为它们记录日志。例如，我们将训练两个模型来进行猫和狗的分类，一个是定制模型，另一个是迁移学习模型(我知道这是一个不公平的比较😊).</p><figure class="kn ko kp kq fq iu fe ff paragraph-image"><div class="fe ff lh"><img src="../Images/bdd5d285a8c02757112b39d24cf7471c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/0*DH8FIDpigP4rIwVO.png"/></div></figure><p id="c3bf" class="pw-post-body-paragraph jb jc ht jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">正如你所看到的，在Tensorboard的帮助下，比较不同模型的性能变得更加容易，这有助于快速分析实验结果。例如，如果我们只想查看训练结果，我们可以从左侧窗格中仅选择相关的跑步。</p><figure class="kn ko kp kq fq iu fe ff paragraph-image"><div class="fe ff lh"><img src="../Images/915b234e5d11e2ea0551f36d71abf581.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/0*szZDMsbgT1OSUhds.png"/></div></figure><p id="0f9f" class="pw-post-body-paragraph jb jc ht jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated"><strong class="jd hu"> 2。分析标量和度量</strong>如上图所示，Tensorboard默认绘制度量。如果您想添加任何其他指标或参数，您也可以这样做。要记录自定义值，您需要使用摘要编写器来编写日志。首先，定义一个摘要作者。</p><pre class="kn ko kp kq fq kr ks kt ku aw kv dt"><span id="c276" class="kw kx ht ks b fv ky kz l la lb">file_writer = tf.summary.create_file_writer(logdir + "/metrics")</span></pre><p id="8de5" class="pw-post-body-paragraph jb jc ht jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">执行此操作后，logdir目录下将有一个名为metrics的新目录。为了记录，value调用调用下面的代码。</p><pre class="kn ko kp kq fq kr ks kt ku aw kv dt"><span id="fcd6" class="kw kx ht ks b fv ky kz l la lb">with file_writer.as_default():<br/>   tf.summary.scalar(name_of_the_scalar, data=value_to_log, step=epoch)</span></pre><p id="547c" class="pw-post-body-paragraph jb jc ht jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">要记录该值，您需要一个在on_epoch_end触发的回调，否则只会记录一个值。在那里，您需要使用<code class="eh lc ld le ks b">tf.summary.scalar</code>进行日志记录。对于这个例子，我们将使用<code class="eh lc ld le ks b">LearningRateScheduler</code>。首先，我们需要定义函数来改变基于时期的学习率。这可以使用下面的函数来完成:</p><pre class="kn ko kp kq fq kr ks kt ku aw kv dt"><span id="cd12" class="kw kx ht ks b fv ky kz l la lb">def learning_rate_schedule(epoch):<br/>    learning_rate = 0.001<br/>    <br/>    if epoch &gt; 1:<br/>     learning_rate = 0.002<br/>    if epoch &gt; 2:<br/>     learning_rate = 0.002+epoch*0.001<br/>        <br/>    with file_writer.as_default():<br/>     tf.summary.scalar('Learning Rate', data=learning_rate, step=epoch)<br/>    return learning_rate</span></pre><p id="831c" class="pw-post-body-paragraph jb jc ht jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">然后将这个回调添加到<code class="eh lc ld le ks b">model.fit</code>中的回调列表中。模型开始训练后，您将能够在Scalars选项卡下监视一个新图形。</p><figure class="kn ko kp kq fq iu fe ff paragraph-image"><div class="fe ff lh"><img src="../Images/b0c4934422b7727a1ceab225d0e637bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/0*odxeIg9c9a5s_WxW.png"/></div></figure><p id="e590" class="pw-post-body-paragraph jb jc ht jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">如果您想要监视一个指标，那么您可以使用下面的语法将文件编写器设置为默认。</p><pre class="kn ko kp kq fq kr ks kt ku aw kv dt"><span id="2fc1" class="kw kx ht ks b fv ky kz l la lb">file_writer.set_as_default()</span></pre><p id="8bf3" class="pw-post-body-paragraph jb jc ht jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated"><strong class="jd hu"> 3。绘制图像数据:</strong>在训练深度学习模型时，最好与AUC曲线、混淆度量等其他度量一起监控训练进度。这些指标可以在Tensorboard中绘制成图像，并可以跨时期进行监控。您也可以使用模型的输入或输出图像。要在张量板上绘制图像，您需要调用<code class="eh lc ld le ks b">tf.sumary.image</code>函数。</p><pre class="kn ko kp kq fq kr ks kt ku aw kv dt"><span id="6396" class="kw kx ht ks b fv ky kz l la lb">tf.summary.image("Image data", image, step=EPOCH)</span></pre><p id="133c" class="pw-post-body-paragraph jb jc ht jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">在图像是张量格式的情况下，您可以将图像作为参数传递，它将被绘制出来。在图像不是张量格式的情况下，在绘图之前需要转换成张量格式。对于这个例子，我们将绘制张量板图像中隐藏卷积层的输出。为此，首先我们将创建一个卷积层输出的网格。为此，我们将使用以下方法:</p><pre class="kn ko kp kq fq kr ks kt ku aw kv dt"><span id="14ed" class="kw kx ht ks b fv ky kz l la lb">def getFeatureMap():<br/> earlyPredictor = tf.keras.Model(model.inputs,model.get_layer(index=6).output)<br/>    feature_maps = earlyPredictor.predict(img)[0]<br/>    square = 8<br/>    ix = 1<br/>    figure = plt.figure(figsize=(12,12))<br/>    for _ in range(square):<br/>     for _ in range(square):<br/>         ax = plt.subplot(square, square, ix)<br/>            ax.set_xticks([])<br/>            ax.set_yticks([])<br/>            plt.imshow(feature_maps[:, :, ix-1], cmap='gray')<br/>            ix += 1<br/>    return figure<br/>    <br/>def plot_to_image(figure):<br/> buf = io.BytesIO()plt.savefig(buf, format='png')<br/>    plt.close(figure)buf.seek(0)<br/>    image = tf.image.decode_png(buf.getvalue(), channels=4)<br/>    image = tf.expand_dims(image, 0)<br/>    return image</span></pre><p id="5d11" class="pw-post-body-paragraph jb jc ht jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">正如在Tensorboard中记录标量值一样，为了记录图像，我们需要一个回调函数来记录每个时期的图像(如果您需要时期级别)。所以我们将在<code class="eh lc ld le ks b">LearningRateScheduler</code>回调期间调用这个。为此，我们首先需要使用<code class="eh lc ld le ks b">getFeatureMap</code>函数获得数字。然后，我们使用<code class="eh lc ld le ks b">plot_to_image</code>将数字转换成张量，并使用<code class="eh lc ld le ks b">tf.summary.image</code>将其写入日志。</p><pre class="kn ko kp kq fq kr ks kt ku aw kv dt"><span id="2471" class="kw kx ht ks b fv ky kz l la lb">figure = getFeatureMap()<br/>with file_writer_image.as_default():<br/>    tf.summary.image("Feature Map", plot_to_image(figure), step=epoch)</span></pre><p id="764c" class="pw-post-body-paragraph jb jc ht jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">训练完成后，您将获得所有时期的输出。您可以使用滑块来查看不同时期的输出。</p><figure class="kn ko kp kq fq iu fe ff paragraph-image"><div class="fe ff lh"><img src="../Images/91e7f542850b1de43b87daa034598426.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/0*2fhKyFvenOaJUf69.png"/></div></figure><p id="2cfb" class="pw-post-body-paragraph jb jc ht jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated"><strong class="jd hu"> 4分析图模型:</strong> Tensorflow使用图模型对模型进行优化。随着Tensorflow 2.0的到来，我们可以使用Keras来定义层，Tensorflow在幕后处理它。Tensorflow为定义的模型创建一个图表来优化训练。</p><figure class="kn ko kp kq fq iu fe ff paragraph-image"><div class="fe ff lh"><img src="../Images/a0986e51104047238e547da229469360.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/0*zQpeGlM3Li9FMyl0.png"/></div></figure><p id="d0f4" class="pw-post-body-paragraph jb jc ht jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">创建模型时会生成图形，如果使用Tensorboard回调，您可以在图形选项卡下看到模型中的所有层。如果你想专注于一层，那么你需要双击它。我们来分析一个卷积层。</p><figure class="kn ko kp kq fq iu fe ff paragraph-image"><div role="button" tabindex="0" class="iv iw di ix bf iy"><div class="fe ff lh"><img src="../Images/5fbd3a138960b15d5e196aa0270706b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/0*vcSnN87fFswk4Ykm.png"/></div></div></figure><p id="babf" class="pw-post-body-paragraph jb jc ht jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">正如你看到的双击任何卷积层，有Conv2D层，其次是Bias和Relu。箭头表示流量，箭头的数量是输出/输入维度。在右上角，您可以看到图层名称以及带有输入/输出维度的输入-输出图层名称。如果你观察辍学层，你会发现一些有趣的事情。如你所知，在训练过程中，Dropout层会随机丢弃一定数量的神经元，但是在推理过程中，该层不会丢弃任何东西。这个模型是如何处理的？这可以从图表中看出:</p><figure class="kn ko kp kq fq iu fe ff paragraph-image"><div class="fe ff lh"><img src="../Images/849ef8fe2a699b9f17e89f57d34e7892.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/0*jh72kZzX-VqKttEA.png"/></div></figure><p id="8bc5" class="pw-post-body-paragraph jb jc ht jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">如果你看到有一个<code class="eh lc ld le ks b">keras_lerning_phase</code>接受一个标量输入，输出进入每个漏失层。学习阶段的输入是指示它是否是学习阶段的布尔值。这样，压差值可以从指定值变为0。</p><figure class="kn ko kp kq fq iu fe ff paragraph-image"><div class="fe ff li"><img src="../Images/8212d14193388578636b3de745e3a2d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:734/format:webp/0*fC8fRG60MNaQgS_g.png"/></div></figure><p id="db03" class="pw-post-body-paragraph jb jc ht jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated"><strong class="jd hu"> 5。超参数调优:</strong>训练深度学习网络实验。这些实验可以从数据扩充到超参数调整。Tensorboard提供了一种在HParams仪表板中跟踪这些超参数实验的方法。要使用HParams仪表板，只需在模型定义中做一些更改。首先，导入HParams API并定义想要优化的超参数。要定义Hparams，请使用以下语法:</p><pre class="kn ko kp kq fq kr ks kt ku aw kv dt"><span id="51dc" class="kw kx ht ks b fv ky kz l la lb">hp.HParam(name, domain=None, display_name=None, description=None)</span></pre><p id="2a68" class="pw-post-body-paragraph jb jc ht jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated"><code class="eh lc ld le ks b">Name</code>:参数<br/> <code class="eh lc ld le ks b">domain</code>的名称:取值，可以是离散的(hp.discrete)、整数区间(<code class="eh lc ld le ks b">hp.IntInterval(min_value=None, max_value=None)</code>)或实数区间(<code class="eh lc ld le ks b">hp.RealInterval(min_value=None, max_value=None)</code> ) <br/> <code class="eh lc ld le ks b">display_name</code>:要在张量板上显示的名称<br/> <code class="eh lc ld le ks b">description</code>:参数说明</p><p id="e4d3" class="pw-post-body-paragraph jb jc ht jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">让我们定义几个我们想要调整的参数。</p><pre class="kn ko kp kq fq kr ks kt ku aw kv dt"><span id="196b" class="kw kx ht ks b fv ky kz l la lb">import tensorboard.plugins.hparams.api as hp<br/>HP_Filters_layer_1 = hp.HParam('num_filters_layer_1', hp.Discrete([16, 32]))<br/>HP_Filters_layer_2 = hp.HParam('num_filters_layer_2', hp.Discrete([32, 64]))<br/>HP_Kernel = hp.HParam('kernel_size', hp.Discrete([3, 5]))<br/>HP_Optimizer = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd']))</span></pre><p id="1383" class="pw-post-body-paragraph jb jc ht jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">然后，我们需要定义文件写入器，并使用以下代码定义HParam板的配置:</p><pre class="kn ko kp kq fq kr ks kt ku aw kv dt"><span id="77a2" class="kw kx ht ks b fv ky kz l la lb">with tf.summary.create_file_writer('logs/hparam_tuning').as_default():<br/> hp.hparams_config(<br/>     hparams=[HP_Filters_layer_1, HP_Filters_layer_2, HP_Kernel, HP_Optimizer],<br/>        metrics=[hp.Metric('accuracy', display_name='Accuracy')])</span></pre><p id="e97e" class="pw-post-body-paragraph jb jc ht jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">这样，我们就为HParam仪表板编写了高级信息。接下来是定义模型。为了定义模型，我们创建了一个接受超参数和运行名的函数。</p><pre class="kn ko kp kq fq kr ks kt ku aw kv dt"><span id="8fbb" class="kw kx ht ks b fv ky kz l la lb">def configurableModel(dir, hparams, name):<br/>    model = tf.keras.Sequential([<br/>     tf.keras.layers.InputLayer(input_shape=imgsize+(3,)),<br/>        tf.keras.layers.Conv2D(hparams[HP_Filters_layer_1], (hparams[HP_Kernel],hparams[HP_Kernel]), activation='relu'),<br/>        tf.keras.layers.MaxPool2D(),<br/>        #Rest of the layers])</span></pre><p id="2004" class="pw-post-body-paragraph jb jc ht jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">正如您在Conv2D层中看到的，我们传递的不是滤波器数量，而是<code class="eh lc ld le ks b">hparams[HP_Filters_layer_1]</code>。这需要在我们有配置的模型的所有层上完成。model.compile也需要这样做，因为我们在超参数中也有optimizer。</p><pre class="kn ko kp kq fq kr ks kt ku aw kv dt"><span id="995f" class="kw kx ht ks b fv ky kz l la lb">model.compile(optimizer=hparams[HP_Optimizer], loss='sparse_categorical_crossentropy', metrics=['accuracy'])</span></pre><p id="f471" class="pw-post-body-paragraph jb jc ht jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">现在您需要在model.fit中传递回调，如下所示:</p><pre class="kn ko kp kq fq kr ks kt ku aw kv dt"><span id="294a" class="kw kx ht ks b fv ky kz l la lb">model.fit(train, batch_size=64, epochs=10, callbacks=[hp.KerasCallback(dir, hparams, trial_id=name)])</span></pre><p id="d67c" class="pw-post-body-paragraph jb jc ht jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated"><code class="eh lc ld le ks b">dir</code>:是目录名。<br/> <code class="eh lc ld le ks b">hparams</code>:超参数字典。<br/> <code class="eh lc ld le ks b">trial_id</code>:使用这些参数运行的名称。</p><p id="892f" class="pw-post-body-paragraph jb jc ht jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">现在我们需要用所有可能的参数组合来运行模型。为此，我们只需在超参数的嵌套循环中调用模型函数:</p><pre class="kn ko kp kq fq kr ks kt ku aw kv dt"><span id="6003" class="kw kx ht ks b fv ky kz l la lb">!rm -rf logs/ #To remove previous logs<br/>iter = 0<br/>for layer1 in HP_Filters_layer_1.domain.values:<br/> for layer2 in HP_Filters_layer_2.domain.values:<br/>     for kernel in HP_Kernel.domain.values:<br/>         for optimizer in HP_Optimizer.domain.values:<br/>             iter += 1<br/>                hparams = {<br/>                HP_Filters_layer_1: layer1,<br/>                HP_Filters_layer_2: layer2,<br/>                HP_Kernel:kernel,<br/>                HP_Optimizer: optimizer<br/>                }<br/>                run_name = "run_"+iter<br/>                acc = configurableModel('logs/hparam_tuning/' + run_name, hparams, run_name)</span></pre><p id="ffd5" class="pw-post-body-paragraph jb jc ht jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">训练结束后，我们将能够在tensorboard中看到HPARAMS选项卡和结果表。</p><figure class="kn ko kp kq fq iu fe ff paragraph-image"><div role="button" tabindex="0" class="iv iw di ix bf iy"><div class="fe ff lj"><img src="../Images/317a28ce6c1030dce991c53516a591b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*pPee8JwMHXH6UsHN.png"/></div></div></figure><p id="93ca" class="pw-post-body-paragraph jb jc ht jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">需要考虑的一件重要事情是，训练需要运行n次(取决于配置的数量。2 <em class="lk"> 2 </em> 2*2)，这可能会导致大量的计算时间。因此，在小时间段的小数据集上进行实验，以找到好的参数或至少过滤掉最差的参数，这可能是一个好主意。</p><p id="0bcb" class="pw-post-body-paragraph jb jc ht jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">当我们探索Tensorboard时，我们发现Tensorboard在许多方面对监控训练有很大的帮助。Tensorboard也可以和PyTorch一起使用。</p><p id="7e6a" class="pw-post-body-paragraph jb jc ht jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">代码可以在<a class="ae lf" href="https://github.com/Keshav-Aggarwal/Exploring-Tensorboard" rel="noopener ugc nofollow" target="_blank"> Github </a>上找到。</p><p id="04bc" class="pw-post-body-paragraph jb jc ht jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">快乐深度学习…</p></div></div>    
</body>
</html>