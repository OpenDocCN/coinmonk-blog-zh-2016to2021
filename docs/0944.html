<html>
<head>
<title>An introduction to CNNs and a step by step model of a Digit Recognizer using MNIST database in python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">介绍了细胞神经网络和使用python中MNIST数据库的数字识别器的逐步模型</h1>
<blockquote>原文：<a href="https://medium.com/coinmonks/an-introduction-to-cnns-and-a-step-by-step-model-of-a-digit-recognizer-using-mnist-database-in-f4ea6af06d77?source=collection_archive---------1-----------------------#2018-07-04">https://medium.com/coinmonks/an-introduction-to-cnns-and-a-step-by-step-model-of-a-digit-recognizer-using-mnist-database-in-f4ea6af06d77?source=collection_archive---------1-----------------------#2018-07-04</a></blockquote><div><div class="ef hh hi hj hk hl"/><div class="hm hn ho hp hq"><figure class="hs ht fm fo hu hv fe ff paragraph-image"><div role="button" tabindex="0" class="hw hx di hy bf hz"><div class="fe ff hr"><img src="../Images/3ab2a2a8e86e2caf9c283848c25f39da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*r79oc2nCHVuUUtwbTY5ROQ.jpeg"/></div></div></figure><div class=""/><p id="c620" class="pw-post-body-paragraph jb jc ie jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">卷积神经网络(CNN或ConvNets)在20世纪末被引入，但由于计算成本高而没有得到普及。在AlexNet赢得2012年的ImageNet挑战赛后，CNN成为人们关注的焦点。现在，随着GPU和TPU可用性的增加，ConvNets正被广泛使用。本文将介绍CNN的基本轮廓，然后是MNIST数据库(手写数字识别)的完整解决方案。</p><h1 id="9e2f" class="jz ka ie bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw dt translated">第一部分(CNN简介)</h1><h1 id="ccf5" class="jz ka ie bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw dt translated">概观</h1><p id="83a5" class="pw-post-body-paragraph jb jc ie jd b je kx jg jh ji ky jk jl jm kz jo jp jq la js jt ju lb jw jx jy hm dt translated">为理解ConvNets的基本结构和工作原理，将涉及以下主题:</p><ol class=""><li id="c798" class="lc ld ie jd b je jf ji jj jm le jq lf ju lg jy lh li lj lk dt translated">卷积运算(用于边缘检测) :滤波器工作、填充和跨越。</li><li id="ef3f" class="lc ld ie jd b je ll ji lm jm ln jq lo ju lp jy lh li lj lk dt translated">体积上的卷积</li><li id="6f07" class="lc ld ie jd b je ll ji lm jm ln jq lo ju lp jy lh li lj lk dt translated">建立一个CNN</li><li id="722f" class="lc ld ie jd b je ll ji lm jm ln jq lo ju lp jy lh li lj lk dt translated">汇集层</li><li id="33fe" class="lc ld ie jd b je ll ji lm jm ln jq lo ju lp jy lh li lj lk dt translated">全连接层</li></ol><h1 id="ae8f" class="jz ka ie bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw dt translated"><strong class="ak">边缘检测的卷积运算</strong></h1><p id="b429" class="pw-post-body-paragraph jb jc ie jd b je kx jg jh ji ky jk jl jm kz jo jp jq la js jt ju lb jw jx jy hm dt translated">我们使用<strong class="jd if">滤波器</strong>(或内核)进行边缘检测。滤光器可以是水平的、垂直的，或者甚至倾斜一个角度，例如45度。垂直检测器的工作如下所示:</p><figure class="lr ls lt lu fq hv fe ff paragraph-image"><div role="button" tabindex="0" class="hw hx di hy bf hz"><div class="fe ff lq"><img src="../Images/2d3a66a1a7c84a4a2bd76398df52a927.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*W-pEMigHgr3wI8Ib_WyADA.png"/></div></div><figcaption class="lv lw fg fe ff lx ly bd b be z ek">The input matrix (6x6x1) convolves with the filter matrix(3x3x1) to give the output matrix(4x4x1)</figcaption></figure><figure class="lr ls lt lu fq hv fe ff paragraph-image"><div class="fe ff lz"><img src="../Images/b743320755360e52f45f25591af4e734.png" data-original-src="https://miro.medium.com/v2/resize:fit:1138/format:webp/1*QYnKB0aXWJEJhhJKSBQIkg.png"/></div><figcaption class="lv lw fg fe ff lx ly bd b be z ek">We notice an edge in the output matrix(white color) which gets thinner as the size is increased</figcaption></figure><p id="ecff" class="pw-post-body-paragraph jb jc ie jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">滤波器矩阵从左上角开始一次扫描输入图像的9(3×3)个元素。逐元素乘法之后是所有九个乘积的相加，以形成输出矩阵的一个元素。</p><p id="380e" class="pw-post-body-paragraph jb jc ie jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">第一次迭代:过滤器扫描列1到3和行1到3。</p><p id="f571" class="pw-post-body-paragraph jb jc ie jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">第二次迭代:过滤器扫描第2到4列和第1到3行，依此类推。</p><p id="d60a" class="pw-post-body-paragraph jb jc ie jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">最后一次迭代:过滤器扫描第4到6列和第4到6行。</p><p id="0bf5" class="pw-post-body-paragraph jb jc ie jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">因此，输出图像的大小为(6–3+1)x(6–3+1)。</p><p id="da5f" class="pw-post-body-paragraph jb jc ie jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">如果输入矩阵有nxn个元素，滤波器有fxf个元素，则输出矩阵有(n-f+1) x (n-f +1)个元素。</p><p id="cabd" class="pw-post-body-paragraph jb jc ie jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">根据数学，这个过程被称为<strong class="jd if">互相关</strong>，但在神经网络中它被命名为卷积。</p><h2 id="124b" class="ma ka ie bd kb mb mc md kf me mf mg kj jm mh mi kn jq mj mk kr ju ml mm kv mn dt translated"><strong class="ak">填充</strong></h2><p id="63c0" class="pw-post-body-paragraph jb jc ie jd b je kx jg jh ji ky jk jl jm kz jo jp jq la js jt ju lb jw jx jy hm dt translated">随着图像尺寸的减小，卷积过程也有缺点。此外，拐角中的像素仅被计数一次，因为不存在导致拐角周围信息丢失的重叠。填充有助于克服这些缺点。</p><figure class="lr ls lt lu fq hv fe ff paragraph-image"><div role="button" tabindex="0" class="hw hx di hy bf hz"><div class="fe ff mo"><img src="../Images/b195ff9ffc38bdd4b39681bfbaf2cd1d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4xM963EIUdUg1jRrPffUSg.png"/></div></div><figcaption class="lv lw fg fe ff lx ly bd b be z ek">A 4x4 image padded with a single layer of zeros (p=1)</figcaption></figure><p id="3964" class="pw-post-body-paragraph jb jc ie jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">现在，如果输入矩阵有nxn个元素，p是填充，滤波器有fxf个元素，则输出矩阵有(n+2p-f+1) x (n+2p-f +1)个元素。这有助于我们更加重视角落中的像素。</p><h2 id="6f06" class="ma ka ie bd kb mb mc md kf me mf mg kj jm mh mi kn jq mj mk kr ju ml mm kv mn dt translated">阔步</h2><p id="a25b" class="pw-post-body-paragraph jb jc ie jd b je kx jg jh ji ky jk jl jm kz jo jp jq la js jt ju lb jw jx jy hm dt translated">如前所述，滤波器矩阵以连续的方式一次扫描输入矩阵的9个元素。默认情况下，步幅设置为1。如果我们想在每次迭代后跳过一次迭代，我们可以设置步幅= 2。迭代次数以有规律的方式减少。当图像尺寸很大时，这很有用。如果步幅给出了滤波器的某些部分没有完全覆盖输入矩阵的情况，我们不考虑它。</p><p id="8707" class="pw-post-body-paragraph jb jc ie jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">因此，在卷积中的填充和跨步的组合效果下:</p><figure class="lr ls lt lu fq hv fe ff paragraph-image"><div role="button" tabindex="0" class="hw hx di hy bf hz"><div class="fe ff mp"><img src="../Images/ba406fa2d2ec294178dc22a9c2bd7b1e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DbNGCgqeFwok05tic4vzUA.png"/></div></div></figure><p id="615b" class="pw-post-body-paragraph jb jc ie jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">上面输出的值并不总是整数。在值不是整数的情况下，我们取下限值。</p><h2 id="b512" class="ma ka ie bd kb mb mc md kf me mf mg kj jm mh mi kn jq mj mk kr ju ml mm kv mn dt translated">体积上的卷积</h2><p id="d049" class="pw-post-body-paragraph jb jc ie jd b je kx jg jh ji ky jk jl jm kz jo jp jq la js jt ju lb jw jx jy hm dt translated">1.<strong class="jd if">带单个过滤器</strong></p><figure class="lr ls lt lu fq hv fe ff paragraph-image"><div role="button" tabindex="0" class="hw hx di hy bf hz"><div class="fe ff mq"><img src="../Images/9ed08bd8dae8559c322fa6f020906495.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*H1oPc6-1oDB7ZELFTmO6KQ.png"/></div></div><figcaption class="lv lw fg fe ff lx ly bd b be z ek">6x6x3 input matrix convolves with 3x3x3 filter to give 4x4x1 output</figcaption></figure><p id="2e6e" class="pw-post-body-paragraph jb jc ie jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">输入矩阵的尺寸为n(h)x n(w)x n(c)[通道的高度、宽度和数量]。输入矩阵和滤波器的通道数应该相同。n(h)和n(w)的值可以不同。在这个例子中，过滤器可以被认为是一个立方体，它从左上角开始一次移动输入的27个元素。因此，无论通道的数量是多少，使用一个滤波器的输入将总是给出单个通道的输出。</p><p id="4dcb" class="pw-post-body-paragraph jb jc ie jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">2.<strong class="jd if">使用多个滤镜(多个滤镜)</strong></p><p id="a850" class="pw-post-body-paragraph jb jc ie jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">输入和滤波器中的通道数将保持不变。输出的通道数量将等于所使用的滤波器数量。</p><figure class="lr ls lt lu fq hv fe ff paragraph-image"><div role="button" tabindex="0" class="hw hx di hy bf hz"><div class="fe ff mr"><img src="../Images/2a035242cc7559e672b46ca69f6029bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SvMakIpvPHJcElz-8S5swQ.png"/></div></div><figcaption class="lv lw fg fe ff lx ly bd b be z ek">The number of channels in the output layer is equal to the number of filters</figcaption></figure><h2 id="f449" class="ma ka ie bd kb mb mc md kf me mf mg kj jm mh mi kn jq mj mk kr ju ml mm kv mn dt translated">建立一个CNN</h2><p id="46ce" class="pw-post-body-paragraph jb jc ie jd b je kx jg jh ji ky jk jl jm kz jo jp jq la js jt ju lb jw jx jy hm dt translated">现在，我们已经理解了卷积的概念，我将尝试证明这些被认为是一类神经网络的原因。滤波器的元素(3×3滤波器中的9个)可以以类似于ann的方式训练。我们还可以添加一个偏置项和一个非线性激活函数。对于单个3×3滤波器，我们有10个参数(9个权重和1个偏置项)。这种使用一个(或多个)滤波器从输入层到输出层的计算被称为CNN的一层。我们可以在网络中添加许多这样的层。与传统神经网络相比，CNN的优势在于，由于参数的数量与输入的大小无关，因此CNN不容易过拟合。</p><p id="fc30" class="pw-post-body-paragraph jb jc ie jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">对于CNN的单层:</p><ol class=""><li id="820b" class="lc ld ie jd b je jf ji jj jm le jq lf ju lg jy lh li lj lk dt translated">输入:n(高)x n(宽)x n(高)</li><li id="3e4c" class="lc ld ie jd b je ll ji lm jm ln jq lo ju lp jy lh li lj lk dt translated">滤波器:f x f x n(c)并且滤波器的数量是n(c)’</li><li id="87d8" class="lc ld ie jd b je ll ji lm jm ln jq lo ju lp jy lh li lj lk dt translated">输出:</li></ol><figure class="lr ls lt lu fq hv fe ff paragraph-image"><div role="button" tabindex="0" class="hw hx di hy bf hz"><div class="fe ff ms"><img src="../Images/6e9f4529355c27bbeeaed5e8aa690501.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HhhUaIGXLaAACrLk5ouajA.png"/></div></div></figure><p id="6ef4" class="pw-post-body-paragraph jb jc ie jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">4.重量数:[n(h) x n(w) + 1] x n(c)'</p><h1 id="f236" class="jz ka ie bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw dt translated">汇集层</h1><p id="7518" class="pw-post-body-paragraph jb jc ie jd b je kx jg jh ji ky jk jl jm kz jo jp jq la js jt ju lb jw jx jy hm dt translated">ConvNets使用池层来减少表示的大小并提高计算速度。关于池层的一个重要事实是没有参数。我们只给出池层的一组超参数(过滤器的大小(f)、步幅(s)和类型(max或avg))。由于在反向传播期间没有参数需要学习，我们可以说池就像一个固定的函数。卷积层和池层通常被视为同一层，因为池层没有任何参数。</p><p id="b89d" class="pw-post-body-paragraph jb jc ie jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">最常见的池类型有:</p><ol class=""><li id="4e82" class="lc ld ie jd b je jf ji jj jm le jq lf ju lg jy lh li lj lk dt translated"><strong class="jd if"> Max pooling </strong>:定义为超参数的过滤器将从符合条件的元素集中选择最大值。最大池比平均池应用更广泛。</li></ol><figure class="lr ls lt lu fq hv fe ff paragraph-image"><div role="button" tabindex="0" class="hw hx di hy bf hz"><div class="fe ff mt"><img src="../Images/e3f3cdf8a3373128cb17e930c0b9d142.png" data-original-src="https://miro.medium.com/v2/resize:fit:748/format:webp/1*zUT3YlpWvVml-EImmh4q-w.png"/></div></div><figcaption class="lv lw fg fe ff lx ly bd b be z ek">Max Pooling</figcaption></figure><p id="03a4" class="pw-post-body-paragraph jb jc ie jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">2.<strong class="jd if">平均池</strong>:定义为超参数的过滤器将从考虑的元素集中选择平均值。这用于非常深的NNs。</p><figure class="lr ls lt lu fq hv fe ff paragraph-image"><div class="fe ff mu"><img src="../Images/eefeee75722eff1bde352b1a35a742b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:870/format:webp/1*LKygE7M4SoqgITZFeW0LTA.png"/></div><figcaption class="lv lw fg fe ff lx ly bd b be z ek">Avg Pooling</figcaption></figure><h1 id="8836" class="jz ka ie bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw dt translated">全连接层</h1><p id="d976" class="pw-post-body-paragraph jb jc ie jd b je kx jg jh ji ky jk jl jm kz jo jp jq la js jt ju lb jw jx jy hm dt translated">完全连接的层就像单个NN层一样。前一层的输出作为这一层的输入给出。这一层之所以得名，是因为前一层的每个单元都与这一层的每个单元相连。</p><h1 id="f351" class="jz ka ie bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw dt translated">B部分(MNIST数据库的逐步解决方案)</h1><p id="7a5a" class="pw-post-body-paragraph jb jc ie jd b je kx jg jh ji ky jk jl jm kz jo jp jq la js jt ju lb jw jx jy hm dt translated">我们的目标是从成千上万的手写图像数据集中正确识别数字。数据可以在:<a class="ae mv" href="https://www.kaggle.com/c/digit-recognizer/data" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/c/digit-recognizer/data</a>找到</p><p id="ba56" class="pw-post-body-paragraph jb jc ie jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">完成我们第一个CNN项目的步骤:</p><p id="2dbd" class="pw-post-body-paragraph jb jc ie jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">1.我们首先导入所需的库。</p><pre class="lr ls lt lu fq mw mx my mz aw na dt"><span id="05af" class="ma ka ie mx b fv nb nc l nd ne">import pandas as pd<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>import matplotlib.image as mpimg<br/>import seaborn as sns</span><span id="2b3a" class="ma ka ie mx b fv nf nc l nd ne">from sklearn.model_selection import train_test_split</span><span id="6f6e" class="ma ka ie mx b fv nf nc l nd ne">from keras.utils.np_utils import to_categorical <br/>from keras.models import Sequential<br/>from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D<br/>from keras.optimizers import RMSprop<br/>from keras.preprocessing.image import ImageDataGenerator<br/>from keras.callbacks import ReduceLROnPlateau</span></pre><p id="256e" class="pw-post-body-paragraph jb jc ie jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">2.我们加载文件并将标签分配给Y_train。这些是<strong class="jd if">一个热编码的</strong>，其余数据给X_train。</p><pre class="lr ls lt lu fq mw mx my mz aw na dt"><span id="c939" class="ma ka ie mx b fv nb nc l nd ne">train = pd.read_csv("../input/train.csv")<br/>test = pd.read_csv("../input/test.csv")<br/>Y_train = train["label"]<br/>X_train = train.drop(labels = ["label"],axis = 1) <br/>Y_train = to_categorical(Y_train, num_classes = 10)</span></pre><p id="d896" class="pw-post-body-paragraph jb jc ie jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">3.我们检查空值。数据集中没有空值。</p><pre class="lr ls lt lu fq mw mx my mz aw na dt"><span id="845a" class="ma ka ie mx b fv nb nc l nd ne">X_train.isnull().any().describe()<br/>test.isnull().any().describe()</span></pre><p id="159e" class="pw-post-body-paragraph jb jc ie jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">4.除以255是像素的<strong class="jd if">归一化</strong>的一种简单有效的方法。CNN在[0，1]数据上比在[0，255]上收敛得更快。</p><pre class="lr ls lt lu fq mw mx my mz aw na dt"><span id="6591" class="ma ka ie mx b fv nb nc l nd ne">X_train = X_train / 255<br/>test = test / 255</span></pre><p id="ba52" class="pw-post-body-paragraph jb jc ie jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">5.我们使用整形，因为输入值是一维的，但我们想要n(h) x n(w)的二维形式。然后，我们将训练集分成10%的验证数据和90%的训练数据。</p><pre class="lr ls lt lu fq mw mx my mz aw na dt"><span id="c82b" class="ma ka ie mx b fv nb nc l nd ne">X_train = X_train.values.reshape(-1,28,28,1)<br/>test = test.values.reshape(-1,28,28,1)<br/>X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=2)</span></pre><p id="c10c" class="pw-post-body-paragraph jb jc ie jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">6.这是我们模型的前4层。Conv2D层后跟max pool层被视为一个层。<strong class="jd if"> Dropout </strong>是一种减少过拟合的正则化技术。它指的是在神经网络中删除单元(隐藏的和可见的)。</p><pre class="lr ls lt lu fq mw mx my mz aw na dt"><span id="0b0f" class="ma ka ie mx b fv nb nc l nd ne">model = Sequential()</span><span id="5c80" class="ma ka ie mx b fv nf nc l nd ne">model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', <br/>                 activation ='relu', input_shape = (28,28,1)))<br/>model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', <br/>                 activation ='relu'))<br/>model.add(MaxPool2D(pool_size=(2,2)))model.add(Dropout(0.25))<br/>model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', <br/>                 activation ='relu'))<br/>model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', <br/>                 activation ='relu'))<br/>model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))</span></pre><p id="97f5" class="pw-post-body-paragraph jb jc ie jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">7.这些是完全连接的层。我们在最后添加了softmax激活单元，以获得softmax输出<strong class="jd if">。展平用于将二维输出转换回一维，因为它必须进入完全连接的层。</strong></p><pre class="lr ls lt lu fq mw mx my mz aw na dt"><span id="e794" class="ma ka ie mx b fv nb nc l nd ne">model.add(Dropout(0.25))<br/>model.add(Flatten())<br/>model.add(Dense(256, activation = "relu"))<br/>model.add(Dropout(0.5))<br/>model.add(Dense(10, activation = "softmax"))</span></pre><p id="b90a" class="pw-post-body-paragraph jb jc ie jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">8.我们将<strong class="jd if"> RMSprop </strong>设置为优化器。如果精度在3次迭代中保持不变，学习率将变为其值的一半。</p><pre class="lr ls lt lu fq mw mx my mz aw na dt"><span id="bad0" class="ma ka ie mx b fv nb nc l nd ne">optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)<br/>model.compile(optimizer = optimizer , loss = "categorical_crossentropy", metrics=["accuracy"])<br/>epochs = 30<br/>batch_size = 64<br/>learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', <br/>                                            patience=3, <br/>                                            verbose=1, <br/>                                            factor=0.5, <br/>                                            min_lr=0.00001)</span></pre><p id="ad02" class="pw-post-body-paragraph jb jc ie jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">9.最后，我们拟合我们的模型。这是向前和向后传播发生的阶段。如果历元数为30，这一步在CPU上的计算大约需要2小时。我们最终预测我们的测试标签。</p><pre class="lr ls lt lu fq mw mx my mz aw na dt"><span id="9d17" class="ma ka ie mx b fv nb nc l nd ne">final = model.fit(X_train, Y_train, batch_size = batch_size, epochs = epochs, validation_data = (X_val, Y_val),callbacks=[learning_rate_reduction])<br/>results = model.predict(test)</span></pre><p id="3da1" class="pw-post-body-paragraph jb jc ie jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated"><a class="ae mv" href="https://www.kaggle.com/mridul02/digit-recognizer-cnn-keras" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/mridul02/digit-recognizer-cnn-keras</a>是数字识别器上我的kaggle内核的链接。<strong class="jd if">测试集的准确率为99.58%(前15%)。</strong></p><p id="fd9d" class="pw-post-body-paragraph jb jc ie jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">为了更好地了解CNN的能力，尝试应用其他机器学习算法并比较结果。</p><h1 id="3119" class="jz ka ie bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw dt translated">结论</h1><p id="4099" class="pw-post-body-paragraph jb jc ie jd b je kx jg jh ji ky jk jl jm kz jo jp jq la js jt ju lb jw jx jy hm dt translated">在本文中，我们已经理解了ConvNet的工作原理，并在一个著名的机器学习问题上实现了它。完成文章后，我们知道:</p><ol class=""><li id="b073" class="lc ld ie jd b je jf ji jj jm le jq lf ju lg jy lh li lj lk dt translated">ConvNets的工作原理及其命名原因。</li><li id="7e01" class="lc ld ie jd b je ll ji lm jm ln jq lo ju lp jy lh li lj lk dt translated">为什么CNN比传统的人工神经网络工作得更好。</li><li id="1903" class="lc ld ie jd b je ll ji lm jm ln jq lo ju lp jy lh li lj lk dt translated">如何建立一个基本的CNN模型？</li></ol><p id="0403" class="pw-post-body-paragraph jb jc ie jd b je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy hm dt translated">我投入了我所有的知识和努力，使这篇文章尽可能的翔实和紧凑。我欢迎反馈，并感谢如何使这篇文章更好的建议。</p></div></div>    
</body>
</html>